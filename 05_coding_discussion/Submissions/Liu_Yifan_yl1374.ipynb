{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adf57b86",
   "metadata": {},
   "source": [
    "# Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fb67e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50c31b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data.\n",
    "dta = pd.read_csv('../turnout.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abdafd6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>educate</th>\n",
       "      <th>income</th>\n",
       "      <th>vote</th>\n",
       "      <th>white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>675</td>\n",
       "      <td>35</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.7852</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1700</td>\n",
       "      <td>37</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.4183</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1283</td>\n",
       "      <td>82</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9689</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1316</td>\n",
       "      <td>25</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.3834</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1211</td>\n",
       "      <td>33</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.9072</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  age  educate  income  vote  white\n",
       "0   675   35     10.0  2.7852     1      1\n",
       "1  1700   37     12.0  3.4183     0      1\n",
       "2  1283   82     10.0  0.9689     1      1\n",
       "3  1316   25     14.0  3.3834     1      1\n",
       "4  1211   33     10.0  2.9072     0      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set seed\n",
    "np.random.seed(1)\n",
    "\n",
    "# Train-Test split (just using Pandas).\n",
    "train = dta.sample(frac=.8).reset_index(drop=True)\n",
    "test = dta.drop(train.index).reset_index(drop=True)\n",
    "\n",
    "# Look at the head of the data.\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4702d6",
   "metadata": {},
   "source": [
    "# The process "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088491d3",
   "metadata": {},
   "source": [
    "I will divide the data into two subsets, one for categrical variable(white or not), one for continuous variables. And I will calculate the class probability and conditional probabilities base on two different types of variables. In the end, I will calculateb the predictive probability combining the above conditional probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28fae6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset the data.\n",
    "cat_cols = train[['vote', 'white']]\n",
    "con_cols = train[['age', 'educate', 'income', 'vote']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "920559a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_probs(data,outcome_var=\"\"):\n",
    "    '''\n",
    "    Function calculates the class and conditional probabilities in \n",
    "    the binary data. \n",
    "    \n",
    "    Arguements\n",
    "    ----------\n",
    "    data: a data set only contains categorical variables.\n",
    "    outcome_var: The variable that serves as the condition.\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    The class probability and the conditional probabilities.\n",
    "    '''\n",
    "    # Generate empty dictionary containers.\n",
    "    class_probs = {};cond_probs = {}\n",
    "    # Locate all variables that are not the outcome.\n",
    "    vars = [v for v in data.columns if v != outcome_var]\n",
    "    # iterate through the class outcomes\n",
    "    for y, d in data.groupby(outcome_var): \n",
    "        # calculate the class probabilities\n",
    "        class_probs.update({y: d.shape[0]/data.shape[0]})\n",
    "        for v in vars:\n",
    "            # calculate the conditional probabilities for each variable given the class.\n",
    "            pr = d[v].sum()/d.shape[0]\n",
    "            cond_probs[(v,1,y)] = pr \n",
    "            cond_probs[(v,0,y)] = 1 - pr\n",
    "    return class_probs, cond_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30490b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign them to objects for later usage.\n",
    "class_probs, cond_probs = calc_probs(cat_cols, 'vote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0c9e473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset the train data by the 'vote' column.\n",
    "v1 = train.query(\"vote == 1\")\n",
    "v0 = train.query(\"vote == 0\")\n",
    "\n",
    "# Collect the mean and standard dev. of each conditional distribution\n",
    "dist_locs = \\\n",
    "{(\"age\",1):{'mean':v1.age.mean(),'sd':v1.age.std()},\n",
    " (\"age\",0):{'mean':v0.age.mean(),'sd':v0.age.std()},\n",
    " (\"educate\",1):{'mean':v1.educate.mean(),'sd':v1.educate.std()},\n",
    " (\"educate\",0):{'mean':v0.educate.mean(),'sd':v0.educate.std()},\n",
    " (\"income\",1):{'mean':v1.income.mean(),'sd':v1.income.std()},\n",
    " (\"income\",0):{'mean':v0.income.mean(),'sd':v0.income.std()}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e6db5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data,class_probs,cond_probs,dist_locs):\n",
    "    '''\n",
    "    This function takes the original data, the class probability, the conditional probabilty of the categrical variable and the statistics of each conditional distribution as input and returns both the probabilities and the most likely class.\n",
    "    \n",
    "    Arguements\n",
    "    ----------\n",
    "    data: the original data.\n",
    "    class_probs: the class probability of the prediction variable.\n",
    "    cond_probs: the conditional probability of the categorical variable.\n",
    "    dist_locs: the mean and standard dev. of each conditional distribution\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    The probabilities and the most likely class.\n",
    "    '''\n",
    "    store_preds = []\n",
    "    #Iterate through each row.\n",
    "    for i,row in data.iterrows():\n",
    "        #Set the initial probabilities to 0.\n",
    "        pr_0 = 1; pr_1 = 1\n",
    "        #Mutiply all the conditional probabilities of continuous varables.\n",
    "        for j in range(1, 4):\n",
    "            pr_0 *= st.norm(dist_locs[(row.index[j],0)]['mean'],\n",
    "                            dist_locs[(row.index[j],0)]['sd']).pdf(row.values[j])\n",
    "            pr_1 *= st.norm(dist_locs[(row.index[j],1)]['mean'], \n",
    "                            dist_locs[(row.index[j],1)]['sd']).pdf(row.values[j])\n",
    "        #Then mutiply the conditional probability of categorical variable and the class probability.\n",
    "        pr_0 *= cond_probs[(row.index[5],row.values[5],0)]\n",
    "        pr_1 *= cond_probs[(row.index[5],row.values[5],1)]\n",
    "        pr_0 *= class_probs[0]\n",
    "        pr_1 *= class_probs[1]\n",
    "        # Assign the class designation to the highest probability\n",
    "        if pr_0 >= pr_1:\n",
    "            class_pred = 0\n",
    "        else:\n",
    "            class_pred = 1\n",
    "            \n",
    "        store_preds.append([pr_0,pr_1,class_pred])\n",
    "        \n",
    "    return pd.DataFrame(store_preds,columns=[\"pr_0\",\"pr_1\",\"pred\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c438e52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.743125"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the predictive accuracy on training data.\n",
    "preds=predict(train,class_probs,cond_probs,dist_locs)\n",
    "accuracy = sum(train.vote == preds.pred)/train.shape[0]\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9487548c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the predictive accuracy on test data.\n",
    "test_preds = predict(test, class_probs, cond_probs, dist_locs)\n",
    "test_accuracy = sum(test.vote == test_preds.pred)/test.shape[0]\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bbf55a",
   "metadata": {},
   "source": [
    "The classifier has a accuracy of 74.31% for the training data and has a accuracy of 71% for the test data. It is indeed better than coin flips(50%)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
