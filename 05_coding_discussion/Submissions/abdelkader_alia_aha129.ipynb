{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27ea2c7c",
   "metadata": {},
   "source": [
    "### Coding Discussion 5\n",
    "##### Alia Abdelkader\n",
    "\n",
    "#### Can we predict whether or not someone will vote?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88258b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint as pp # for printing\n",
    "import scipy.stats as st # for Normal PDF\n",
    "\n",
    "# Silence warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Change working directory to the location of the cloned repository, where the data file is located\n",
    "os.chdir('/Users/Alia/Desktop')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71439bc",
   "metadata": {},
   "source": [
    "#### Building a Naive Bayesian Classifier - Binary Predictor\n",
    "\n",
    "- vote = 1 means the person voted\n",
    "- vote = 0 means the person did not vote\n",
    "\n",
    "- white = 1 means the person is white\n",
    "- white = 0 means the person is not white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3584c3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: 1600 \n",
      "Test Data: 400\n"
     ]
    }
   ],
   "source": [
    "# Set seed\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Read in data\n",
    "edata = pd.read_csv(\"turnout.csv\")\n",
    "\n",
    "# Train-Test split\n",
    "train = edata.sample(frac=.8).reset_index(drop=True)\n",
    "test = edata.drop(train.index).reset_index(drop=True)\n",
    "\n",
    "# Print off the split count\n",
    "print(\"Training Data:\",train.shape[0],\n",
    "      \"\\nTest Data:\",test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1a680e",
   "metadata": {},
   "source": [
    "##### Calculate class probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05306eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pr(vote = 1): 0.7425\n",
      "Pr(vote = 0): 0.2575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N = train.shape[0]\n",
    "\n",
    "# Subset the data by class (voted or did not vote)\n",
    "v1 = train.query(\"vote == 1\")\n",
    "v0 = train.query(\"vote == 0\")\n",
    "\n",
    "# Calculate the probability for each class\n",
    "pr_v_1 = v1.shape[0]/N\n",
    "pr_v_0 = v0.shape[0]/N\n",
    "\n",
    "# Print the probabilities\n",
    "print(\n",
    "f\"\"\"\n",
    "Pr(vote = 1): {pr_v_1}\n",
    "Pr(vote = 0): {pr_v_0}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a991265e",
   "metadata": {},
   "source": [
    "##### Calculate conditional probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb22e458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pr(white = 1 | vote = 1): 0.8686868686868687\n",
      "Pr(white = 0 | vote = 1): 0.13131313131313133\n",
      "Pr(white = 1 | vote = 0): 0.7985436893203883\n",
      "Pr(white = 0 | vote = 0): 0.20145631067961164\n",
      "\n",
      "\n",
      "Pr(v = 1) = 0.09750000000000002\n",
      "Pr(v = 0) = 0.051875\n",
      "\n",
      "Because 0.0975 is greater than 0.0519, we would predict that the person would vote (v=1).\n"
     ]
    }
   ],
   "source": [
    "# Given V == 1\n",
    "w1_v1 = v1.query(\"white == 1\").shape[0]/v1.shape[0]\n",
    "w0_v1 = v1.query(\"white== 0\").shape[0]/v1.shape[0]\n",
    "\n",
    "# Given V == 0\n",
    "w1_v0 = v0.query(\"white == 1\").shape[0]/v0.shape[0]\n",
    "w0_v0 = v0.query(\"white == 0\").shape[0]/v0.shape[0]\n",
    "\n",
    "print(\n",
    "f\"\"\"\n",
    "Pr(white = 1 | vote = 1): {w1_v1}\n",
    "Pr(white = 0 | vote = 1): {w0_v1}\n",
    "Pr(white = 1 | vote = 0): {w1_v0}\n",
    "Pr(white = 0 | vote = 0): {w0_v0}\n",
    "\"\"\")\n",
    "\n",
    "# Predict whether a person will vote if they are not white\n",
    "\n",
    "prob_v1 = w0_v1 * pr_v_1\n",
    "prob_v0 = w0_v0 * pr_v_0\n",
    "\n",
    "print(f\"\"\"\n",
    "Pr(v = 1) = {prob_v1}\n",
    "Pr(v = 0) = {prob_v0}\n",
    "\"\"\")\n",
    "\n",
    "print(\"Because 0.0975 is greater than 0.0519, we would predict that the person would vote (v=1).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9beba0",
   "metadata": {},
   "source": [
    "##### Predicting Multiple Observations - Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f7656ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class probabilities\n",
      "\n",
      "{0: 0.2575, 1: 0.7425}\n",
      "\n",
      "\n",
      "conditional probabilities\n",
      "\n",
      "{('white', 0, 0): 0.20145631067961167,\n",
      " ('white', 0, 1): 0.13131313131313127,\n",
      " ('white', 1, 0): 0.7985436893203883,\n",
      " ('white', 1, 1): 0.8686868686868687}\n"
     ]
    }
   ],
   "source": [
    "def calc_probs(data,outcome_var=\"\"):\n",
    "    '''\n",
    "    Function calculates the class and conditional probabilities in\n",
    "    the binary data.\n",
    "    '''\n",
    "    # Generate empty dictionary containers.\n",
    "    class_probs = {};cond_probs = {}\n",
    "    # Locate all variables that are not the outcome.\n",
    "    vars = [v for v in data.columns if v != outcome_var]\n",
    "    # iterate through the class outcomes\n",
    "    for y, d in data.groupby(outcome_var):\n",
    "        # calculate the class probabilities\n",
    "        class_probs.update({y: d.shape[0]/data.shape[0]})\n",
    "        for v in vars:\n",
    "            # calculate the conditional probabilities for each variable given the class.\n",
    "            pr = d[v].sum()/d.shape[0]\n",
    "            cond_probs[(v,1,y)] = pr\n",
    "            cond_probs[(v,0,y)] = 1 - pr\n",
    "    return class_probs, cond_probs\n",
    "\n",
    "# Drop columns not needed for binary predictors\n",
    "train_binary = train.drop(columns=['id', 'age', 'educate', 'income'])\n",
    "test_binary = test.drop(columns=['id', 'age', 'educate', 'income'])\n",
    "\n",
    "# Run\n",
    "class_probs, cond_probs = calc_probs(train_binary,outcome_var=\"vote\")\n",
    "\n",
    "# Print\n",
    "print(\"class probabilities\",end=\"\\n\\n\")\n",
    "pp.pprint(class_probs)\n",
    "print(\"\\n\")\n",
    "print(\"conditional probabilities\",end=\"\\n\\n\")\n",
    "pp.pprint(cond_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbcb711d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       pr_0    pr_1  pred\n",
      "0  0.205625  0.6450     1\n",
      "1  0.051875  0.0975     1\n",
      "2  0.205625  0.6450     1\n",
      "3  0.205625  0.6450     1\n",
      "4  0.205625  0.6450     1\n",
      "5  0.205625  0.6450     1\n",
      "6  0.205625  0.6450     1\n",
      "7  0.205625  0.6450     1\n",
      "8  0.205625  0.6450     1\n",
      "9  0.205625  0.6450     1\n",
      "\n",
      "\n",
      "Training accuracy = 0.7425\n",
      "Test accuracy = 0.7\n"
     ]
    }
   ],
   "source": [
    "def predict_binary(data,class_probs,cond_probs):\n",
    "    '''\n",
    "    Function calculates the conditional probability for membership into each class.\n",
    "    Then returns both the probabilities and the most likely class.\n",
    "    '''\n",
    "    store_preds = []\n",
    "    for i,row in data.iterrows():\n",
    "        pr_1 = 1; pr_0 = 1\n",
    "        for j in range(1,len(row.index)):\n",
    "            pr_0 *= cond_probs[(row.index[j],row.values[j],0)]\n",
    "            pr_1 *= cond_probs[(row.index[j],row.values[j],1)]\n",
    "        pr_0 *= class_probs[0]\n",
    "        pr_1 *= class_probs[1]\n",
    "        store_preds.append([pr_0,pr_1,max([(pr_0,0),(pr_1,1)])[1]])\n",
    "    return pd.DataFrame(store_preds,columns=[\"pr_0\",\"pr_1\",\"pred\"])\n",
    "\n",
    "# Run\n",
    "preds = predict_binary(train_binary,class_probs,cond_probs)\n",
    "print(preds.head(10))\n",
    "print('\\n')\n",
    "\n",
    "# Calculate the model's predictive accuracy\n",
    "accuracy = sum(train_binary.vote == preds.pred)/train_binary.shape[0]\n",
    "print(f\"\"\"Training accuracy = {accuracy}\"\"\")\n",
    "\n",
    "# Check the model's accuracy on the test data\n",
    "binary_preds = predict_binary(test_binary, class_probs, cond_probs)\n",
    "binary_test_accuracy = sum(test_binary.vote == binary_preds.pred)/test_binary.shape[0]\n",
    "print(f\"\"\"Test accuracy = {binary_test_accuracy}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5028bf33",
   "metadata": {},
   "source": [
    "The classifier's accuracy when run on the test data was 70%, which is better than chance (i.e. a coin flip.) Predictably, the accuracy on the training data, which has more observations, was 74%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ddf48b",
   "metadata": {},
   "source": [
    "#### Building a Naive Bayesian Classifier - Continuous Predictors\n",
    "\n",
    "For this model, we'll use a probability density function for Gaussian (normal) distribution to convert continuous values into probabilities, thereby mapping the continuous predictors into a probability space.\n",
    "\n",
    "We can use information regarding the distribution of each continuous predictor and find out where any single point is on that continuous variable's probability distribution.\n",
    "\n",
    "In this model, we'll use only *income* and *educate* as our two predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1b16e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('educate', 0): {'mean': 10.62864077669903, 'sd': 3.304381091983527},\n",
      " ('educate', 1): {'mean': 12.558922558922559, 'sd': 3.295714127444309},\n",
      " ('income', 0): {'mean': 2.7381618932038836, 'sd': 2.2429913729337625},\n",
      " ('income', 1): {'mean': 4.229461952861947, 'sd': 2.8482089910676964}}\n"
     ]
    }
   ],
   "source": [
    "# Drop columns not needed for the specified model, rearrange\n",
    "train_cont = train.drop(columns=['id', 'white', 'age'])\n",
    "train_cont = train_cont[['vote', 'educate', 'income']]\n",
    "test_cont = test.drop(columns=['id', 'white', 'age'])\n",
    "test_cont = test_cont[['vote', 'educate', 'income']]\n",
    "\n",
    "# Subset data by \"vote\"\n",
    "v1 = train_cont.query(\"vote == 1\")\n",
    "v0 = train_cont.query(\"vote == 0\")\n",
    "\n",
    "# Calculate class probabilities\n",
    "pr_v1 = v1.shape[0]/train_cont.shape[0]\n",
    "pr_v0 = v0.shape[0]/train_cont.shape[0]\n",
    "\n",
    "# Calculate mean and stdev of each continuous distribution\n",
    "dist_locs = \\\n",
    "{(\"educate\",1):{'mean':v1.educate.mean(), 'sd': v1.educate.std()}, # Educate given v1\n",
    " (\"educate\",0):{'mean':v0.educate.mean(), 'sd': v0.educate.std()}, # Educate given v0\n",
    " (\"income\",1):{'mean':v1.income.mean(), 'sd': v1.income.std()}, # Income given v1\n",
    " (\"income\",0):{'mean':v0.income.mean(), 'sd': v0.income.std()} # Income given v0\n",
    "}\n",
    "\n",
    "pp.pprint(dist_locs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab508a1",
   "metadata": {},
   "source": [
    "Now that we have mapped the variables, we can predict whether each person will vote.\n",
    "\n",
    "##### Predicting Multiple Observations - Continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f2e139f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       pr_0      pr_1  pred\n",
      "0  0.001206  0.004321     1\n",
      "1  0.000252  0.000086     0\n",
      "2  0.004438  0.005513     1\n",
      "3  0.003170  0.002730     0\n",
      "4  0.003276  0.010273     1\n",
      "5  0.000466  0.000190     0\n",
      "6  0.004891  0.009462     1\n",
      "7  0.001431  0.006917     1\n",
      "8  0.002290  0.004604     1\n",
      "9  0.002755  0.011423     1\n",
      "\n",
      "\n",
      "Training accuracy = 0.73125\n",
      "Test accuracy = 0.7075\n"
     ]
    }
   ],
   "source": [
    "def predict_cont(data,dist_locs):\n",
    "    '''\n",
    "    Function calculates the conditional probability for membership into each class.\n",
    "    Then returns both the probabilities and the most likely class.\n",
    "    '''\n",
    "    store_preds = []\n",
    "    for i,row in data.iterrows():\n",
    "\n",
    "        # Get the predictions using a Gaussan distribution\n",
    "        pr_0 = 1; pr_1 = 1\n",
    "        for j in range(1,len(row)):\n",
    "            pr_0 *= st.norm(dist_locs[(row.index[j],0)]['mean'],\n",
    "                            dist_locs[(row.index[j],0)]['sd']).pdf(row.values[j])\n",
    "            pr_1 *= st.norm(dist_locs[(row.index[j],1)]['mean'],\n",
    "                            dist_locs[(row.index[j],1)]['sd']).pdf(row.values[j])\n",
    "        pr_0 *= pr_v0\n",
    "        pr_1 *= pr_v1\n",
    "\n",
    "        # Assign the class designation to the highest probability\n",
    "        if pr_0 >= pr_1:\n",
    "            class_pred = 0\n",
    "        else:\n",
    "            class_pred = 1\n",
    "\n",
    "        store_preds.append([pr_0,pr_1,class_pred])\n",
    "\n",
    "    return pd.DataFrame(store_preds,columns=[\"pr_0\",\"pr_1\",\"pred\"])\n",
    "\n",
    "# Run\n",
    "preds = predict_cont(train_cont,dist_locs)\n",
    "print(preds.head(10))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Calculate the model's predictive accuracy\n",
    "accuracy = sum(train_cont.vote == preds.pred)/train_cont.shape[0]\n",
    "print(f\"\"\"Training accuracy = {accuracy}\"\"\")\n",
    "\n",
    "cont_preds = predict_cont(test_cont, dist_locs)\n",
    "cont_accuracy = sum(test_cont.vote == cont_preds.pred)/test_cont.shape[0]\n",
    "print(f\"\"\"Test accuracy = {cont_accuracy}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fde23e",
   "metadata": {},
   "source": [
    "For continuous predictors, the classifier's accuracy when run on the test data was 70.7%, which is better still than chance (i.e. a coin flip.) The accuracy on the training data, which is more robust, was 73.1%, which is to be expected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
