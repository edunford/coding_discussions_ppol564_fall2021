{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e56db013",
   "metadata": {},
   "source": [
    "## Coding Discussion 04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "223667ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8834ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening article text files and stop words file and saving each to an object\n",
    "aljazeera = open(\"/Users/carolineadams/coding_discussions_ppol564_fall2021/04_coding_discussion/Data/aljazeera-khashoggi.txt\", \"r\")\n",
    "bbc=open(\"/Users/carolineadams/coding_discussions_ppol564_fall2021/04_coding_discussion/Data/bbc-khashoggi.txt\", \"r\")\n",
    "breitbart=open(\"/Users/carolineadams/coding_discussions_ppol564_fall2021/04_coding_discussion/Data/breitbart-khashoggi.txt\", \"r\")\n",
    "cnn=open(\"/Users/carolineadams/coding_discussions_ppol564_fall2021/04_coding_discussion/Data/cnn-khashoggi.txt\", \"r\")\n",
    "fox=open(\"/Users/carolineadams/coding_discussions_ppol564_fall2021/04_coding_discussion/Data/fox-khashoggi.txt\", \"r\")\n",
    "stop_words=pd.read_csv(\"/Users/carolineadams/coding_discussions_ppol564_fall2021/04_coding_discussion/Data/stop_words.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "168c7917",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_l=stop_words['word'].to_list() #creating a list of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38d330f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn each text file into a string\n",
    "aljazeera_str=aljazeera.read()\n",
    "bbc_str=bbc.read()\n",
    "breitbart_str=breitbart.read()\n",
    "cnn_str=cnn.read()\n",
    "fox_str=fox.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "468b867c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of all article strings\n",
    "texts=[]\n",
    "texts.append(aljazeera_str)\n",
    "texts.append(bbc_str)\n",
    "texts.append(breitbart_str)\n",
    "texts.append(cnn_str)\n",
    "texts.append(fox_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06b23864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn string of text into list of standardized words\n",
    "def tokenize(text=None):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, returns a list of the words in the string in lower case without punctuation.\n",
    "   \n",
    "    Arguments\n",
    "    --------------\n",
    "    text : a string of text\n",
    "    \n",
    "    Return\n",
    "    --------------\n",
    "    A list of the words in the string in lower case without punctuation.    \n",
    "    \"\"\"\n",
    "    text = text.lower()  #turning all letters in the string to lower case\n",
    "    text = text.replace('.','')  #removing periods\n",
    "    text = text.replace(\"(\", \"\")  #removing parenthesis\n",
    "    text = text.replace(\")\", \"\")  #removing parenthesis\n",
    "    text = text.replace(\"-\", \"\")  #removing dashes\n",
    "    text = text.replace(\",\", \"\")  #removing commas\n",
    "    text = text.replace(\"?\", \"\")  #removing question marks\n",
    "    text = text.replace(\"[\", \"\")  #removing brackets\n",
    "    text = text.replace(\"]\", \"\")  #removing brackets\n",
    "    text = text.replace('\"', \"\")  #removing quotation marks\n",
    "    text = text.replace(\"“\", \"\")  #removing quotation marks\n",
    "    text = text.replace(\"”\", \"\")  #removing quotation marks\n",
    "    text = text.replace(\"\\'\", \"\")  #removing back slashes\n",
    "    text = text.replace(\":\", \"\")  #removing colons\n",
    "    text_list = text.split()  #splitting the string by a space and turning each word into a value in a list\n",
    "    return text_list  #returning the split list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf30c69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn string of text into list of standardized words; excludes stop words\n",
    "def tokenize_no_stop(text=None):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, returns a list of the words in the string in lower case without punctuation; excludes stop words.\n",
    "   \n",
    "    Arguments\n",
    "    --------------\n",
    "    text : a string of text\n",
    "    \n",
    "    Return\n",
    "    --------------\n",
    "    A list of the words in the string in lower case without punctuation; excludes stop words.    \n",
    "    \"\"\"\n",
    "    text = text.lower()  #turning all letters in the string to lower case\n",
    "    text = text.replace('.','')  #removing periods\n",
    "    text = text.replace(\"(\", \"\")  #removing parenthesis\n",
    "    text = text.replace(\")\", \"\")  #removing parenthesis\n",
    "    text = text.replace(\"-\", \"\")  #removing dashes\n",
    "    text = text.replace(\",\", \"\")  #removing commas\n",
    "    text = text.replace(\"?\", \"\")  #removing question marks\n",
    "    text = text.replace(\"[\", \"\")  #removing brackets\n",
    "    text = text.replace(\"]\", \"\")  #removing brackets\n",
    "    text = text.replace('\"', \"\")  #removing quotation marks\n",
    "    text = text.replace(\"“\", \"\")  #removing quotation marks\n",
    "    text = text.replace(\"”\", \"\")  #removing quotation marks\n",
    "    text = text.replace(\":\", \"\")  #removing colons\n",
    "    text = text.replace(\"\\'\", \"\")  #removing back slashes\n",
    "    text_list = text.split()  #splitting the string by a space and turning each word into a value in a list\n",
    "    text_list2 = [word for word in text_list if word not in stop_words_l]  #removes stop words and creates a new list\n",
    "\n",
    "    return text_list2  #return the list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "430d5510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn string of text into list of standardized words; ; excludes stop words and numbers\n",
    "def tokenize_no_num(text=None):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, returns a list of the words in the string in lower case without punctuation, numbers or money signs; excludes stop words.\n",
    "   \n",
    "    Arguments\n",
    "    --------------\n",
    "    text : a string of text\n",
    "    \n",
    "    Return\n",
    "    --------------\n",
    "    A list of the words in the string in lower case without punctuation, numbers, or money signs; excludes stop words.    \n",
    "    \"\"\"\n",
    "    text = text.lower()  #turning all letters in the string to lower case\n",
    "    text = text.replace('.','')  #removing periods\n",
    "    text = text.replace(\"(\", \"\")  #removing parenthesis\n",
    "    text = text.replace(\")\", \"\")  #removing parenthesis\n",
    "    text = text.replace(\"-\", \"\")  #removing dashes\n",
    "    text = text.replace(\",\", \"\")  #removing commas\n",
    "    text = text.replace(\"?\", \"\")  #removing question marks\n",
    "    text = text.replace(\"[\", \"\")  #removing brackets\n",
    "    text = text.replace(\"]\", \"\")  #removing brackets\n",
    "    text = text.replace('\"', \"\")  #removing quotation marks\n",
    "    text = text.replace(\"“\", \"\")  #removing quotation marks\n",
    "    text = text.replace(\"”\", \"\")  #removing quotation marks\n",
    "    text = text.replace(\":\", \"\")  #removing colons\n",
    "    text = text.replace(\"\\'\", \"\")  #removing back slashes\n",
    "    text = text.replace('0','')  #removing instances of 0\n",
    "    text = text.replace('1','')  #removing instances of 1\n",
    "    text = text.replace(\"2\", \"\")  #removing instances of 2\n",
    "    text = text.replace(\"3\", \"\")  #removing instances of 3\n",
    "    text = text.replace(\"4\", \"\")  #removing instances of 4\n",
    "    text = text.replace(\"5\", \"\")  #removing instances of 5\n",
    "    text = text.replace(\"6\", \"\")  #removing instances of 6\n",
    "    text = text.replace(\"7\", \"\")  #removing instances of 7\n",
    "    text = text.replace(\"8\", \"\")  #removing instances of 8\n",
    "    text = text.replace('9', \"\")  #removing instances of 9\n",
    "    text = text.replace(\"10\", \"\")  #removing instances of 10\n",
    "    text = text.replace(\"$'\", \"\")  #removing instances of $\n",
    "    text = text.replace(\"£'\", \"\")  #removing instances of £\n",
    "    text_list = text.split()  #splitting the string by a space and turning each word into a value in a list\n",
    "    text_list2 = [word for word in text_list if word not in stop_words_l]  #removes stop words and creates a new list\n",
    "\n",
    "    return text_list2  #returning list of split words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "710eeee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert text into a document term matrix\n",
    "def convert_text_to_dtm(txt):\n",
    "    \"\"\"\n",
    "    Takes in a list of words, returns a dataframe that shows how frequently each word appeared in the list. \n",
    "   \n",
    "    Arguments\n",
    "    --------------\n",
    "    txt : a list of strings\n",
    "    \n",
    "    Return\n",
    "    --------------\n",
    "    A dataframe that shows how frequently each word appeared in the list.    \n",
    "    \"\"\"\n",
    "    d = dict()  #create an empty dictionary\n",
    "    for word in tokenize(txt):  #pass list through the tokenize function and iterate through words\n",
    "        if word in d:  #if word is in the dictionary\n",
    "            d[word][0] += 1  #add one to the value in the dictionary\n",
    "        else:  #if word isn't in the dictionary\n",
    "            d[word] = [1]  #if not in the dictionary, set the value to 1\n",
    "    return pd.DataFrame(d)  #return the dictionary as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c89436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert text into a document term matrix; excludes stop words\n",
    "def convert_text_to_dtm_no_stop(txt):\n",
    "    \"\"\"\n",
    "    Takes in a list of words, returns a dataframe that shows how frequently each word appeared in the list; excludes stop words. \n",
    "   \n",
    "    Arguments\n",
    "    --------------\n",
    "    txt : a list of strings\n",
    "    \n",
    "    Return\n",
    "    --------------\n",
    "    A dataframe that shows how frequently each word appeared in the list.    \n",
    "    \"\"\"\n",
    "    d = dict()  #create an empty dictionary\n",
    "    for word in tokenize_no_stop(txt):  #pass list through the tokenize function that excludes stop words and iterate through words\n",
    "        if word in d:  #if word is in the dictionary\n",
    "            d[word][0] += 1  #add one to the value in the dictionary\n",
    "        else:  #if word isn't in the dictionary\n",
    "            d[word] = [1]  #if not in the dictionary, set the value to 1\n",
    "    return pd.DataFrame(d)  #return the dictionary as a pandas dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05506ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert text into a document term matrix; excludes stop words and numbers\n",
    "def convert_text_to_dtm_no_num(txt):\n",
    "    \"\"\"\n",
    "    Takes in a list of words, returns a dataframe that shows how frequently each word appeared in the list; excludes stop words and numbers. \n",
    "   \n",
    "    Arguments\n",
    "    --------------\n",
    "    txt : a list of strings\n",
    "    \n",
    "    Return\n",
    "    --------------\n",
    "    A dataframe that shows how frequently each word appeared in the list.    \n",
    "    \"\"\"\n",
    "    d = dict()  #create an empty dictionary\n",
    "    for word in tokenize_no_num(txt):  #pass list through the tokenize function that excludes stop words and numbers and iterate through words\n",
    "        if word in d:  #if word is in the dictionary\n",
    "            d[word][0] += 1  #add one to the value in the dictionary\n",
    "        else:  #if word isn't in the dictionary\n",
    "            d[word] = [1]  #if not in the dictionary, set the value to 1\n",
    "    return pd.DataFrame(d)  #return the dictionary as a pandas dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e4def6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a document term matrix for a list of texts\n",
    "def gen_DTM(texts=None):\n",
    "    \"\"\"\n",
    "    Takes in a nested list including lists of words, returns a combined dataframe that shows how frequently each word that was used in any list appeared in each list. \n",
    "   \n",
    "    Arguments\n",
    "    --------------\n",
    "    texts : a nested list containing lists of strings\n",
    "    \n",
    "    Return\n",
    "    --------------\n",
    "    A dataframe that shows how frequently each word that was used in any list appeared in each list.   \n",
    "    \"\"\"\n",
    "    DTM = pd.DataFrame()  #create an empty pandas dataframe\n",
    "    for text in texts:  #iterate through the nested list\n",
    "        entry = convert_text_to_dtm(text)  #convert each list of words to a dataframe of freqencies\n",
    "        DTM = DTM.append(pd.DataFrame(entry),ignore_index=True,sort=True) #append a new row to the new dataframe\n",
    "    \n",
    "    DTM.fillna(0, inplace=True) # Fill in any missing values with 0s (i.e. when a word is in one text but not another)\n",
    "\n",
    "    return DTM  #return the combined dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bd50899",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a document term matrix for a list of texts; exclude stop words\n",
    "def gen_DTM_no_stop(texts=None):\n",
    "    \"\"\"\n",
    "    Takes in a nested list including lists of words, returns a combined dataframe that shows how frequently each word that was used in any list appeared in each list; excludes stop words. \n",
    "   \n",
    "    Arguments\n",
    "    --------------\n",
    "    texts : a nested list containing lists of strings\n",
    "    \n",
    "    Return\n",
    "    --------------\n",
    "    A dataframe that shows how frequently each word that was used in any list appeared in each list.   \n",
    "    \"\"\"\n",
    "    DTM = pd.DataFrame()  #create an empty pandas dataframe\n",
    "    for text in texts:  #iterate through the nested list\n",
    "        entry = convert_text_to_dtm_no_stop(text)  #convert each list of words to a dataframe of freqencies\n",
    "        DTM = DTM.append(pd.DataFrame(entry),ignore_index=True,sort=True) #append a new row to the new dataframe\n",
    "    \n",
    "    DTM.fillna(0, inplace=True) # Fill in any missing values with 0s (i.e. when a word is in one text but not another)\n",
    "\n",
    "    return DTM  #return the combined dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3c7dd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a document term matrix for a list of texts; exclude stop words and numbers\n",
    "def gen_DTM_no_num(texts=None):\n",
    "    \"\"\"\n",
    "    Takes in a nested list including lists of words, returns a combined dataframe that shows how frequently each word that was used in any list appeared in each list; excludes stop words and numbers. \n",
    "   \n",
    "    Arguments\n",
    "    --------------\n",
    "    texts : a nested list containing lists of strings\n",
    "    \n",
    "    Return\n",
    "    --------------\n",
    "    A dataframe that shows how frequently each word that was used in any list appeared in each list.   \n",
    "    \"\"\"\n",
    "    DTM = pd.DataFrame()  #create an empty pandas dataframe\n",
    "    for text in texts:  #iterate through the nested list\n",
    "        entry = convert_text_to_dtm_no_num(text)  #convert each list of words to a dataframe of freqencies\n",
    "        DTM = DTM.append(pd.DataFrame(entry),ignore_index=True,sort=True) #append a new row to the new dataframe\n",
    "    \n",
    "    DTM.fillna(0, inplace=True) # Fill in any missing values with 0s (i.e. when a word is in one text but not another)\n",
    "\n",
    "    return DTM  #return the combined dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb9f2652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the gen_DTM function on the list of texts\n",
    "article_d=gen_DTM(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b1a23d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the gen_DTM_no_stop function on the list of texts (excludes stop words)\n",
    "article_d_no_stop=gen_DTM_no_stop(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ff49422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the gen_DTM_no_stop function on the list of texts (excludes stop words and numbers)\n",
    "article_d_no_num=gen_DTM_no_num(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cba21294",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating objects for the row of data corresponding to each individual article (including stop words and numbers)\n",
    "alj = article_d.iloc[0].values\n",
    "bb = article_d.iloc[1].values\n",
    "br= article_d.iloc[2].values\n",
    "cn= article_d.iloc[3].values\n",
    "fo= article_d.iloc[4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e086663",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating objects for the row of data corresponding to each individual article (excluding stop words but not numbers)\n",
    "alj_no_stop = article_d_no_stop.iloc[0].values\n",
    "bb_no_stop = article_d_no_stop.iloc[1].values\n",
    "br_no_stop= article_d_no_stop.iloc[2].values\n",
    "cn_no_stop= article_d_no_stop.iloc[3].values\n",
    "fo_no_stop= article_d_no_stop.iloc[4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8816600",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating objects for the row of data corresponding to each individual article (excluding stop words and numbers)\n",
    "alj_no_num = article_d_no_stop.iloc[0].values\n",
    "bb_no_num = article_d_no_stop.iloc[1].values\n",
    "br_no_num= article_d_no_stop.iloc[2].values\n",
    "cn_no_num= article_d_no_stop.iloc[3].values\n",
    "fo_no_num= article_d_no_stop.iloc[4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce8ec00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a function to calculate the angle between two vectors\n",
    "def cosine(a,b):\n",
    "    \"\"\"\n",
    "    Takes in two vectors of data, returns a value that describes the angle between the two vectors. \n",
    "    \n",
    "    Arguments\n",
    "    --------------\n",
    "    a : a vector\n",
    "    b : a vector\n",
    "    \n",
    "    Return\n",
    "    --------------\n",
    "    The angle between the two vectors.   \n",
    "    \"\"\"    \n",
    "    cos = np.dot(a,b)/(np.sqrt(np.dot(a,a)) * np.sqrt(np.dot(b,b))) #calculating the angle between two vectors a and b\n",
    "    return cos  #returning the cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984beb13",
   "metadata": {},
   "source": [
    "#### Calculating similarity between different articles; first, including all words, second excluding stop words, and third, excluding stop words and numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2252a7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.736611067369947 0.5173215975276089 0.5173215975276089\n"
     ]
    }
   ],
   "source": [
    "#calculating the similarity between CNN and Fox News\n",
    "print(cosine(cn,fo), cosine(cn_no_stop,fo_no_stop), cosine(cn_no_num,fo_no_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53d85add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7440412240226454 0.5039192189493414 0.5039192189493414\n"
     ]
    }
   ],
   "source": [
    "#calculating the similarity between CNN and BBC\n",
    "print(cosine(cn,bb), cosine(cn_no_stop,bb_no_stop), cosine(cn_no_num,bb_no_num)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f018933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8671739848772201 0.5470292918958526 0.5470292918958526\n"
     ]
    }
   ],
   "source": [
    "#calculating the similarity between Breitbart and Fox News\n",
    "print(cosine(br,fo), cosine(br_no_stop,fo_no_stop), cosine(br_no_num,fo_no_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1abbc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7346592558334714 0.5331228099011469 0.5331228099011469\n"
     ]
    }
   ],
   "source": [
    "#calculating the similarity between CNN and Aljazeera\n",
    "print(cosine(cn,alj), cosine(cn_no_stop,alj_no_stop), cosine(cn_no_num,alj_no_num)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebdbe0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8704785650109934 0.6789384344078828 0.6789384344078828\n"
     ]
    }
   ],
   "source": [
    "#calculating the similarity between Aljazeera and BBC\n",
    "print(cosine(alj,bb), cosine(alj_no_stop,bb_no_stop), cosine(alj_no_num,bb_no_num)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a94f4d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8969720949048929 0.5816310433433123 0.5816310433433123\n"
     ]
    }
   ],
   "source": [
    "#calculating the similarity between Breitbart and BBC\n",
    "print(cosine(bb,br), cosine(bb_no_stop,br_no_stop), cosine(bb_no_num,br_no_num)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91f5a4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8365576738176702 0.5840012756971252 0.5840012756971252\n"
     ]
    }
   ],
   "source": [
    "#calculating the similarity between Aljazeera and Breitbart\n",
    "print(cosine(alj,br), cosine(alj_no_stop,br_no_stop), cosine(alj_no_num,br_no_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3bf6d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8867032233742135 0.6277433633605314 0.6277433633605314\n"
     ]
    }
   ],
   "source": [
    "#calculating the similarity between BBC and Fox News\n",
    "print(cosine(fo,bb), cosine(fo_no_stop,bb_no_stop), cosine(fo_no_num,bb_no_num)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc9e78e",
   "metadata": {},
   "source": [
    "Without removing stop words, it appears that the different news outlets reported on the murder of journalist Jamal Khashoggi pretty similarly. All articles were more similar to each other with stop words included than when stop words were removed, which is unsurprising. When stop words were included, BBC and Breitbart had the most similar article, followed by BBC and Fox News. The two least similar articles were CNN and Al Jazeera. Given that Fox News and Breitbart are more conservative news outlets and BBC is pretty neutral, this is surprising.\n",
    "\n",
    "When stop words were removed, there was a large decrease in similarity between most articles, indicating that the stop words were substantially contributing to the high similarities previously. Without stop words included, Al Jazeera and BBC published articles that were most similar to each other. The most dissimilar articles were CNN and BBC and CNN and Fox News. \n",
    "\n",
    "When also removing numbers from the text, the cosine similarity values did not change from when just the stop words were removed. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
