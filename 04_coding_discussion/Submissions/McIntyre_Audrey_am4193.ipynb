{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69306d0d",
   "metadata": {},
   "source": [
    "# Coding Discussion 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9c83673",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in packages\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c915ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/aljazeera-khashoggi.txt') as f:\n",
    "    alj = f.read()\n",
    "\n",
    "with open('../Data/BBC-khashoggi.txt') as f:\n",
    "    bbc = f.read()\n",
    "    \n",
    "with open('../Data/breitbart-khashoggi.txt', encoding='utf8') as f:\n",
    "    bre = f.read()\n",
    "    \n",
    "with open('../Data/fox-khashoggi.txt', encoding='utf8') as f:\n",
    "    fox = f.read()\n",
    "    \n",
    "with open('../Data/cnn-khashoggi.txt') as f:\n",
    "    cnn = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff6f593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text=None):\n",
    "    \"\"\"\n",
    "    tokenize converts text into a list of words while removing non-letter characters.\n",
    "    It takes a string and returns a list of strings.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = text.replace('.',' ')\n",
    "    text = text.replace(',', ' ')\n",
    "    text = text.replace('(', ' ')\n",
    "    text = text.replace(')', ' ')\n",
    "    text = text.replace(\"’\", ' ')\n",
    "    text = text.replace(\"'\", ' ')\n",
    "    text = text.replace(':', ' ')\n",
    "    text = text.replace('“', ' ')\n",
    "    text = text.replace('”', ' ')\n",
    "    text = text.replace('—', ' ')\n",
    "    text = text.replace('\"', ' ')\n",
    "    text = text.replace('[', ' ')\n",
    "    text = text.replace(']', ' ')\n",
    "    text = text.replace('?', ' ')\n",
    "    text = text.replace('!',' ')\n",
    "    text = text.replace('/',' ')\n",
    "    text = text.replace('\\\\', ' ')\n",
    "    text = text.replace('-', ' ')\n",
    "    text = text.replace('$', '')\n",
    "    text = text.replace('£', '')\n",
    "    text = text.replace('0', '')\n",
    "    text = text.replace('1', '')\n",
    "    text = text.replace('2', '')\n",
    "    text = text.replace('3', '')\n",
    "    text = text.replace('4', '')\n",
    "    text = text.replace('5', '')\n",
    "    text = text.replace('6', '')\n",
    "    text = text.replace('7', '')\n",
    "    text = text.replace('8', '')\n",
    "    text = text.replace('9', '')\n",
    "    text_list = text.split()\n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de1a8269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_dtm(txt):\n",
    "    '''\n",
    "    Converts text into a document term matrix.\n",
    "    '''\n",
    "    d = dict()\n",
    "    for word in tokenize(txt):\n",
    "        if word in d:\n",
    "            d[word][0] += 1\n",
    "        else:\n",
    "            d[word] = [1]\n",
    "    return pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77d6b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_DTM(texts=None):\n",
    "    '''\n",
    "    Generate a document term matrix\n",
    "    '''\n",
    "    DTM = pd.DataFrame()\n",
    "    for text in texts:\n",
    "        entry = convert_text_to_dtm(text)\n",
    "        DTM = DTM.append(pd.DataFrame(entry),ignore_index=True,sort=True) # Row bind\n",
    "    \n",
    "    DTM.fillna(0, inplace=True) # Fill in any missing values with 0s (i.e. when a word is in one text but not another)\n",
    "    return DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cfcfded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>abdulaziz</th>\n",
       "      <th>able</th>\n",
       "      <th>about</th>\n",
       "      <th>absent</th>\n",
       "      <th>accident</th>\n",
       "      <th>accidentally</th>\n",
       "      <th>according</th>\n",
       "      <th>account</th>\n",
       "      <th>accounts</th>\n",
       "      <th>...</th>\n",
       "      <th>world</th>\n",
       "      <th>worse</th>\n",
       "      <th>would</th>\n",
       "      <th>writer</th>\n",
       "      <th>yalova</th>\n",
       "      <th>year</th>\n",
       "      <th>yelova</th>\n",
       "      <th>yet</th>\n",
       "      <th>your</th>\n",
       "      <th>â</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 860 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    a  abdulaziz  able  about  absent  accident  accidentally  according  \\\n",
       "0  11        0.0   0.0      2     0.0       0.0           0.0        0.0   \n",
       "1  23        0.0   0.0      2     1.0       0.0           0.0        1.0   \n",
       "2  11        2.0   0.0      2     0.0       0.0           1.0        1.0   \n",
       "3  16        0.0   0.0      4     0.0       0.0           0.0        1.0   \n",
       "4  14        0.0   1.0      1     0.0       1.0           1.0        0.0   \n",
       "\n",
       "   account  accounts  ...  world  worse  would  writer  yalova  year  yelova  \\\n",
       "0      0.0       0.0  ...    0.0    0.0    1.0     0.0     0.0   0.0     0.0   \n",
       "1      1.0       2.0  ...    1.0    0.0    4.0     0.0     0.0   1.0     0.0   \n",
       "2      1.0       0.0  ...    1.0    0.0    1.0     0.0     0.0   0.0     0.0   \n",
       "3      0.0       0.0  ...    0.0    1.0    2.0     2.0     0.0   0.0     1.0   \n",
       "4      0.0       0.0  ...    0.0    0.0    0.0     0.0     1.0   0.0     0.0   \n",
       "\n",
       "   yet  your    â  \n",
       "0  0.0   0.0  0.0  \n",
       "1  0.0   3.0  1.0  \n",
       "2  1.0   0.0  0.0  \n",
       "3  0.0   0.0  0.0  \n",
       "4  1.0   0.0  0.0  \n",
       "\n",
       "[5 rows x 860 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = gen_DTM([alj, bbc, bre, fox, cnn])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "133015fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_fun(x,y):\n",
    "    \"\"\"\n",
    "    cosine_fun takes two arrays and finds the cosine \n",
    "    \"\"\"\n",
    "    cos= (np.dot(x,y)/( np.sqrt(np.dot(x,x)) * np.sqrt(np.dot(y,y)) ))\n",
    "    return cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab87a971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alj</th>\n",
       "      <th>bbc</th>\n",
       "      <th>bre</th>\n",
       "      <th>cnn</th>\n",
       "      <th>fox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alj</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.874243</td>\n",
       "      <td>0.841171</td>\n",
       "      <td>0.847628</td>\n",
       "      <td>0.765426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbc</th>\n",
       "      <td>0.874243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900848</td>\n",
       "      <td>0.891444</td>\n",
       "      <td>0.759504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bre</th>\n",
       "      <td>0.841171</td>\n",
       "      <td>0.900848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869250</td>\n",
       "      <td>0.703809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn</th>\n",
       "      <td>0.847628</td>\n",
       "      <td>0.891444</td>\n",
       "      <td>0.869250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.768582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox</th>\n",
       "      <td>0.765426</td>\n",
       "      <td>0.759504</td>\n",
       "      <td>0.703809</td>\n",
       "      <td>0.768582</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          alj       bbc       bre       cnn       fox\n",
       "alj  1.000000  0.874243  0.841171  0.847628  0.765426\n",
       "bbc  0.874243  1.000000  0.900848  0.891444  0.759504\n",
       "bre  0.841171  0.900848  1.000000  0.869250  0.703809\n",
       "cnn  0.847628  0.891444  0.869250  1.000000  0.768582\n",
       "fox  0.765426  0.759504  0.703809  0.768582  1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a dictionary for each article as an array of its values\n",
    "ndict = {'alj':df.iloc[0].values,\n",
    "'bbc':df.iloc[1].values,\n",
    "'bre':df.iloc[2].values,\n",
    "'cnn':df.iloc[3].values,\n",
    "'fox':df.iloc[4].values}\n",
    "#turning dictionary into a new data frame \n",
    "ndf = pd.DataFrame(ndict)\n",
    "#finding the cosines for each pair of articles using the correlation command\n",
    "cosines = ndf.corr(method=cosine_fun)\n",
    "cosines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10100440",
   "metadata": {},
   "source": [
    "With stop words included but non-letter characters removed, these articles seem fairly similar. Fox has the fewest similiarities to other articles. Brietbart and the BBC talk abuot the scandal in the most similar ways, while Breitbart and Fox are most dissimilar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16d10613",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in stop words and formatting them as a list\n",
    "stopwords = pd.read_csv(\"../Data/stop_words.csv\")\n",
    "stopwords = stopwords['word'].tolist()\n",
    "\n",
    "\n",
    "#rewriting tokenize function to exclude stop words \n",
    "def tokenize_stop(text=None):\n",
    "    \"\"\"\n",
    "    tokenize converts text into a list of words while removing non-letter characters.\n",
    "    It takes a string and returns a list of strings.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = text.replace('.',' ')\n",
    "    text = text.replace(',', ' ')\n",
    "    text = text.replace('(', ' ')\n",
    "    text = text.replace(')', ' ')\n",
    "    text = text.replace(\"’\", ' ')\n",
    "    text = text.replace(\"'\", ' ')\n",
    "    text = text.replace(':', ' ')\n",
    "    text = text.replace('“', ' ')\n",
    "    text = text.replace('”', ' ')\n",
    "    text = text.replace('—', ' ')\n",
    "    text = text.replace('\"', ' ')\n",
    "    text = text.replace('[', ' ')\n",
    "    text = text.replace(']', ' ')\n",
    "    text = text.replace('?', ' ')\n",
    "    text = text.replace('!',' ')\n",
    "    text = text.replace('/',' ')\n",
    "    text = text.replace('\\\\', ' ')\n",
    "    text = text.replace('-', ' ')\n",
    "    text = text.replace('$', '')\n",
    "    text = text.replace('£', '')\n",
    "    text = text.replace('0', '')\n",
    "    text = text.replace('1', '')\n",
    "    text = text.replace('2', '')\n",
    "    text = text.replace('3', '')\n",
    "    text = text.replace('4', '')\n",
    "    text = text.replace('5', '')\n",
    "    text = text.replace('6', '')\n",
    "    text = text.replace('7', '')\n",
    "    text = text.replace('8', '')\n",
    "    text = text.replace('9', '')\n",
    "    text_list = text.split()\n",
    "    text_list2 = [word for word in text_list if word not in stopwords]\n",
    "    return text_list2\n",
    "\n",
    "#new convert text to dtm function to exclude stop words\n",
    "def convert_text_to_dtm_stop(txt):\n",
    "    '''\n",
    "    Converts text into a document term matrix.\n",
    "    '''\n",
    "    d = dict()\n",
    "    for word in tokenize_stop(txt):\n",
    "        if word in d:\n",
    "            d[word][0] += 1\n",
    "        else:\n",
    "            d[word] = [1]\n",
    "    return pd.DataFrame(d)\n",
    "\n",
    "\n",
    "#new document term matrix function to exlude stop words\n",
    "def gen_DTM_stop(texts=None):\n",
    "    '''\n",
    "    Generate a document term matrix\n",
    "    '''\n",
    "    DTM = pd.DataFrame()\n",
    "    for text in texts:\n",
    "        entry = convert_text_to_dtm_stop(text)\n",
    "        DTM = DTM.append(pd.DataFrame(entry),ignore_index=True,sort=True) # Row bind\n",
    "    \n",
    "    DTM.fillna(0, inplace=True) # Fill in any missing values with 0s (i.e. when a word is in one text but not another)\n",
    "    return DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fbdfc5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abdulaziz</th>\n",
       "      <th>absent</th>\n",
       "      <th>accident</th>\n",
       "      <th>accidentally</th>\n",
       "      <th>account</th>\n",
       "      <th>accounts</th>\n",
       "      <th>accusation</th>\n",
       "      <th>accusing</th>\n",
       "      <th>acknowledged</th>\n",
       "      <th>added</th>\n",
       "      <th>...</th>\n",
       "      <th>white</th>\n",
       "      <th>widely</th>\n",
       "      <th>withheld</th>\n",
       "      <th>woods</th>\n",
       "      <th>world</th>\n",
       "      <th>worse</th>\n",
       "      <th>writer</th>\n",
       "      <th>yalova</th>\n",
       "      <th>yelova</th>\n",
       "      <th>â</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 625 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abdulaziz  absent  accident  accidentally  account  accounts  accusation  \\\n",
       "0        0.0     0.0       0.0           0.0      0.0       0.0         0.0   \n",
       "1        0.0     1.0       0.0           0.0      1.0       2.0         0.0   \n",
       "2        2.0     0.0       0.0           1.0      1.0       0.0         1.0   \n",
       "3        0.0     0.0       0.0           0.0      0.0       0.0         0.0   \n",
       "4        0.0     0.0       1.0           1.0      0.0       0.0         0.0   \n",
       "\n",
       "   accusing  acknowledged  added  ...  white  widely  withheld  woods  world  \\\n",
       "0       1.0           0.0    2.0  ...    0.0     0.0       0.0    0.0    0.0   \n",
       "1       0.0           1.0    1.0  ...    0.0     1.0       0.0    0.0    1.0   \n",
       "2       1.0           0.0    1.0  ...    1.0     0.0       1.0    0.0    1.0   \n",
       "3       0.0           0.0    0.0  ...    0.0     0.0       0.0    1.0    0.0   \n",
       "4       0.0           0.0    0.0  ...    0.0     0.0       0.0    0.0    0.0   \n",
       "\n",
       "   worse  writer  yalova  yelova    â  \n",
       "0    0.0     0.0     0.0     0.0  0.0  \n",
       "1    0.0     0.0     0.0     0.0  1.0  \n",
       "2    0.0     0.0     0.0     0.0  0.0  \n",
       "3    1.0     2.0     0.0     1.0  0.0  \n",
       "4    0.0     0.0     1.0     0.0  0.0  \n",
       "\n",
       "[5 rows x 625 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = gen_DTM_stop([alj, bbc, bre, fox, cnn])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da66c28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alj</th>\n",
       "      <th>bbc</th>\n",
       "      <th>bre</th>\n",
       "      <th>cnn</th>\n",
       "      <th>fox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alj</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704096</td>\n",
       "      <td>0.601929</td>\n",
       "      <td>0.721042</td>\n",
       "      <td>0.610199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbc</th>\n",
       "      <td>0.704096</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622375</td>\n",
       "      <td>0.694799</td>\n",
       "      <td>0.551647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bre</th>\n",
       "      <td>0.601929</td>\n",
       "      <td>0.622375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.582348</td>\n",
       "      <td>0.424620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn</th>\n",
       "      <td>0.721042</td>\n",
       "      <td>0.694799</td>\n",
       "      <td>0.582348</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.608453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox</th>\n",
       "      <td>0.610199</td>\n",
       "      <td>0.551647</td>\n",
       "      <td>0.424620</td>\n",
       "      <td>0.608453</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          alj       bbc       bre       cnn       fox\n",
       "alj  1.000000  0.704096  0.601929  0.721042  0.610199\n",
       "bbc  0.704096  1.000000  0.622375  0.694799  0.551647\n",
       "bre  0.601929  0.622375  1.000000  0.582348  0.424620\n",
       "cnn  0.721042  0.694799  0.582348  1.000000  0.608453\n",
       "fox  0.610199  0.551647  0.424620  0.608453  1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a dictionary for each article as an array of its values\n",
    "ndict2 = {'alj':df2.iloc[0].values,\n",
    "'bbc':df2.iloc[1].values,\n",
    "'bre':df2.iloc[2].values,\n",
    "'cnn':df2.iloc[3].values,\n",
    "'fox':df2.iloc[4].values}\n",
    "#turning dictionary into a new data frame \n",
    "ndf2 = pd.DataFrame(ndict2)\n",
    "#finding the cosines for each pair of articles using the correlation command\n",
    "unstoppedcosines = ndf2.corr(method=cosine_fun)\n",
    "unstoppedcosines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85d41f1",
   "metadata": {},
   "source": [
    "Without stop words included, the articles are overall less similar to each other. Fox and Breitbart are still the most dissimilar, but Breitbart andd the BBC are no longer very similar. Instead, CNN and Aljazeera are the most similar among articles. \n",
    "\n",
    "Although removing stop words has decreased the similarity between these articles, using sentiment analysis would be helpful to pinpoint how similar or dissimilar they truly are. Additionally, removing words that are essential to the story but do not carry emotional information (such as names) may help in further exploring similarities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
