{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPOL564 | Data Science 1: Foundations | Coding discussion 04\n",
    "####  Alvaro Altamirano Montoya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 : Import Libraries, set WD, and load files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['always', 'am', 'among', 'amongst', 'an', 'and', 'another', 'any', 'anybody']\n"
     ]
    }
   ],
   "source": [
    "# 1.1 Importing required libraries\n",
    "import numpy as np, pandas as pd, os\n",
    "\n",
    "# 1.2 Set paths and read txt files\n",
    "path1 = r'C:\\Users\\unily\\Documents\\Georgetown\\PPOL 564 - Intro to Data Science\\Coding discussions\\4\\texts'\n",
    "os.chdir(path1) # Set WD\n",
    "# Read all .txt files and save them into a dictionary\n",
    "texts = {}\n",
    "for path, subdirs, files in os.walk(path1):\n",
    "    for name in files:\n",
    "        f = open(name, 'r', encoding = 'utf-8', newline = '')\n",
    "        texts[name] = f.readline()\n",
    "\n",
    "# 1.3 Loading/defining stopwords\n",
    "path2 = r'C:\\Users\\unily\\Documents\\Georgetown\\PPOL 564 - Intro to Data Science\\Coding discussions\\4'\n",
    "os.chdir(path2)\n",
    "stopwords = pd.read_csv('stop_words.csv')['word'].tolist()\n",
    "print(stopwords[23:32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['aljazeera-khashoggi.txt', 'bbc-khashoggi.txt', 'breitbart-khashoggi.txt', 'cnn-khashoggi.txt', 'fox-khashoggi.txt'])\n"
     ]
    }
   ],
   "source": [
    "print(texts.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2: Tokenization, DTM, and cosine functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Tokenizer function\n",
    "def tokenizeText(text = None):\n",
    "    '''\n",
    "    tokenizeText tokenizes the text and breaks up into single words and removes stopwords\n",
    "    ----------------------------\n",
    "    Args: \n",
    "    A string 'text' with default value as None\n",
    "    ----------------------------\n",
    "    Output:\n",
    "    Word-Tokenized strings with stopwords removal\n",
    "    '''\n",
    "    tokens = text.lower().split()\n",
    "    tokens = [tok for tok in tokens if tok not in stopwords]\n",
    "    return tokens\n",
    "\n",
    "#### Text to DTM function\n",
    "def convert_text_to_dtm(txt):\n",
    "    '''\n",
    "    convert_text_to_dtm converts ingested text into a document term matrix.\n",
    "    ----------------------------\n",
    "    Args: \n",
    "    Applies Tokenization function to 'txt' document.\n",
    "    ----------------------------\n",
    "    Output:\n",
    "    Term-frequency matrix\n",
    "    '''\n",
    "    d = dict()\n",
    "    for word in tokenizeText(txt):\n",
    "        if word in d:\n",
    "            d[word][0] += 1\n",
    "        else:\n",
    "            d[word] = [1]\n",
    "    return pd.DataFrame(d)\n",
    "\n",
    "#### DTM function\n",
    "def gen_DTM(texts=None):\n",
    "    '''\n",
    "    gen_DTM generates a document term matrix from a string input\n",
    "    ----------------------------\n",
    "    Args: \n",
    "    A string object\n",
    "    ----------------------------\n",
    "    Output:\n",
    "    Dcoument term frequency matrix\n",
    "    '''\n",
    "    DTM = pd.DataFrame()\n",
    "    for text in texts:\n",
    "        entry = convert_text_to_dtm(text)\n",
    "        DTM = DTM.append(pd.DataFrame(entry),ignore_index=True,sort=True) # Row bind\n",
    "    \n",
    "    DTM.fillna(0, inplace=True) # Fill in any missing values with 0s (i.e. when a word is in one text but not another)\n",
    "    return DTM \n",
    "\n",
    "#### Cosine distance function\n",
    "def cosine(a,b):\n",
    "    '''\n",
    "    Calculates cosine distance\n",
    "    ----------------------------\n",
    "    Args: \n",
    "    A set of string documents in this case\n",
    "    ----------------------------\n",
    "    Output:\n",
    "    Cosine distance coefficients\n",
    "    '''\n",
    "    cos = np.dot(a,b)/(np.sqrt(np.dot(a,a)) * np.sqrt(np.dot(b,b))  )\n",
    "    return cos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply gen_DTM function on all texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gen_DTM(texts.values())\n",
    "df.index  = files\n",
    "# Data wrangling\n",
    "df = df.T.reset_index() \n",
    "df.columns.name = None\n",
    "del df['index']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Does each news site report on these stories in a similar way?\n",
    "\n",
    "#### They report the topic using similar observations, but with different language and focus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Aljazeera   BBC  Breitbart   CNN   FOX\n",
      "Aljazeera       1.00  0.61       0.50  0.50  0.59\n",
      "BBC             0.61  1.00       0.51  0.46  0.54\n",
      "Breitbart       0.50  0.51       1.00  0.33  0.47\n",
      "CNN             0.50  0.46       0.33  1.00  0.48\n",
      "FOX             0.59  0.54       0.47  0.48  1.00\n"
     ]
    }
   ],
   "source": [
    "# Renaming the columns\n",
    "df = df.rename(columns = {'aljazeera-khashoggi.txt' : 'Aljazeera',\n",
    "        'bbc-khashoggi.txt' : 'BBC', 'breitbart-khashoggi.txt' : 'Breitbart',\n",
    "        'cnn-khashoggi.txt' : 'CNN', 'fox-khashoggi.txt' : 'FOX'})\n",
    "\n",
    "corr_matrix = df.corr(method=cosine)\n",
    "print(corr_matrix.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Which news sites talk about the Khashoggi scandal in similar/dissimilar ways? \n",
    "#### According to the previous matrix, the BBC and Aljazeera's texts are the two most similar. On the other hand, CNN and Breitbart are the most dissimilar pair according to their cosine distances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Aljazeera   BBC  Breitbart   CNN   FOX\n",
      "Aljazeera       1.00  0.86       0.82  0.73  0.83\n",
      "BBC             0.86  1.00       0.89  0.74  0.89\n",
      "Breitbart       0.82  0.89       1.00  0.69  0.87\n",
      "CNN             0.73  0.74       0.69  1.00  0.74\n",
      "FOX             0.83  0.89       0.87  0.74  1.00\n"
     ]
    }
   ],
   "source": [
    "#### Tokenizer function without removal of stopwords\n",
    "def tokenizeText(text = None):\n",
    "    '''\n",
    "    Tonkenizes the text and breaks up into single words\n",
    "    ----------------------------\n",
    "    Args: \n",
    "    A string 'text' with default value as None\n",
    "    ----------------------------\n",
    "    Output:\n",
    "    Word-Tokenized strings\n",
    "    '''\n",
    "    tokens = text.lower().split()\n",
    "    return tokens\n",
    "\n",
    "#### Apply gen_DTM function on all texts using NEW tokenization function (without stopwords)\n",
    "df = gen_DTM(texts.values())\n",
    "df.index  = files\n",
    "# Data wrangling\n",
    "df = df.T.reset_index() \n",
    "df.columns.name = None\n",
    "\n",
    "# Renaming the columns\n",
    "df = df.rename(columns = {'aljazeera-khashoggi.txt' : 'Aljazeera',\n",
    "        'bbc-khashoggi.txt' : 'BBC', 'breitbart-khashoggi.txt' : 'Breitbart',\n",
    "        'cnn-khashoggi.txt' : 'CNN', 'fox-khashoggi.txt' : 'FOX'})\n",
    "\n",
    "corr_matrix = df.corr(method=cosine)\n",
    "print(corr_matrix.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: If you change what words you remove, does the picture of similarity change?\n",
    "#### Not removing the stopwords, as shown in this last correlation table results in higher-than-actual cosine similarities, given the share load of stopwords each .txt had."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
