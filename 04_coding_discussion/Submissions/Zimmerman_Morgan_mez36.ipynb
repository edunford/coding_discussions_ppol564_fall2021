{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d4a37a3",
   "metadata": {},
   "source": [
    "# Coding Discussion #4\n",
    "#### Morgan Zimmerman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "0a9267a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "cd0119e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in aljazeera-khashoggi.txt as lines1\n",
    "with open('/Users/morganzimmerman/Desktop/GitHub/coding_discussions_ppol564_fall2021/04_coding_discussion/Data/aljazeera-khashoggi.txt') as aljazeera:\n",
    "    story1 = aljazeera.read()\n",
    "    \n",
    "# Read in bbc-khashoggi.txt as lines2\n",
    "with open('/Users/morganzimmerman/Desktop/GitHub/coding_discussions_ppol564_fall2021/04_coding_discussion/Data/bbc-khashoggi.txt') as bbc:\n",
    "    story2 = bbc.read()\n",
    "\n",
    "# Read in breitbart-khashoggi.txt as lines3\n",
    "with open('/Users/morganzimmerman/Desktop/GitHub/coding_discussions_ppol564_fall2021/04_coding_discussion/Data/breitbart-khashoggi.txt') as breitbart:\n",
    "    story3 = breitbart.read()\n",
    "\n",
    "# Read in cnn-khashoggi.txt as lines4\n",
    "with open('/Users/morganzimmerman/Desktop/GitHub/coding_discussions_ppol564_fall2021/04_coding_discussion/Data/cnn-khashoggi.txt') as cnn:\n",
    "    story4 = cnn.read()\n",
    "\n",
    "# Read in fox-khashoggi.txt as lines5\n",
    "with open('/Users/morganzimmerman/Desktop/GitHub/coding_discussions_ppol564_fall2021/04_coding_discussion/Data/fox-khashoggi.txt') as fox:\n",
    "    story5 = fox.read()\n",
    "    \n",
    "# Import stop_words file\n",
    "stop_words = pd.read_csv('/Users/morganzimmerman/Desktop/GitHub/coding_discussions_ppol564_fall2021/04_coding_discussion/Data/stop_words.csv')\n",
    "stop_words_list = stop_words['word'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "68570314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list to store all stories\n",
    "text = [story1, story2, story3, story4, story5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "64b73beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text=None):\n",
    "    '''\n",
    "    This function takes a string of text and ouputs a list of all words from the string in lowercase and without any punctuation or numbers.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    str: string of text\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    list: list of all words from the string in lowercase and without any punctuation or numbers.\n",
    "    '''\n",
    "    text = text.lower()\n",
    "    text = text.replace('.',' ') # Removes periods\n",
    "    text = text.replace('!',' ') # Removes exclamation points\n",
    "    text = text.replace('?',' ') # Removes question marks\n",
    "    text = text.replace(',',' ') # Removes commas\n",
    "    text = text.replace('(',' ') # Removes left parentheses\n",
    "    text = text.replace(')',' ') # Removes right parentheses\n",
    "    text = text.replace('[',' ') # Removes left square brackets\n",
    "    text = text.replace(']',' ') # Removes right square brackets\n",
    "    text = text.replace(';',' ') # Removes semi-colons\n",
    "    text = text.replace(':',' ') # Removes colons\n",
    "    text = text.replace('\"',' ') # Removes double quotation marks\n",
    "    text = text.replace(\"'\",' ') # Removes single quotation marks\n",
    "    text = text.replace(\"”\",' ') # Removes quotation marks\n",
    "    text = text.replace(\"“\",' ') # Removes quotation marks\n",
    "    text = text.replace('/',' ') # Removes back-slashes\n",
    "    text = text.replace('-',' ') # Removes dashes\n",
    "    text = text.replace('—',' ') # Removes dashes\n",
    "    text = text.replace('_',' ') # Removes underscores\n",
    "    text = text.replace('$',' ') # Removes dollar signs\n",
    "    text = text.replace('£',' ') # Removes symbol\n",
    "    text = text.replace('0',' ') # Removes the digit 0\n",
    "    text = text.replace('1',' ') # Removes the digit 1\n",
    "    text = text.replace('2',' ') # Removes the digit 2\n",
    "    text = text.replace('3',' ') # Removes the digit 3\n",
    "    text = text.replace('4',' ') # Removes the digit 4\n",
    "    text = text.replace('5',' ') # Removes the digit 5\n",
    "    text = text.replace('6',' ') # Removes the digit 6\n",
    "    text = text.replace('7',' ') # Removes the digit 7\n",
    "    text = text.replace('8',' ') # Removes the digit 8\n",
    "    text = text.replace('9',' ') # Removes the digit 9\n",
    "    \n",
    "    text_list = text.split()\n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a53e7472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude(text_list):\n",
    "    '''\n",
    "    This function takes a list of words and eliminates any words that are found on the stop_words.csv file\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    list: list of words\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    list: list of words that excludes any words from the stop_words.csv file\n",
    "    '''\n",
    "    final_list = [word for word in text_list if word not in stop_words_list]\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "bb94fbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DTM(final_list):\n",
    "    '''\n",
    "    This function converts list of text into a document term matrix\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    list: list of words\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    dataframe: pandas dataframe in the form of a document term matrix\n",
    "    '''\n",
    "    d = dict()\n",
    "    for word in final_list:\n",
    "        if word in d:\n",
    "            d[word][0] += 1\n",
    "        else:\n",
    "            d[word] = [1]\n",
    "    return pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "53fbf420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_DTM(texts=None):\n",
    "    '''\n",
    "    This function applies the functions tokenize(), exclude(), and DTM() to each news story\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    list: list of text for each news story\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dataframe: pandas dataframe in the form of a document term matrix\n",
    "    '''\n",
    "    final_DTM = pd.DataFrame()\n",
    "    \n",
    "    for story in text:\n",
    "        entry_a = tokenize(story)\n",
    "        entry_b = exclude(entry_a)\n",
    "        entry_c = DTM(entry_b)\n",
    "        final_DTM = final_DTM.append(pd.DataFrame(entry_c),ignore_index=True,sort=True) # Row bind\n",
    "    \n",
    "    final_DTM.fillna(0, inplace=True) # Fill in any missing values with 0s (i.e. when a word is in one text but not another)\n",
    "    return final_DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a3ab9dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(a,b):\n",
    "    '''\n",
    "    This function takes two numerical values and calculates the angle between the two vectors (cosine)\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    float: two floats that represent word counts\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    float: float that represents the cosine calculation between the two inputted floats\n",
    "    '''\n",
    "    cos = np.dot(a,b) / (np.sqrt(np.dot(a,a)) * np.sqrt(np.dot(b,b)))\n",
    "    return cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "3e0202ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abdulaziz</th>\n",
       "      <th>absent</th>\n",
       "      <th>accident</th>\n",
       "      <th>accidentally</th>\n",
       "      <th>account</th>\n",
       "      <th>accounts</th>\n",
       "      <th>accusation</th>\n",
       "      <th>accusing</th>\n",
       "      <th>acknowledged</th>\n",
       "      <th>added</th>\n",
       "      <th>...</th>\n",
       "      <th>we’re</th>\n",
       "      <th>white</th>\n",
       "      <th>widely</th>\n",
       "      <th>withheld</th>\n",
       "      <th>woods</th>\n",
       "      <th>world</th>\n",
       "      <th>worse</th>\n",
       "      <th>writer</th>\n",
       "      <th>yalova</th>\n",
       "      <th>yelova</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 634 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abdulaziz  absent  accident  accidentally  account  accounts  accusation  \\\n",
       "0        0.0     0.0       0.0           0.0      0.0       0.0         0.0   \n",
       "1        0.0     1.0       0.0           0.0      1.0       2.0         0.0   \n",
       "2        2.0     0.0       0.0           1.0      1.0       0.0         1.0   \n",
       "3        0.0     0.0       1.0           1.0      0.0       0.0         0.0   \n",
       "4        0.0     0.0       0.0           0.0      0.0       0.0         0.0   \n",
       "\n",
       "   accusing  acknowledged  added  ...  we’re  white  widely  withheld  woods  \\\n",
       "0       1.0           0.0    2.0  ...    0.0    0.0     0.0       0.0    0.0   \n",
       "1       0.0           1.0    1.0  ...    0.0    0.0     1.0       0.0    0.0   \n",
       "2       1.0           0.0    1.0  ...    1.0    1.0     0.0       1.0    0.0   \n",
       "3       0.0           0.0    0.0  ...    0.0    0.0     0.0       0.0    0.0   \n",
       "4       0.0           0.0    0.0  ...    0.0    0.0     0.0       0.0    1.0   \n",
       "\n",
       "   world  worse  writer  yalova  yelova  \n",
       "0    0.0    0.0     0.0     0.0     0.0  \n",
       "1    1.0    0.0     0.0     0.0     0.0  \n",
       "2    1.0    0.0     0.0     0.0     0.0  \n",
       "3    0.0    0.0     0.0     1.0     0.0  \n",
       "4    0.0    1.0     2.0     0.0     1.0  \n",
       "\n",
       "[5 rows x 634 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run gen_DTM function on all five stories to tokenize the text and get counts of each word\n",
    "df = gen_DTM(text)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "5d8b3319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Aljazeera     BBC  Breitbart     CNN     FOX\n",
      "Aljazeera     1.0000  0.7043     0.5868  0.6102  0.7161\n",
      "BBC           0.7043  1.0000     0.5877  0.5518  0.6674\n",
      "Breitbart     0.5868  0.5877     1.0000  0.3856  0.5553\n",
      "CNN           0.6102  0.5518     0.3856  1.0000  0.5791\n",
      "FOX           0.7161  0.6674     0.5553  0.5791  1.0000\n"
     ]
    }
   ],
   "source": [
    "# Index the dataframe, calculate cosine value between each pair of stories\n",
    "\n",
    "# Aljazeera vs. BBC\n",
    "a = df.iloc[0].values\n",
    "b = df.iloc[1].values\n",
    "albbc = round(cosine(a,b),4)\n",
    "\n",
    "# Aljazeera vs. Breitbart\n",
    "a = df.iloc[0].values\n",
    "b = df.iloc[2].values\n",
    "albr = round(cosine(a,b),4)\n",
    "\n",
    "# Aljazeera vs. CNN\n",
    "a = df.iloc[0].values\n",
    "b = df.iloc[3].values\n",
    "alcnn = round(cosine(a,b),4)\n",
    "\n",
    "# Aljazeera vs. FOX\n",
    "a = df.iloc[0].values\n",
    "b = df.iloc[4].values\n",
    "alfox = round(cosine(a,b),4)\n",
    "\n",
    "# BBC vs. Breitbart\n",
    "a = df.iloc[1].values\n",
    "b = df.iloc[2].values\n",
    "bbcbr = round(cosine(a,b),4)\n",
    "\n",
    "# BBC vs. CNN\n",
    "a = df.iloc[1].values\n",
    "b = df.iloc[3].values\n",
    "bbccnn = round(cosine(a,b),4)\n",
    "\n",
    "# BBC vs. FOX\n",
    "a = df.iloc[1].values\n",
    "b = df.iloc[4].values\n",
    "bbcfox = round(cosine(a,b),4)\n",
    "\n",
    "# Breitbart vs. CNN\n",
    "a = df.iloc[2].values\n",
    "b = df.iloc[3].values\n",
    "brcnn = round(cosine(a,b),4)\n",
    "\n",
    "# Breitbart vs. FOX\n",
    "a = df.iloc[2].values\n",
    "b = df.iloc[4].values\n",
    "brfox = round(cosine(a,b),4)\n",
    "\n",
    "# CNN vs. FOX\n",
    "a = df.iloc[3].values\n",
    "b = df.iloc[4].values\n",
    "cnnfox = round(cosine(a,b),4)\n",
    "\n",
    "# Put calculated values into a dataframe to easily compare\n",
    "# Intitialize data of lists \n",
    "cos_values = [{'Aljazeera': 1, 'BBC': albbc, 'Breitbart': albr, 'CNN': alcnn, 'FOX': alfox},\n",
    "             {'Aljazeera': albbc, 'BBC': 1, 'Breitbart': bbcbr, 'CNN': bbccnn, 'FOX': bbcfox},\n",
    "             {'Aljazeera': albr, 'BBC': bbcbr, 'Breitbart': 1, 'CNN': brcnn, 'FOX': brfox},\n",
    "             {'Aljazeera': alcnn, 'BBC': bbccnn, 'Breitbart': brcnn, 'CNN': 1, 'FOX': cnnfox},\n",
    "             {'Aljazeera': alfox, 'BBC': bbcfox, 'Breitbart': brfox, 'CNN': cnnfox, 'FOX': 1}]\n",
    "  \n",
    "# Index the dataframe\n",
    "cos_df = pd.DataFrame(cos_values, index =['Aljazeera', 'BBC', 'Breitbart', 'CNN', 'FOX'])\n",
    "  \n",
    "# Print the data\n",
    "print(cos_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cba60ab",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "#### Method\n",
    "After standardizing each news story by eliminating punctuation and the list of 'stop' words, I calculated the cosine value (using the dot product) for each possible pair of stories. The above dataframe (cos_df) shows each cosine value for the respective pairs of stories. A story evaluated against itself produces a cosine value of 1 (since it's exactly the same thing). Therefore, the higher the value we get from the cosine calculation, the more similar those two stories are. \n",
    "\n",
    "#### Background\n",
    "For context, Aljazeera is the news source headquartered in the Middle East. BBC (the British Broadcasting Corporation) is the news source from the United Kingdom. Then there is Breitbart, which is a American far-right news source started by conservative commentator Andrew Breitbart. Two more competing news sources in America are CNN and FOX, where CNN is known for holding bias in favor of the Democratic party, while FOX is typically bias towards Republicans.\n",
    "\n",
    "#### Observations\n",
    "When comparing the resulting cosine values, we see that these five news sites report on similar stories in dissimilar ways. The most similarly reported pair of new stories is Aljazeera and FOX (0.7161), with Aljazeera and BBC (0.7043) as a close second. We expect the Middle East news source and FOX to be comparable, as both are right-wing and present stories through a biased lens. Additionally, Aljazeera and BBC are rather similar, maybe because they are both international news sources (not headquartered in the United States). CNN and Breitbart are the least similar stories at a cosine value of 0.3856. This is because Breitbart is very right-wing, while CNN is very left-wing. We'd expect the two to have opposing viewpoints and present stories in a way that represents those views. In conclusion, this assignment verifies that stories may be presented differently based on the source it comes from and the bias behind each broadcasting channel."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
