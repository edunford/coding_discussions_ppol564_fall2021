{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " \"a's\",\n",
       " 'able',\n",
       " 'about',\n",
       " 'above',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'across',\n",
       " 'actually',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " \"ain't\",\n",
       " 'all',\n",
       " 'allow',\n",
       " 'allows',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anyhow',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'appear',\n",
       " 'appreciate',\n",
       " 'appropriate',\n",
       " 'are',\n",
       " \"aren't\",\n",
       " 'around',\n",
       " 'as',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asking',\n",
       " 'associated',\n",
       " 'at',\n",
       " 'available',\n",
       " 'away',\n",
       " 'awfully',\n",
       " 'b',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'believe',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'better',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'both',\n",
       " 'brief',\n",
       " 'but',\n",
       " 'by',\n",
       " 'c',\n",
       " \"c'mon\",\n",
       " \"c's\",\n",
       " 'came',\n",
       " 'can',\n",
       " \"can't\",\n",
       " 'cannot',\n",
       " 'cant',\n",
       " 'cause',\n",
       " 'causes',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'changes',\n",
       " 'clearly',\n",
       " 'co',\n",
       " 'com',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'concerning',\n",
       " 'consequently',\n",
       " 'consider',\n",
       " 'considering',\n",
       " 'contain',\n",
       " 'containing',\n",
       " 'contains',\n",
       " 'corresponding',\n",
       " 'could',\n",
       " \"couldn't\",\n",
       " 'course',\n",
       " 'currently',\n",
       " 'd',\n",
       " 'definitely',\n",
       " 'described',\n",
       " 'despite',\n",
       " 'did',\n",
       " \"didn't\",\n",
       " 'different',\n",
       " 'do',\n",
       " 'does',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " \"don't\",\n",
       " 'done',\n",
       " 'down',\n",
       " 'downwards',\n",
       " 'during',\n",
       " 'e',\n",
       " 'each',\n",
       " 'edu',\n",
       " 'eg',\n",
       " 'eight',\n",
       " 'either',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'enough',\n",
       " 'entirely',\n",
       " 'especially',\n",
       " 'et',\n",
       " 'etc',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everybody',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'ex',\n",
       " 'exactly',\n",
       " 'example',\n",
       " 'except',\n",
       " 'f',\n",
       " 'far',\n",
       " 'few',\n",
       " 'fifth',\n",
       " 'first',\n",
       " 'five',\n",
       " 'followed',\n",
       " 'following',\n",
       " 'follows',\n",
       " 'for',\n",
       " 'former',\n",
       " 'formerly',\n",
       " 'forth',\n",
       " 'four',\n",
       " 'from',\n",
       " 'further',\n",
       " 'furthermore',\n",
       " 'g',\n",
       " 'get',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'given',\n",
       " 'gives',\n",
       " 'go',\n",
       " 'goes',\n",
       " 'going',\n",
       " 'gone',\n",
       " 'got',\n",
       " 'gotten',\n",
       " 'greetings',\n",
       " 'h',\n",
       " 'had',\n",
       " \"hadn't\",\n",
       " 'happens',\n",
       " 'hardly',\n",
       " 'has',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he's\",\n",
       " 'hello',\n",
       " 'help',\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " \"here's\",\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " 'hereupon',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'hi',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'hither',\n",
       " 'hopefully',\n",
       " 'how',\n",
       " 'howbeit',\n",
       " 'however',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " \"i've\",\n",
       " 'ie',\n",
       " 'if',\n",
       " 'ignored',\n",
       " 'immediate',\n",
       " 'in',\n",
       " 'inasmuch',\n",
       " 'inc',\n",
       " 'indeed',\n",
       " 'indicate',\n",
       " 'indicated',\n",
       " 'indicates',\n",
       " 'inner',\n",
       " 'insofar',\n",
       " 'instead',\n",
       " 'into',\n",
       " 'inward',\n",
       " 'is',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'j',\n",
       " 'just',\n",
       " 'k',\n",
       " 'keep',\n",
       " 'keeps',\n",
       " 'kept',\n",
       " 'know',\n",
       " 'knows',\n",
       " 'known',\n",
       " 'l',\n",
       " 'last',\n",
       " 'lately',\n",
       " 'later',\n",
       " 'latter',\n",
       " 'latterly',\n",
       " 'least',\n",
       " 'less',\n",
       " 'lest',\n",
       " 'let',\n",
       " \"let's\",\n",
       " 'like',\n",
       " 'liked',\n",
       " 'likely',\n",
       " 'little',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'looks',\n",
       " 'ltd',\n",
       " 'm',\n",
       " 'mainly',\n",
       " 'many',\n",
       " 'may',\n",
       " 'maybe',\n",
       " 'me',\n",
       " 'mean',\n",
       " 'meanwhile',\n",
       " 'merely',\n",
       " 'might',\n",
       " 'more',\n",
       " 'moreover',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'much',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'n',\n",
       " 'name',\n",
       " 'namely',\n",
       " 'nd',\n",
       " 'near',\n",
       " 'nearly',\n",
       " 'necessary',\n",
       " 'need',\n",
       " 'needs',\n",
       " 'neither',\n",
       " 'never',\n",
       " 'nevertheless',\n",
       " 'new',\n",
       " 'next',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'non',\n",
       " 'none',\n",
       " 'noone',\n",
       " 'nor',\n",
       " 'normally',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'novel',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'o',\n",
       " 'obviously',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'okay',\n",
       " 'old',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'ones',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'or',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'ought',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'outside',\n",
       " 'over',\n",
       " 'overall',\n",
       " 'own',\n",
       " 'p',\n",
       " 'particular',\n",
       " 'particularly',\n",
       " 'per',\n",
       " 'perhaps',\n",
       " 'placed',\n",
       " 'please',\n",
       " 'plus',\n",
       " 'possible',\n",
       " 'presumably',\n",
       " 'probably',\n",
       " 'provides',\n",
       " 'q',\n",
       " 'que',\n",
       " 'quite',\n",
       " 'qv',\n",
       " 'r',\n",
       " 'rather',\n",
       " 'rd',\n",
       " 're',\n",
       " 'really',\n",
       " 'reasonably',\n",
       " 'regarding',\n",
       " 'regardless',\n",
       " 'regards',\n",
       " 'relatively',\n",
       " 'respectively',\n",
       " 'right',\n",
       " 's',\n",
       " 'said',\n",
       " 'same',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'saying',\n",
       " 'says',\n",
       " 'second',\n",
       " 'secondly',\n",
       " 'see',\n",
       " 'seeing',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'seems',\n",
       " 'seen',\n",
       " 'self',\n",
       " 'selves',\n",
       " 'sensible',\n",
       " 'sent',\n",
       " 'serious',\n",
       " 'seriously',\n",
       " 'seven',\n",
       " 'several',\n",
       " 'shall',\n",
       " 'she',\n",
       " 'should',\n",
       " \"shouldn't\",\n",
       " 'since',\n",
       " 'six',\n",
       " 'so',\n",
       " 'some',\n",
       " 'somebody',\n",
       " 'somehow',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'sometime',\n",
       " 'sometimes',\n",
       " 'somewhat',\n",
       " 'somewhere',\n",
       " 'soon',\n",
       " 'sorry',\n",
       " 'specified',\n",
       " 'specify',\n",
       " 'specifying',\n",
       " 'still',\n",
       " 'sub',\n",
       " 'such',\n",
       " 'sup',\n",
       " 'sure',\n",
       " 't',\n",
       " \"t's\",\n",
       " 'take',\n",
       " 'taken',\n",
       " 'tell',\n",
       " 'tends',\n",
       " 'th',\n",
       " 'than',\n",
       " 'thank',\n",
       " 'thanks',\n",
       " 'thanx',\n",
       " 'that',\n",
       " \"that's\",\n",
       " 'thats',\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'thence',\n",
       " 'there',\n",
       " \"there's\",\n",
       " 'thereafter',\n",
       " 'thereby',\n",
       " 'therefore',\n",
       " 'therein',\n",
       " 'theres',\n",
       " 'thereupon',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'think',\n",
       " 'third',\n",
       " 'this',\n",
       " 'thorough',\n",
       " 'thoroughly',\n",
       " 'those',\n",
       " 'though',\n",
       " 'three',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'thus',\n",
       " 'to',\n",
       " 'together',\n",
       " 'too',\n",
       " 'took',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'tried',\n",
       " 'tries',\n",
       " 'truly',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'twice',\n",
       " 'two',\n",
       " 'u',\n",
       " 'un',\n",
       " 'under',\n",
       " 'unfortunately',\n",
       " 'unless',\n",
       " 'unlikely',\n",
       " 'until',\n",
       " 'unto',\n",
       " 'up',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'use',\n",
       " 'used',\n",
       " 'useful',\n",
       " 'uses',\n",
       " 'using',\n",
       " 'usually',\n",
       " 'uucp',\n",
       " 'v',\n",
       " 'value',\n",
       " 'various',\n",
       " 'very',\n",
       " 'via',\n",
       " 'viz',\n",
       " 'vs',\n",
       " 'w',\n",
       " 'want',\n",
       " 'wants',\n",
       " 'was',\n",
       " \"wasn't\",\n",
       " 'way',\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " \"we've\",\n",
       " 'welcome',\n",
       " 'well',\n",
       " 'went',\n",
       " 'were',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " \"what's\",\n",
       " 'whatever',\n",
       " 'when',\n",
       " 'whence',\n",
       " 'whenever',\n",
       " 'where',\n",
       " \"where's\",\n",
       " 'whereafter',\n",
       " 'whereas',\n",
       " 'whereby',\n",
       " 'wherein',\n",
       " 'whereupon',\n",
       " 'wherever',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'while',\n",
       " 'whither',\n",
       " 'who',\n",
       " \"who's\",\n",
       " 'whoever',\n",
       " 'whole',\n",
       " 'whom',\n",
       " 'whose',\n",
       " 'why',\n",
       " 'will',\n",
       " 'willing',\n",
       " 'wish',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without',\n",
       " \"won't\",\n",
       " 'wonder',\n",
       " 'would',\n",
       " \"wouldn't\",\n",
       " 'x',\n",
       " 'y',\n",
       " 'yes',\n",
       " 'yet',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'z',\n",
       " 'zero',\n",
       " \"she's\",\n",
       " \"he'd\",\n",
       " \"she'd\",\n",
       " \"he'll\",\n",
       " \"she'll\",\n",
       " \"shan't\",\n",
       " \"mustn't\",\n",
       " \"when's\",\n",
       " \"why's\",\n",
       " \"how's\",\n",
       " 'area',\n",
       " 'areas',\n",
       " 'asked',\n",
       " 'asks',\n",
       " 'back',\n",
       " 'backed',\n",
       " 'backing',\n",
       " 'backs',\n",
       " 'began',\n",
       " 'beings',\n",
       " 'big',\n",
       " 'case',\n",
       " 'cases',\n",
       " 'clear',\n",
       " 'differ',\n",
       " 'differently',\n",
       " 'downed',\n",
       " 'downing',\n",
       " 'downs',\n",
       " 'early',\n",
       " 'end',\n",
       " 'ended',\n",
       " 'ending',\n",
       " 'ends',\n",
       " 'evenly',\n",
       " 'face',\n",
       " 'faces',\n",
       " 'fact',\n",
       " 'facts',\n",
       " 'felt',\n",
       " 'find',\n",
       " 'finds',\n",
       " 'full',\n",
       " 'fully',\n",
       " 'furthered',\n",
       " 'furthering',\n",
       " 'furthers',\n",
       " 'gave',\n",
       " 'general',\n",
       " 'generally',\n",
       " 'give',\n",
       " 'good',\n",
       " 'goods',\n",
       " 'great',\n",
       " 'greater',\n",
       " 'greatest',\n",
       " 'group',\n",
       " 'grouped',\n",
       " 'grouping',\n",
       " 'groups',\n",
       " 'high',\n",
       " 'higher',\n",
       " 'highest',\n",
       " 'important',\n",
       " 'interest',\n",
       " 'interested',\n",
       " 'interesting',\n",
       " 'interests',\n",
       " 'kind',\n",
       " 'knew',\n",
       " 'large',\n",
       " 'largely',\n",
       " 'latest',\n",
       " 'lets',\n",
       " 'long',\n",
       " 'longer',\n",
       " 'longest',\n",
       " 'made',\n",
       " 'make',\n",
       " 'making',\n",
       " 'man',\n",
       " 'member',\n",
       " 'members',\n",
       " 'men',\n",
       " 'mr',\n",
       " 'mrs',\n",
       " 'needed',\n",
       " 'needing',\n",
       " 'newer',\n",
       " 'newest',\n",
       " 'number',\n",
       " 'numbers',\n",
       " 'older',\n",
       " 'oldest',\n",
       " 'open',\n",
       " 'opened',\n",
       " 'opening',\n",
       " 'opens',\n",
       " 'order',\n",
       " 'ordered',\n",
       " 'ordering',\n",
       " 'orders',\n",
       " 'part',\n",
       " 'parted',\n",
       " 'parting',\n",
       " 'parts',\n",
       " 'place',\n",
       " 'places',\n",
       " 'point',\n",
       " 'pointed',\n",
       " 'pointing',\n",
       " 'points',\n",
       " 'present',\n",
       " 'presented',\n",
       " 'presenting',\n",
       " 'presents',\n",
       " 'problem',\n",
       " 'problems',\n",
       " 'put',\n",
       " 'puts',\n",
       " 'room',\n",
       " 'rooms',\n",
       " 'seconds',\n",
       " 'sees',\n",
       " 'show',\n",
       " 'showed',\n",
       " 'showing',\n",
       " 'shows',\n",
       " 'side',\n",
       " 'sides',\n",
       " 'small',\n",
       " 'smaller',\n",
       " 'smallest',\n",
       " 'state',\n",
       " 'states',\n",
       " 'thing',\n",
       " 'things',\n",
       " 'thinks',\n",
       " 'thought',\n",
       " 'thoughts',\n",
       " 'today',\n",
       " 'turn',\n",
       " 'turned',\n",
       " 'turning',\n",
       " 'turns',\n",
       " 'wanted',\n",
       " 'wanting',\n",
       " 'ways',\n",
       " 'wells',\n",
       " 'work',\n",
       " 'worked',\n",
       " 'working',\n",
       " 'works',\n",
       " 'year',\n",
       " 'years',\n",
       " 'young',\n",
       " 'younger',\n",
       " 'youngest']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load stop words to a list\n",
    "stop_words = pd.read_csv(\"/Users/Lawrence/Desktop/Georgetown_G1/PPOL_564_DS/coding_discussions_ppol564_fall2021/04_coding_discussion/Data/stop_words.csv\")\n",
    "list_sw = stop_words['word'].tolist()\n",
    "list_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open all the files and read them. \n",
    "txt1 = open('/Users/Lawrence/Desktop/Georgetown_G1/PPOL_564_DS/coding_discussions_ppol564_fall2021/04_coding_discussion/Data/aljazeera-khashoggi.txt')\n",
    "dta1 = txt1.read()\n",
    "txt2 = open('/Users/Lawrence/Desktop/Georgetown_G1/PPOL_564_DS/coding_discussions_ppol564_fall2021/04_coding_discussion/Data/bbc-khashoggi.txt')\n",
    "dta2 = txt2.read()\n",
    "txt3 = open('/Users/Lawrence/Desktop/Georgetown_G1/PPOL_564_DS/coding_discussions_ppol564_fall2021/04_coding_discussion/Data/breitbart-khashoggi.txt')\n",
    "dta3 = txt3.read()\n",
    "txt4 = open('/Users/Lawrence/Desktop/Georgetown_G1/PPOL_564_DS/coding_discussions_ppol564_fall2021/04_coding_discussion/Data/cnn-khashoggi.txt')\n",
    "dta4 = txt4.read()\n",
    "txt5 = open('/Users/Lawrence/Desktop/Georgetown_G1/PPOL_564_DS/coding_discussions_ppol564_fall2021/04_coding_discussion/Data/fox-khashoggi.txt')\n",
    "dta5 = txt5.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punct(dta):\n",
    "    '''\n",
    "    Make the read file as input and output a list for every words which all in lower case and no punctuation.\n",
    "    \n",
    "    Arguements\n",
    "    ----------\n",
    "    dta: a file which has been read.\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    a list that contains each word of the txt file.\n",
    "    '''\n",
    "    for i in dta:\n",
    "        if i in string.punctuation:\n",
    "            dta = dta.replace(i, \" \")\n",
    "            dta = dta.lower()\n",
    "            dta_list = dta.split()\n",
    "        \n",
    "    return dta_list\n",
    "\n",
    "dta1 = punct(dta1)\n",
    "dta2 = punct(dta2)\n",
    "dta3 = punct(dta3)\n",
    "dta4 = punct(dta4)\n",
    "dta5 = punct(dta5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['turkey',\n",
       " 'istanbul',\n",
       " 'turkish',\n",
       " 'president',\n",
       " 'recep',\n",
       " 'tayyip',\n",
       " 'erdogan',\n",
       " 'has',\n",
       " 'said',\n",
       " 'the',\n",
       " 'murder',\n",
       " 'of',\n",
       " 'journalist',\n",
       " 'jamal',\n",
       " 'khashoggi',\n",
       " 'at',\n",
       " 'the',\n",
       " 'kingdom',\n",
       " 's',\n",
       " 'consulate',\n",
       " 'in',\n",
       " 'istanbul',\n",
       " 'was',\n",
       " 'planned',\n",
       " 'by',\n",
       " 'saudi',\n",
       " 'officials',\n",
       " 'days',\n",
       " 'in',\n",
       " 'advance',\n",
       " 'addressing',\n",
       " 'legislators',\n",
       " 'from',\n",
       " 'his',\n",
       " 'justice',\n",
       " 'and',\n",
       " 'development',\n",
       " 'party',\n",
       " 'ak',\n",
       " 'party',\n",
       " 'on',\n",
       " 'tuesday',\n",
       " 'erdogan',\n",
       " 'detailed',\n",
       " 'khashoggi',\n",
       " 's',\n",
       " 'disappearance',\n",
       " 'and',\n",
       " 'murder',\n",
       " 'but',\n",
       " 'stopped',\n",
       " 'short',\n",
       " 'of',\n",
       " 'accusing',\n",
       " 'saudi',\n",
       " 'royals',\n",
       " 'of',\n",
       " 'the',\n",
       " 'savage',\n",
       " 'killing',\n",
       " 'that',\n",
       " 'has',\n",
       " 'caused',\n",
       " 'global',\n",
       " 'outrage',\n",
       " 'on',\n",
       " 'september',\n",
       " '28',\n",
       " 'khashoggi',\n",
       " 'arrived',\n",
       " 'at',\n",
       " 'the',\n",
       " 'saudi',\n",
       " 'arabian',\n",
       " 'consulate',\n",
       " 'for',\n",
       " 'him',\n",
       " 'to',\n",
       " 'sort',\n",
       " 'out',\n",
       " 'his',\n",
       " 'wedding',\n",
       " 'paperwork',\n",
       " 'erdogan',\n",
       " 'said',\n",
       " 'during',\n",
       " 'the',\n",
       " 'speech',\n",
       " 'in',\n",
       " 'the',\n",
       " 'turkish',\n",
       " 'parliament',\n",
       " 'in',\n",
       " 'the',\n",
       " 'capital',\n",
       " 'ankara',\n",
       " 'it',\n",
       " 'seems',\n",
       " 'that',\n",
       " 'at',\n",
       " 'that',\n",
       " 'time',\n",
       " 'they',\n",
       " 'saudi',\n",
       " 'arabian',\n",
       " 'officials',\n",
       " 'started',\n",
       " 'to',\n",
       " 'plan',\n",
       " 'a',\n",
       " 'roadmap',\n",
       " 'for',\n",
       " 'his',\n",
       " 'murder',\n",
       " 'he',\n",
       " 'added',\n",
       " 'that',\n",
       " 'some',\n",
       " 'saudi',\n",
       " 'officials',\n",
       " 'left',\n",
       " 'turkey',\n",
       " 'and',\n",
       " 'travelled',\n",
       " 'to',\n",
       " 'saudi',\n",
       " 'arabia',\n",
       " 'indicating',\n",
       " 'they',\n",
       " 'planned',\n",
       " 'the',\n",
       " 'murder',\n",
       " 'khashoggi',\n",
       " '59',\n",
       " 'a',\n",
       " 'washington',\n",
       " 'post',\n",
       " 'columnist',\n",
       " 'and',\n",
       " 'critic',\n",
       " 'of',\n",
       " 'the',\n",
       " 'powerful',\n",
       " 'saudi',\n",
       " 'crown',\n",
       " 'prince',\n",
       " 'mohammed',\n",
       " 'bin',\n",
       " 'salman',\n",
       " 'disappeared',\n",
       " 'after',\n",
       " 'entering',\n",
       " 'the',\n",
       " 'saudi',\n",
       " 'consulate',\n",
       " 'on',\n",
       " 'october',\n",
       " '2',\n",
       " 'until',\n",
       " 'tuesday',\n",
       " 's',\n",
       " 'speech',\n",
       " 'erdogan',\n",
       " 'had',\n",
       " 'remained',\n",
       " 'largely',\n",
       " 'silent',\n",
       " 'on',\n",
       " 'the',\n",
       " 'case',\n",
       " 'although',\n",
       " 'unnamed',\n",
       " 'turkish',\n",
       " 'officials',\n",
       " 'have',\n",
       " 'leaked',\n",
       " 'information',\n",
       " 'about',\n",
       " 'the',\n",
       " 'murder',\n",
       " 'including',\n",
       " 'information',\n",
       " 'about',\n",
       " 'a',\n",
       " '15',\n",
       " 'member',\n",
       " 'saudi',\n",
       " 'assassination',\n",
       " 'team',\n",
       " 'who',\n",
       " 'flew',\n",
       " 'into',\n",
       " 'istanbul',\n",
       " 'on',\n",
       " 'two',\n",
       " 'chartered',\n",
       " 'planes',\n",
       " 'in',\n",
       " 'the',\n",
       " 'wake',\n",
       " 'of',\n",
       " 'intense',\n",
       " 'global',\n",
       " 'pressure',\n",
       " 'saudi',\n",
       " 'arabia',\n",
       " 'admitted',\n",
       " 'last',\n",
       " 'week',\n",
       " 'that',\n",
       " 'khashoggi',\n",
       " 'was',\n",
       " 'killed',\n",
       " 'inside',\n",
       " 'its',\n",
       " 'istanbul',\n",
       " 'consulate',\n",
       " 'on',\n",
       " 'october',\n",
       " '2',\n",
       " 'as',\n",
       " 'a',\n",
       " 'result',\n",
       " 'of',\n",
       " 'a',\n",
       " 'fistfight',\n",
       " 'during',\n",
       " 'an',\n",
       " 'interrogation',\n",
       " 'saudi',\n",
       " 'authorities',\n",
       " 'arrested',\n",
       " '18',\n",
       " 'people',\n",
       " 'in',\n",
       " 'connection',\n",
       " 'with',\n",
       " 'the',\n",
       " 'killing',\n",
       " 'and',\n",
       " 'fired',\n",
       " 'top',\n",
       " 'security',\n",
       " 'officials',\n",
       " 'considered',\n",
       " 'close',\n",
       " 'to',\n",
       " 'bin',\n",
       " 'salman',\n",
       " 'erdogan',\n",
       " 'called',\n",
       " 'the',\n",
       " 'killing',\n",
       " 'a',\n",
       " 'political',\n",
       " 'murder',\n",
       " 'adding',\n",
       " 'that',\n",
       " 'international',\n",
       " 'investigators',\n",
       " 'should',\n",
       " 'be',\n",
       " 'included',\n",
       " 'in',\n",
       " 'the',\n",
       " 'probe',\n",
       " 'the',\n",
       " 'turkish',\n",
       " 'leader',\n",
       " 'went',\n",
       " 'on',\n",
       " 'to',\n",
       " 'call',\n",
       " 'the',\n",
       " 'killing',\n",
       " 'savage',\n",
       " 'adding',\n",
       " 'that',\n",
       " 'ankara',\n",
       " 'would',\n",
       " 'continue',\n",
       " 'its',\n",
       " 'investigation',\n",
       " 'until',\n",
       " 'all',\n",
       " 'questions',\n",
       " 'have',\n",
       " 'been',\n",
       " 'answered',\n",
       " 'why',\n",
       " 'did',\n",
       " 'they',\n",
       " 'the',\n",
       " 'saudi',\n",
       " 'team',\n",
       " 'come',\n",
       " 'to',\n",
       " 'istanbul',\n",
       " 'on',\n",
       " 'instruction',\n",
       " 'by',\n",
       " 'whom',\n",
       " 'erdogan',\n",
       " 'asked',\n",
       " 'adding',\n",
       " 'that',\n",
       " 'saudi',\n",
       " 'arabia',\n",
       " 'should',\n",
       " 'make',\n",
       " 'clear',\n",
       " 'why',\n",
       " 'it',\n",
       " 'did',\n",
       " 'not',\n",
       " 'let',\n",
       " 'investigators',\n",
       " 'into',\n",
       " 'the',\n",
       " 'consulate',\n",
       " 'until',\n",
       " 'days',\n",
       " 'later',\n",
       " 'where',\n",
       " 'is',\n",
       " 'the',\n",
       " 'body',\n",
       " 'galip',\n",
       " 'dalay',\n",
       " 'visiting',\n",
       " 'scholar',\n",
       " 'at',\n",
       " 'the',\n",
       " 'university',\n",
       " 'of',\n",
       " 'oxford',\n",
       " 'stressed',\n",
       " 'the',\n",
       " 'significance',\n",
       " 'of',\n",
       " 'erdogan',\n",
       " 's',\n",
       " 'speech',\n",
       " 'the',\n",
       " 'most',\n",
       " 'important',\n",
       " 'thing',\n",
       " 'is',\n",
       " 'that',\n",
       " 'erdogan',\n",
       " 'confirmed',\n",
       " 'everything',\n",
       " 'we',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'heard',\n",
       " 'through',\n",
       " 'other',\n",
       " 'channels',\n",
       " 'he',\n",
       " 'told',\n",
       " 'al',\n",
       " 'jazeera',\n",
       " 'however',\n",
       " 'now',\n",
       " 'it',\n",
       " 's',\n",
       " 'no',\n",
       " 'longer',\n",
       " 'attributed',\n",
       " 'to',\n",
       " 'unnamed',\n",
       " 'turkish',\n",
       " 'officials',\n",
       " 'but',\n",
       " 'it',\n",
       " 's',\n",
       " 'the',\n",
       " 'president',\n",
       " 'of',\n",
       " 'turkey',\n",
       " 'who',\n",
       " 'has',\n",
       " 'confirmed',\n",
       " 'what',\n",
       " 'has',\n",
       " 'happened',\n",
       " 'dalay',\n",
       " 'said',\n",
       " 'erdogan',\n",
       " 'also',\n",
       " 'demanded',\n",
       " 'answers',\n",
       " 'on',\n",
       " 'what',\n",
       " 'happened',\n",
       " 'to',\n",
       " 'khashoggi',\n",
       " 's',\n",
       " 'body',\n",
       " 'mentioning',\n",
       " 'reports',\n",
       " 'that',\n",
       " 'a',\n",
       " 'local',\n",
       " 'cooperator',\n",
       " 'allegedly',\n",
       " 'disposed',\n",
       " 'of',\n",
       " 'it',\n",
       " 'where',\n",
       " 'is',\n",
       " 'the',\n",
       " 'body',\n",
       " 'there',\n",
       " 'are',\n",
       " 'claims',\n",
       " 'his',\n",
       " 'body',\n",
       " 'has',\n",
       " 'been',\n",
       " 'given',\n",
       " 'to',\n",
       " 'a',\n",
       " 'local',\n",
       " 'person',\n",
       " 'but',\n",
       " 'who',\n",
       " 'is',\n",
       " 'this',\n",
       " 'local',\n",
       " 'person',\n",
       " 'erdogan',\n",
       " 'asked',\n",
       " 'nobody',\n",
       " 'is',\n",
       " 'allowed',\n",
       " 'to',\n",
       " 'think',\n",
       " 'this',\n",
       " 'case',\n",
       " 'will',\n",
       " 'come',\n",
       " 'to',\n",
       " 'an',\n",
       " 'end',\n",
       " 'without',\n",
       " 'answering',\n",
       " 'all',\n",
       " 'these',\n",
       " 'questions',\n",
       " 'he',\n",
       " 'added',\n",
       " 'the',\n",
       " 'turkish',\n",
       " 'president',\n",
       " 'also',\n",
       " 'said',\n",
       " 'saudi',\n",
       " 'arabia',\n",
       " 'was',\n",
       " 'taking',\n",
       " 'the',\n",
       " 'right',\n",
       " 'steps',\n",
       " 'by',\n",
       " 'working',\n",
       " 'with',\n",
       " 'ankara',\n",
       " 'on',\n",
       " 'the',\n",
       " 'investigation',\n",
       " 'and',\n",
       " 'carrying',\n",
       " 'out',\n",
       " 'the',\n",
       " '18',\n",
       " 'arrests',\n",
       " 'dalay',\n",
       " 'who',\n",
       " 'is',\n",
       " 'also',\n",
       " 'a',\n",
       " 'non',\n",
       " 'resident',\n",
       " 'fellow',\n",
       " 'at',\n",
       " 'brookings',\n",
       " 'institution',\n",
       " 'doha',\n",
       " 'underlined',\n",
       " 'erdogan',\n",
       " 's',\n",
       " 'distinction',\n",
       " 'in',\n",
       " 'his',\n",
       " 'speech',\n",
       " 'between',\n",
       " 'king',\n",
       " 'salman',\n",
       " 'and',\n",
       " 'his',\n",
       " 'son',\n",
       " 'bin',\n",
       " 'salman',\n",
       " 'everything',\n",
       " 'that',\n",
       " 'erdogan',\n",
       " 'provided',\n",
       " 'pointed',\n",
       " 'towards',\n",
       " 'mbs',\n",
       " 'without',\n",
       " 'naming',\n",
       " 'the',\n",
       " 'crown',\n",
       " 'prince',\n",
       " 'specifically',\n",
       " 'said',\n",
       " 'dalay',\n",
       " 'adding',\n",
       " 'that',\n",
       " 'the',\n",
       " 'turkish',\n",
       " 'president',\n",
       " 'was',\n",
       " 'clearly',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'prevent',\n",
       " 'a',\n",
       " 'full',\n",
       " 'blown',\n",
       " 'crisis',\n",
       " 'between',\n",
       " 'ankara',\n",
       " 'and',\n",
       " 'riyadh',\n",
       " 'on',\n",
       " 'sunday',\n",
       " 'speaking',\n",
       " 'in',\n",
       " 'an',\n",
       " 'exclusive',\n",
       " 'interview',\n",
       " 'with',\n",
       " 'fox',\n",
       " 'news',\n",
       " 'saudi',\n",
       " 'arabia',\n",
       " 's',\n",
       " 'foreign',\n",
       " 'minister',\n",
       " 'adel',\n",
       " 'al',\n",
       " 'jubeir',\n",
       " 'said',\n",
       " 'khashoggi',\n",
       " 's',\n",
       " 'killing',\n",
       " 'inside',\n",
       " 'the',\n",
       " 'consulate',\n",
       " 'was',\n",
       " 'a',\n",
       " 'terrible',\n",
       " 'tragedy',\n",
       " 'and',\n",
       " 'that',\n",
       " 'mbs',\n",
       " 'had',\n",
       " 'nothing',\n",
       " 'to',\n",
       " 'do',\n",
       " 'with',\n",
       " 'it',\n",
       " 'taha',\n",
       " 'ozhan',\n",
       " 'research',\n",
       " 'director',\n",
       " 'at',\n",
       " 'the',\n",
       " 'ankara',\n",
       " 'institute',\n",
       " 'told',\n",
       " 'al',\n",
       " 'jazeera',\n",
       " 'that',\n",
       " 'he',\n",
       " 'thought',\n",
       " 'erdogan',\n",
       " 'was',\n",
       " 'taking',\n",
       " 'the',\n",
       " 'right',\n",
       " 'steps',\n",
       " 'the',\n",
       " 'saudis',\n",
       " 'know',\n",
       " 'very',\n",
       " 'well',\n",
       " 'what',\n",
       " 'turkey',\n",
       " 'knows',\n",
       " 'and',\n",
       " 'what',\n",
       " 'erdogan',\n",
       " 'has',\n",
       " 'been',\n",
       " 'doing',\n",
       " 'is',\n",
       " 'the',\n",
       " 'right',\n",
       " 'thing',\n",
       " 'namely',\n",
       " 'asking',\n",
       " 'the',\n",
       " 'saudis',\n",
       " 'for',\n",
       " 'full',\n",
       " 'cooperation',\n",
       " 'in',\n",
       " 'this',\n",
       " 'case']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove(dta):\n",
    "    '''\n",
    "    Use the read file as input and all the words except stop words in a list as output. \n",
    "    \n",
    "    Arguements\n",
    "    ----------\n",
    "    address: the word list.\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    a list that contains each word without stop words.\n",
    "    '''\n",
    "    dta = [word for word in dta if word not in list_sw]\n",
    "    return dta\n",
    "\n",
    "dta1_r = remove(dta1)\n",
    "dta2_r = remove(dta2)\n",
    "dta3_r = remove(dta3)\n",
    "dta4_r = remove(dta4)\n",
    "dta5_r = remove(dta5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['turkey',\n",
       " 'istanbul',\n",
       " 'turkish',\n",
       " 'president',\n",
       " 'recep',\n",
       " 'tayyip',\n",
       " 'erdogan',\n",
       " 'murder',\n",
       " 'journalist',\n",
       " 'jamal',\n",
       " 'khashoggi',\n",
       " 'kingdom',\n",
       " 'consulate',\n",
       " 'istanbul',\n",
       " 'planned',\n",
       " 'saudi',\n",
       " 'officials',\n",
       " 'days',\n",
       " 'advance',\n",
       " 'addressing',\n",
       " 'legislators',\n",
       " 'justice',\n",
       " 'development',\n",
       " 'party',\n",
       " 'ak',\n",
       " 'party',\n",
       " 'tuesday',\n",
       " 'erdogan',\n",
       " 'detailed',\n",
       " 'khashoggi',\n",
       " 'disappearance',\n",
       " 'murder',\n",
       " 'stopped',\n",
       " 'short',\n",
       " 'accusing',\n",
       " 'saudi',\n",
       " 'royals',\n",
       " 'savage',\n",
       " 'killing',\n",
       " 'caused',\n",
       " 'global',\n",
       " 'outrage',\n",
       " 'september',\n",
       " '28',\n",
       " 'khashoggi',\n",
       " 'arrived',\n",
       " 'saudi',\n",
       " 'arabian',\n",
       " 'consulate',\n",
       " 'sort',\n",
       " 'wedding',\n",
       " 'paperwork',\n",
       " 'erdogan',\n",
       " 'speech',\n",
       " 'turkish',\n",
       " 'parliament',\n",
       " 'capital',\n",
       " 'ankara',\n",
       " 'time',\n",
       " 'saudi',\n",
       " 'arabian',\n",
       " 'officials',\n",
       " 'started',\n",
       " 'plan',\n",
       " 'roadmap',\n",
       " 'murder',\n",
       " 'added',\n",
       " 'saudi',\n",
       " 'officials',\n",
       " 'left',\n",
       " 'turkey',\n",
       " 'travelled',\n",
       " 'saudi',\n",
       " 'arabia',\n",
       " 'indicating',\n",
       " 'planned',\n",
       " 'murder',\n",
       " 'khashoggi',\n",
       " '59',\n",
       " 'washington',\n",
       " 'post',\n",
       " 'columnist',\n",
       " 'critic',\n",
       " 'powerful',\n",
       " 'saudi',\n",
       " 'crown',\n",
       " 'prince',\n",
       " 'mohammed',\n",
       " 'bin',\n",
       " 'salman',\n",
       " 'disappeared',\n",
       " 'entering',\n",
       " 'saudi',\n",
       " 'consulate',\n",
       " 'october',\n",
       " '2',\n",
       " 'tuesday',\n",
       " 'speech',\n",
       " 'erdogan',\n",
       " 'remained',\n",
       " 'silent',\n",
       " 'unnamed',\n",
       " 'turkish',\n",
       " 'officials',\n",
       " 'leaked',\n",
       " 'information',\n",
       " 'murder',\n",
       " 'including',\n",
       " 'information',\n",
       " '15',\n",
       " 'saudi',\n",
       " 'assassination',\n",
       " 'team',\n",
       " 'flew',\n",
       " 'istanbul',\n",
       " 'chartered',\n",
       " 'planes',\n",
       " 'wake',\n",
       " 'intense',\n",
       " 'global',\n",
       " 'pressure',\n",
       " 'saudi',\n",
       " 'arabia',\n",
       " 'admitted',\n",
       " 'week',\n",
       " 'khashoggi',\n",
       " 'killed',\n",
       " 'inside',\n",
       " 'istanbul',\n",
       " 'consulate',\n",
       " 'october',\n",
       " '2',\n",
       " 'result',\n",
       " 'fistfight',\n",
       " 'interrogation',\n",
       " 'saudi',\n",
       " 'authorities',\n",
       " 'arrested',\n",
       " '18',\n",
       " 'people',\n",
       " 'connection',\n",
       " 'killing',\n",
       " 'fired',\n",
       " 'top',\n",
       " 'security',\n",
       " 'officials',\n",
       " 'considered',\n",
       " 'close',\n",
       " 'bin',\n",
       " 'salman',\n",
       " 'erdogan',\n",
       " 'called',\n",
       " 'killing',\n",
       " 'political',\n",
       " 'murder',\n",
       " 'adding',\n",
       " 'international',\n",
       " 'investigators',\n",
       " 'included',\n",
       " 'probe',\n",
       " 'turkish',\n",
       " 'leader',\n",
       " 'call',\n",
       " 'killing',\n",
       " 'savage',\n",
       " 'adding',\n",
       " 'ankara',\n",
       " 'continue',\n",
       " 'investigation',\n",
       " 'questions',\n",
       " 'answered',\n",
       " 'saudi',\n",
       " 'team',\n",
       " 'istanbul',\n",
       " 'instruction',\n",
       " 'erdogan',\n",
       " 'adding',\n",
       " 'saudi',\n",
       " 'arabia',\n",
       " 'investigators',\n",
       " 'consulate',\n",
       " 'days',\n",
       " 'body',\n",
       " 'galip',\n",
       " 'dalay',\n",
       " 'visiting',\n",
       " 'scholar',\n",
       " 'university',\n",
       " 'oxford',\n",
       " 'stressed',\n",
       " 'significance',\n",
       " 'erdogan',\n",
       " 'speech',\n",
       " 'erdogan',\n",
       " 'confirmed',\n",
       " 'sort',\n",
       " 'heard',\n",
       " 'channels',\n",
       " 'told',\n",
       " 'al',\n",
       " 'jazeera',\n",
       " 'attributed',\n",
       " 'unnamed',\n",
       " 'turkish',\n",
       " 'officials',\n",
       " 'president',\n",
       " 'turkey',\n",
       " 'confirmed',\n",
       " 'happened',\n",
       " 'dalay',\n",
       " 'erdogan',\n",
       " 'demanded',\n",
       " 'answers',\n",
       " 'happened',\n",
       " 'khashoggi',\n",
       " 'body',\n",
       " 'mentioning',\n",
       " 'reports',\n",
       " 'local',\n",
       " 'cooperator',\n",
       " 'allegedly',\n",
       " 'disposed',\n",
       " 'body',\n",
       " 'claims',\n",
       " 'body',\n",
       " 'local',\n",
       " 'person',\n",
       " 'local',\n",
       " 'person',\n",
       " 'erdogan',\n",
       " 'allowed',\n",
       " 'answering',\n",
       " 'questions',\n",
       " 'added',\n",
       " 'turkish',\n",
       " 'president',\n",
       " 'saudi',\n",
       " 'arabia',\n",
       " 'taking',\n",
       " 'steps',\n",
       " 'ankara',\n",
       " 'investigation',\n",
       " 'carrying',\n",
       " '18',\n",
       " 'arrests',\n",
       " 'dalay',\n",
       " 'resident',\n",
       " 'fellow',\n",
       " 'brookings',\n",
       " 'institution',\n",
       " 'doha',\n",
       " 'underlined',\n",
       " 'erdogan',\n",
       " 'distinction',\n",
       " 'speech',\n",
       " 'king',\n",
       " 'salman',\n",
       " 'son',\n",
       " 'bin',\n",
       " 'salman',\n",
       " 'erdogan',\n",
       " 'provided',\n",
       " 'mbs',\n",
       " 'naming',\n",
       " 'crown',\n",
       " 'prince',\n",
       " 'specifically',\n",
       " 'dalay',\n",
       " 'adding',\n",
       " 'turkish',\n",
       " 'president',\n",
       " 'prevent',\n",
       " 'blown',\n",
       " 'crisis',\n",
       " 'ankara',\n",
       " 'riyadh',\n",
       " 'sunday',\n",
       " 'speaking',\n",
       " 'exclusive',\n",
       " 'interview',\n",
       " 'fox',\n",
       " 'news',\n",
       " 'saudi',\n",
       " 'arabia',\n",
       " 'foreign',\n",
       " 'minister',\n",
       " 'adel',\n",
       " 'al',\n",
       " 'jubeir',\n",
       " 'khashoggi',\n",
       " 'killing',\n",
       " 'inside',\n",
       " 'consulate',\n",
       " 'terrible',\n",
       " 'tragedy',\n",
       " 'mbs',\n",
       " 'taha',\n",
       " 'ozhan',\n",
       " 'research',\n",
       " 'director',\n",
       " 'ankara',\n",
       " 'institute',\n",
       " 'told',\n",
       " 'al',\n",
       " 'jazeera',\n",
       " 'erdogan',\n",
       " 'taking',\n",
       " 'steps',\n",
       " 'saudis',\n",
       " 'turkey',\n",
       " 'erdogan',\n",
       " 'saudis',\n",
       " 'cooperation']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dta1_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turkey</th>\n",
       "      <th>istanbul</th>\n",
       "      <th>turkish</th>\n",
       "      <th>president</th>\n",
       "      <th>recep</th>\n",
       "      <th>tayyip</th>\n",
       "      <th>erdogan</th>\n",
       "      <th>murder</th>\n",
       "      <th>journalist</th>\n",
       "      <th>jamal</th>\n",
       "      <th>...</th>\n",
       "      <th>jubeir</th>\n",
       "      <th>terrible</th>\n",
       "      <th>tragedy</th>\n",
       "      <th>taha</th>\n",
       "      <th>ozhan</th>\n",
       "      <th>research</th>\n",
       "      <th>director</th>\n",
       "      <th>institute</th>\n",
       "      <th>saudis</th>\n",
       "      <th>cooperation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   turkey  istanbul  turkish  president  recep  tayyip  erdogan  murder  \\\n",
       "0       4         5        7          4      1       1       14       6   \n",
       "\n",
       "   journalist  jamal  ...  jubeir  terrible  tragedy  taha  ozhan  research  \\\n",
       "0           1      1  ...       1         1        1     1      1         1   \n",
       "\n",
       "   director  institute  saudis  cooperation  \n",
       "0         1          1       2            1  \n",
       "\n",
       "[1 rows x 186 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_text_to_dtm(dta):\n",
    "    '''\n",
    "    Converts text into a document term matrix.\n",
    "    '''\n",
    "    d = dict()\n",
    "    for word in remove(dta):\n",
    "        if word in d:\n",
    "            d[word][0] += 1\n",
    "        else:\n",
    "            d[word] = [1]\n",
    "    return pd.DataFrame(d)\n",
    "\n",
    "convert_text_to_dtm(dta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>08</th>\n",
       "      <th>1</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>18</th>\n",
       "      <th>2</th>\n",
       "      <th>28</th>\n",
       "      <th>2r</th>\n",
       "      <th>30</th>\n",
       "      <th>...</th>\n",
       "      <th>“may</th>\n",
       "      <th>“other</th>\n",
       "      <th>“partner</th>\n",
       "      <th>“putting</th>\n",
       "      <th>“saudi</th>\n",
       "      <th>“the</th>\n",
       "      <th>“to</th>\n",
       "      <th>“we</th>\n",
       "      <th>“why</th>\n",
       "      <th>”</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 674 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    08    1   11   12   15   18    2   28   2r   30  ...  “may  “other  \\\n",
       "0  0.0  0.0  0.0  0.0  1.0  2.0  2.0  1.0  0.0  0.0  ...   0.0     0.0   \n",
       "1  0.0  0.0  0.0  1.0  0.0  2.0  1.0  0.0  1.0  0.0  ...   0.0     0.0   \n",
       "2  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...   1.0     1.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...   0.0     0.0   \n",
       "4  1.0  2.0  1.0  0.0  1.0  1.0  1.0  0.0  0.0  1.0  ...   0.0     0.0   \n",
       "\n",
       "   “partner  “putting  “saudi  “the  “to  “we  “why     ”  \n",
       "0       0.0       0.0     0.0   0.0  0.0  0.0   0.0   0.0  \n",
       "1       0.0       0.0     0.0   0.0  0.0  0.0   0.0   0.0  \n",
       "2       1.0       1.0     0.0   2.0  0.0  1.0   1.0  11.0  \n",
       "3       0.0       0.0     0.0   0.0  0.0  0.0   0.0   0.0  \n",
       "4       0.0       0.0     1.0   0.0  1.0  1.0   0.0   5.0  \n",
       "\n",
       "[5 rows x 674 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_DTM(dta):\n",
    "    '''\n",
    "    Generate a document term matrix\n",
    "    '''\n",
    "    DTM = pd.DataFrame()\n",
    "    for text in dta:\n",
    "        entry = convert_text_to_dtm(text)\n",
    "        DTM = DTM.append(pd.DataFrame(entry),ignore_index=True,sort=True)\n",
    "        \n",
    "    DTM.fillna(0, inplace = True)\n",
    "    return DTM\n",
    "\n",
    "gen_DTM([dta1,dta2,dta3,dta4,dta5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(a,b):\n",
    "    '''\n",
    "    Calculate the the cosine of two vectors\n",
    "    \n",
    "    Arguements\n",
    "    ----------\n",
    "    a,b: vectors\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    the value of cosine of these two vectors\n",
    "    '''\n",
    "    cos = np.dot(a,b)/(np.sqrt(np.dot(a,a)) * np.sqrt(np.dot(b,b)))\n",
    "    return cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cosine between every file. \n",
    "sim_no_stop = [cosine(gen_DTM([dta1,dta2,dta3,dta4,dta5]).iloc[0].values, gen_DTM([dta1,dta2,dta3,dta4,dta5]).iloc[1].values),\n",
    "cosine(gen_DTM([dta1,dta2,dta3,dta4,dta5]).iloc[0].values, gen_DTM([dta1,dta2,dta3,dta4,dta5]).iloc[2].values),\n",
    "cosine(gen_DTM([dta1,dta2,dta3,dta4,dta5]).iloc[0].values, gen_DTM([dta1,dta2,dta3,dta4,dta5]).iloc[3].values),\n",
    "cosine(gen_DTM([dta1,dta2,dta3,dta4,dta5]).iloc[0].values, gen_DTM([dta1,dta2,dta3,dta4,dta5]).iloc[4].values),\n",
    "cosine(gen_DTM([dta1,dta2,dta3,dta4,dta5]).iloc[1].values, gen_DTM([dta1,dta2,dta3,dta4,dta5]).iloc[2].values),\n",
    "cosine(gen_DTM([dta1,dta2,dta3,dta4,dta5]).iloc[1].values, gen_DTM([dta1,dta2,dta3,dta4,dta5]).iloc[3].values),\n",
    "cosine(gen_DTM([dta1,dta2,dta3,dta4,dta5]).iloc[1].values, gen_DTM([dta1,dta2,dta3,dta4,dta5]).iloc[4].values),\n",
    "cosine(gen_DTM([dta1,dta2,dta3,dta4,dta5]).iloc[2].values, gen_DTM([dta1,dta2,dta3,dta4,dta5]).iloc[3].values),\n",
    "cosine(gen_DTM([dta1,dta2,dta3,dta4,dta5]).iloc[2].values, gen_DTM([dta1,dta2,dta3,dta4,dta5]).iloc[4].values),\n",
    "cosine(gen_DTM([dta1,dta2,dta3,dta4,dta5]).iloc[3].values, gen_DTM([dta1,dta2,dta3,dta4,dta5]).iloc[4].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7041497395190525,\n",
       " 0.5113636772885002,\n",
       " 0.607536842465486,\n",
       " 0.6770706948484275,\n",
       " 0.5178111952033483,\n",
       " 0.5505247517970405,\n",
       " 0.630565150461454,\n",
       " 0.33904537821469555,\n",
       " 0.5494311777526358,\n",
       " 0.5558525646949523]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_no_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turkey</th>\n",
       "      <th>istanbul</th>\n",
       "      <th>turkish</th>\n",
       "      <th>president</th>\n",
       "      <th>recep</th>\n",
       "      <th>tayyip</th>\n",
       "      <th>erdogan</th>\n",
       "      <th>has</th>\n",
       "      <th>said</th>\n",
       "      <th>the</th>\n",
       "      <th>...</th>\n",
       "      <th>thought</th>\n",
       "      <th>saudis</th>\n",
       "      <th>know</th>\n",
       "      <th>very</th>\n",
       "      <th>well</th>\n",
       "      <th>knows</th>\n",
       "      <th>doing</th>\n",
       "      <th>namely</th>\n",
       "      <th>asking</th>\n",
       "      <th>cooperation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 289 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   turkey  istanbul  turkish  president  recep  tayyip  erdogan  has  said  \\\n",
       "0       4         5        7          4      1       1       14    6     6   \n",
       "\n",
       "   the  ...  thought  saudis  know  very  well  knows  doing  namely  asking  \\\n",
       "0   38  ...        1       2     1     1     1      1      1       1       1   \n",
       "\n",
       "   cooperation  \n",
       "0            1  \n",
       "\n",
       "[1 rows x 289 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_text_to_dtm_no_remove(dta):\n",
    "    '''\n",
    "    Converts text into a document term matrix.\n",
    "    '''\n",
    "    d = dict()\n",
    "    for word in dta:\n",
    "        if word in d:\n",
    "            d[word][0] += 1\n",
    "        else:\n",
    "            d[word] = [1]\n",
    "    return pd.DataFrame(d)\n",
    "\n",
    "convert_text_to_dtm_no_remove(dta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>08</th>\n",
       "      <th>1</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>18</th>\n",
       "      <th>2</th>\n",
       "      <th>28</th>\n",
       "      <th>2r</th>\n",
       "      <th>30</th>\n",
       "      <th>...</th>\n",
       "      <th>“may</th>\n",
       "      <th>“other</th>\n",
       "      <th>“partner</th>\n",
       "      <th>“putting</th>\n",
       "      <th>“saudi</th>\n",
       "      <th>“the</th>\n",
       "      <th>“to</th>\n",
       "      <th>“we</th>\n",
       "      <th>“why</th>\n",
       "      <th>”</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 906 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    08    1   11   12   15   18    2   28   2r   30  ...  “may  “other  \\\n",
       "0  0.0  0.0  0.0  0.0  1.0  2.0  2.0  1.0  0.0  0.0  ...   0.0     0.0   \n",
       "1  0.0  0.0  0.0  1.0  0.0  2.0  1.0  0.0  1.0  0.0  ...   0.0     0.0   \n",
       "2  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...   1.0     1.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...   0.0     0.0   \n",
       "4  1.0  2.0  1.0  0.0  1.0  1.0  1.0  0.0  0.0  1.0  ...   0.0     0.0   \n",
       "\n",
       "   “partner  “putting  “saudi  “the  “to  “we  “why     ”  \n",
       "0       0.0       0.0     0.0   0.0  0.0  0.0   0.0   0.0  \n",
       "1       0.0       0.0     0.0   0.0  0.0  0.0   0.0   0.0  \n",
       "2       1.0       1.0     0.0   2.0  0.0  1.0   1.0  11.0  \n",
       "3       0.0       0.0     0.0   0.0  0.0  0.0   0.0   0.0  \n",
       "4       0.0       0.0     1.0   0.0  1.0  1.0   0.0   5.0  \n",
       "\n",
       "[5 rows x 906 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_DTM_no_remove(dta):\n",
    "    '''\n",
    "    Generate a document term matrix\n",
    "    '''\n",
    "    DTM = pd.DataFrame()\n",
    "    for text in dta:\n",
    "        entry = convert_text_to_dtm_no_remove(text)\n",
    "        DTM = DTM.append(pd.DataFrame(entry),ignore_index=True,sort=True)\n",
    "        \n",
    "    DTM.fillna(0, inplace = True)\n",
    "    return DTM\n",
    "\n",
    "gen_DTM_no_remove([dta1,dta2,dta3,dta4,dta5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_with_stop = [cosine(gen_DTM_no_remove([dta1,dta2,dta3,dta4,dta5]).iloc[0].values, gen_DTM_no_remove([dta1,dta2,dta3,dta4,dta5]).iloc[1].values),\n",
    "cosine(gen_DTM_no_remove([dta1,dta2,dta3,dta4,dta5]).iloc[0].values, gen_DTM_no_remove([dta1,dta2,dta3,dta4,dta5]).iloc[2].values),\n",
    "cosine(gen_DTM_no_remove([dta1,dta2,dta3,dta4,dta5]).iloc[0].values, gen_DTM_no_remove([dta1,dta2,dta3,dta4,dta5]).iloc[3].values),\n",
    "cosine(gen_DTM_no_remove([dta1,dta2,dta3,dta4,dta5]).iloc[0].values, gen_DTM_no_remove([dta1,dta2,dta3,dta4,dta5]).iloc[4].values),\n",
    "cosine(gen_DTM_no_remove([dta1,dta2,dta3,dta4,dta5]).iloc[1].values, gen_DTM_no_remove([dta1,dta2,dta3,dta4,dta5]).iloc[2].values),\n",
    "cosine(gen_DTM_no_remove([dta1,dta2,dta3,dta4,dta5]).iloc[1].values, gen_DTM_no_remove([dta1,dta2,dta3,dta4,dta5]).iloc[3].values),\n",
    "cosine(gen_DTM_no_remove([dta1,dta2,dta3,dta4,dta5]).iloc[1].values, gen_DTM_no_remove([dta1,dta2,dta3,dta4,dta5]).iloc[4].values),\n",
    "cosine(gen_DTM_no_remove([dta1,dta2,dta3,dta4,dta5]).iloc[2].values, gen_DTM_no_remove([dta1,dta2,dta3,dta4,dta5]).iloc[3].values),\n",
    "cosine(gen_DTM_no_remove([dta1,dta2,dta3,dta4,dta5]).iloc[2].values, gen_DTM_no_remove([dta1,dta2,dta3,dta4,dta5]).iloc[4].values),\n",
    "cosine(gen_DTM_no_remove([dta1,dta2,dta3,dta4,dta5]).iloc[3].values, gen_DTM_no_remove([dta1,dta2,dta3,dta4,dta5]).iloc[4].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8738641656783281,\n",
       " 0.8110627186003684,\n",
       " 0.7643034039690844,\n",
       " 0.8301078937033459,\n",
       " 0.8750263049244931,\n",
       " 0.7588748618146538,\n",
       " 0.8798458504844707,\n",
       " 0.6745183530937948,\n",
       " 0.8606112208188483,\n",
       " 0.7448307395184334]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_with_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there are stop words the overall similarity is high, we can find that aljazeera-khashoggi.txt and bbc-khashoggi.txt are the most similar among the ten comparisons, bbc-khashoggi.txt and breitbart-khashoggi.txt are the similarity and breitbart-khashoggi.txt are the least similar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
