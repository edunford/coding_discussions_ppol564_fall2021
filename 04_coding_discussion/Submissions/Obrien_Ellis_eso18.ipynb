{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1688402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import sklearn as sk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac6cad9",
   "metadata": {},
   "source": [
    "# Part 1 Original Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e370663",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading In Stop Words \n",
    "stopwords=pd.read_csv('/Users/ellisobrien/Desktop/Georgetown Semester 1/Data Science/coding_discussions_ppol564_fall2021/04_coding_discussion/Data/stop_words.csv')\n",
    "\n",
    "#Creating directory \n",
    "folder='/Users/ellisobrien/Desktop/Georgetown Semester 1/Data Science/coding_discussions_ppol564_fall2021/04_coding_discussion/Data'\n",
    "\n",
    "#reading in each file \n",
    "aljazeera=open((str(folder)+\"/aljazeera-khashoggi.txt\"), \"r\")\n",
    "bbc=open((str(folder)+\"/bbc-khashoggi.txt\"), \"r\")\n",
    "breitbart=open((str(folder)+\"/breitbart-khashoggi.txt\"), \"r\")\n",
    "cnn=open((str(folder)+\"/cnn-khashoggi.txt\"), \"r\")\n",
    "fox=open((str(folder)+\"/fox-khashoggi.txt\"), \"r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00207fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting each text to string\n",
    "aljazeera=aljazeera.read()\n",
    "bbc=bbc.read()\n",
    "breitbart=breitbart.read()\n",
    "cnn=cnn.read()\n",
    "fox=fox.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8af35ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [1 1 0 ... 2 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ellisobrien/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'aren', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'mustn', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "#importing sklearn count vectorizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#creating list of texts\n",
    "textlist = [aljazeera, bbc, breitbart, cnn, fox]\n",
    "#setting vectorizer\n",
    "vectorizer = CountVectorizer(stop_words=list(stopwords['word']))\n",
    "\n",
    "#applying vectorizer \n",
    "vf = vectorizer.fit_transform(textlist)\n",
    "\n",
    "#printing as array\n",
    "print(vf.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9bdde631",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating function \n",
    "def cosdot(x,y):\n",
    "    '''\n",
    "    inputs: two vectors \n",
    "    outputs: cosine dotproduct \n",
    "    '''\n",
    "    vfx=vf[x].todense()\n",
    "    vfy=vf[y].todense()\n",
    "    dp = np.dot(vfx,vfy.transpose())/(np.sqrt(np.dot(vfx,vfx.transpose())) * np.sqrt(np.dot(vfy,vfy.transpose())))\n",
    "    return float(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3ef3fd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of numbers for loop\n",
    "numberlist=[0,1,2,3,4]\n",
    "#list of column names for loop\n",
    "columnnames=['aljazeera', 'bbc', 'breitbart', 'cnn', 'fox']\n",
    "#blank Data Frame \n",
    "df = pd.DataFrame(columns=[\"Article1\", \"Article2\", \"Coefficient\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6b015a30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article1</th>\n",
       "      <th>Article2</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aljazeera</td>\n",
       "      <td>bbc</td>\n",
       "      <td>0.704288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aljazeera</td>\n",
       "      <td>breitbart</td>\n",
       "      <td>0.600776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aljazeera</td>\n",
       "      <td>cnn</td>\n",
       "      <td>0.608624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aljazeera</td>\n",
       "      <td>fox</td>\n",
       "      <td>0.719294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bbc</td>\n",
       "      <td>breitbart</td>\n",
       "      <td>0.621047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bbc</td>\n",
       "      <td>cnn</td>\n",
       "      <td>0.550651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bbc</td>\n",
       "      <td>fox</td>\n",
       "      <td>0.692978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>breitbart</td>\n",
       "      <td>cnn</td>\n",
       "      <td>0.421972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>breitbart</td>\n",
       "      <td>fox</td>\n",
       "      <td>0.581209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cnn</td>\n",
       "      <td>fox</td>\n",
       "      <td>0.605116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Article1   Article2  Coefficient\n",
       "0  aljazeera        bbc     0.704288\n",
       "1  aljazeera  breitbart     0.600776\n",
       "2  aljazeera        cnn     0.608624\n",
       "3  aljazeera        fox     0.719294\n",
       "4        bbc  breitbart     0.621047\n",
       "5        bbc        cnn     0.550651\n",
       "6        bbc        fox     0.692978\n",
       "7  breitbart        cnn     0.421972\n",
       "8  breitbart        fox     0.581209\n",
       "9        cnn        fox     0.605116"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looping through to add each to a data frame \n",
    "for i in (numberlist): \n",
    "    for j in range(i+1, 5):\n",
    "         df.loc[len(df)]=[columnnames[i],columnnames[j], cosdot(i, j)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cb2591",
   "metadata": {},
   "source": [
    "# Part 2 with New Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7a4d25b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('saudi', 56), ('erdogan', 49), ('khashoggi', 47), ('consulate', 24), ('turkish', 23), ('arabia', 23), ('murder', 22)]\n"
     ]
    }
   ],
   "source": [
    "#Finding the most common words\n",
    "words = vf.sum(axis=0)\n",
    "word_frequency = [(word, words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
    "word_frequency =sorted(word_frequency, key = lambda x: x[1], reverse=True)\n",
    "print(word_frequency[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ca7f37d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appending New Words\n",
    "new_stop_words = stopwords['word'].tolist()+['saudi', 'erdogan', 'khashoggi',  'consulate', 'turkish', 'arabia', 'murder']\n",
    "#Making List to dataframe \n",
    "new_stop_words = pd.DataFrame(new_stop_words,columns=['word'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "42610818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [1 1 0 ... 2 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ellisobrien/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ain', 'aren', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'll', 'mon', 'mustn', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "#setting vectorizer with new stop words\n",
    "vectorizer2 = CountVectorizer(stop_words=list(new_stop_words['word']))\n",
    "#creating new object with new stopwords\n",
    "vf2 = vectorizer2.fit_transform(textlist)\n",
    "#printing as array\n",
    "print(vf2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "07598304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function with new stopword list\n",
    "def cosdot2(x,y):\n",
    "    '''\n",
    "    inputs: two vectors \n",
    "    outputs: cosine dotproduct \n",
    "    '''\n",
    "    vf2x=vf2[x].todense()\n",
    "    vf2y=vf2[y].todense()\n",
    "    dp2 = np.dot(vf2x,vf2y.transpose())/(np.sqrt(np.dot(vf2x,vf2x.transpose())) * np.sqrt(np.dot(vf2y,vf2y.transpose())))\n",
    "    return float(dp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4ba9d3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data frame for new stopword lists\n",
    "df2 = pd.DataFrame(columns=[\"Article1\", \"Article2\", \"New_Coefficient\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a82e80f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looping through new stop word array \n",
    "for i in (numberlist): \n",
    "    for j in range(i+1, 5):\n",
    "         df2.loc[len(df2)]=[columnnames[i],columnnames[j], cosdot2(i, j)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "addc16a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article1</th>\n",
       "      <th>Article2</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>New_Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aljazeera</td>\n",
       "      <td>bbc</td>\n",
       "      <td>0.704288</td>\n",
       "      <td>0.457895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aljazeera</td>\n",
       "      <td>breitbart</td>\n",
       "      <td>0.600776</td>\n",
       "      <td>0.436066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aljazeera</td>\n",
       "      <td>cnn</td>\n",
       "      <td>0.608624</td>\n",
       "      <td>0.342936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aljazeera</td>\n",
       "      <td>fox</td>\n",
       "      <td>0.719294</td>\n",
       "      <td>0.422397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bbc</td>\n",
       "      <td>breitbart</td>\n",
       "      <td>0.621047</td>\n",
       "      <td>0.480912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bbc</td>\n",
       "      <td>cnn</td>\n",
       "      <td>0.550651</td>\n",
       "      <td>0.266810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bbc</td>\n",
       "      <td>fox</td>\n",
       "      <td>0.692978</td>\n",
       "      <td>0.431374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>breitbart</td>\n",
       "      <td>cnn</td>\n",
       "      <td>0.421972</td>\n",
       "      <td>0.211457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>breitbart</td>\n",
       "      <td>fox</td>\n",
       "      <td>0.581209</td>\n",
       "      <td>0.423251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cnn</td>\n",
       "      <td>fox</td>\n",
       "      <td>0.605116</td>\n",
       "      <td>0.266060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Article1   Article2  Coefficient  New_Coefficient\n",
       "0  aljazeera        bbc     0.704288         0.457895\n",
       "1  aljazeera  breitbart     0.600776         0.436066\n",
       "2  aljazeera        cnn     0.608624         0.342936\n",
       "3  aljazeera        fox     0.719294         0.422397\n",
       "4        bbc  breitbart     0.621047         0.480912\n",
       "5        bbc        cnn     0.550651         0.266810\n",
       "6        bbc        fox     0.692978         0.431374\n",
       "7  breitbart        cnn     0.421972         0.211457\n",
       "8  breitbart        fox     0.581209         0.423251\n",
       "9        cnn        fox     0.605116         0.266060"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#joining two data frames\n",
    "final_df = pd.merge(df, df2, how=\"left\", on=[\"Article1\", \"Article2\"])\n",
    "#printing final data frame \n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90610d94",
   "metadata": {},
   "source": [
    "### Observations\n",
    "With the original list the two most similar articles are Aljazeera and Fox. The least similar are Breitbart and CNN. There is much less similarity between the articles once the list of stop words are ammended which makes sense. With the new list the most similar are Breibart and BBC, which marks a change from the original list. The least similar are still Breitbart and CNN. \n",
    "\n",
    "Over the correlation with the original stop words is in between .42 and .71. With the new stop words it is betweet .21 and .48. I am not surprised to see CNN and Breitbart as the most dissimiliar as the \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
