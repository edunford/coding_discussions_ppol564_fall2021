{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8db0310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da5d59e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory\n",
    "os.chdir('/Users/nikhilaiyer/Documents/GRAD SCHOOL/ppol564/coding_discussions_ppol564_fall2021/04_coding_discussion/Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd05425b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to read in necessary files\n",
    "def file_reader(og_file):\n",
    "    '''\n",
    "    This function reads the news article in and returns it to a variable.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    .txt: File with the news article\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    Str: The \"opened\" file\n",
    "    '''\n",
    "    open_file = open(og_file).read()\n",
    "    return open_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b829148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function on files\n",
    "aljazeera = file_reader(\"aljazeera-khashoggi.txt\")\n",
    "bbc = file_reader(\"bbc-khashoggi.txt\")\n",
    "breitbart = file_reader(\"breitbart-khashoggi.txt\")\n",
    "cnn = file_reader(\"cnn-khashoggi.txt\")\n",
    "fox = file_reader(\"fox-khashoggi.txt\")\n",
    "stop_words = pd.read_csv('stop_words.csv')['word'].tolist()\n",
    "all_stories = [aljazeera, bbc, breitbart, cnn, fox]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb35833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace puncuation in text, and then turn text into a list of words\n",
    "def tokenize(text):\n",
    "    '''\n",
    "    This function takes in a text file (str) and changes the whole file to lower case, removes all the puncuations,\n",
    "    and removes the stop words provided to us.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    Str: text \n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    List: Text file as a list with the removed items above\n",
    "    '''\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"!\", \"\") #remove exclamation mark\n",
    "    text = text.replace(\"@\", \"\") #remove at symbol\n",
    "    text = text.replace(\"#\", \"\") #remove pound sign\n",
    "    text = text.replace(\"$\", \"\") #remove dollar sign\n",
    "    text = text.replace(\"*\", \"\") #remove asterisk\n",
    "    text = text.replace(\"(\", \"\") #remove open parenthetical\n",
    "    text = text.replace(\")\", \"\") #remove close parenthetical\n",
    "    text = text.replace(\"-\", \"\") #remove dash\n",
    "    text = text.replace(\"+\", \"\") #remove plus sign\n",
    "    text = text.replace(\"=\", \"\") #remove equals sign\n",
    "    text = text.replace(\"[\", \"\") #remove open bracket\n",
    "    text = text.replace(\"]\", \"\") #remove closed bracket\n",
    "    text = text.replace(\":\", \"\") #remove colon\n",
    "    text = text.replace(\";\", \"\") #remove semi colon\n",
    "    text = text.replace(\"'\", \"\") #remove single quote\n",
    "    text = text.replace('\"', \"\") #remove double quote\n",
    "    text = text.replace(\"”\",' ') #remove special quotation marks\n",
    "    text = text.replace(\"“\",' ') #remove special quotation marks\n",
    "    text = text.replace(\",\", \"\") #remove comma\n",
    "    text = text.replace(\".\", \"\") #remove period\n",
    "    text = text.replace(\"?\", \"\") #remove question mark\n",
    "    text = text.replace(\"0\", \"\") #remove no. 0\n",
    "    text = text.replace(\"1\", \"\") #remove no. 1\n",
    "    text = text.replace(\"2\", \"\") #remove no. 2\n",
    "    text = text.replace(\"3\", \"\") #remove no. 3\n",
    "    text = text.replace(\"4\", \"\") #remove no. 4\n",
    "    text = text.replace(\"5\", \"\") #remove no. 5\n",
    "    text = text.replace(\"6\", \"\") #remove no. 6\n",
    "    text = text.replace(\"7\", \"\") #remove no. 7\n",
    "    text = text.replace(\"8\", \"\") #remove no. 8\n",
    "    text = text.replace(\"9\", \"\") #remove no. 9\n",
    "    text_list = text.split()\n",
    "    text_list = [word for word in text_list if word not in stop_words]\n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f73df91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtm(text):\n",
    "    '''\n",
    "    This function takes in a list of the news article words, counts the frequency of the words, and adds it to a dictionary.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    Str: Takes in a list of words from the news article\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    DataFrame: Word bank of all the words in the file, with the frequency of appearance\n",
    "    '''\n",
    "    word_bank = dict()\n",
    "    text = tokenize(text)\n",
    "    for word in text:\n",
    "        if word in word_bank:\n",
    "            word_bank[word][0] += 1\n",
    "        else:\n",
    "            word_bank[word] = [1]\n",
    "    return pd.DataFrame(word_bank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52cd0843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combo_dtm(all_texts):\n",
    "    '''\n",
    "    This function combines all the data frames developed in the dtm() function of the word counts of each article.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    List: A list of lists of the news article words\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    DataFrame: Word bank of all the words in the file, with the frequency of appearance in a combined data frame for all articles passed in\n",
    "    '''\n",
    "    full_dtm = pd.DataFrame()\n",
    "    for text in all_texts:\n",
    "        curr_dtm = dtm(text)\n",
    "        full_dtm = full_dtm.append(pd.DataFrame(curr_dtm), ignore_index = True, sort = True)\n",
    "    full_dtm.fillna(0, inplace = True)\n",
    "    return full_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9eddb8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abdulaziz</th>\n",
       "      <th>absent</th>\n",
       "      <th>accident</th>\n",
       "      <th>accidentally</th>\n",
       "      <th>accidentallyerdogan</th>\n",
       "      <th>account</th>\n",
       "      <th>accounts</th>\n",
       "      <th>accusation</th>\n",
       "      <th>accusing</th>\n",
       "      <th>acknowledged</th>\n",
       "      <th>...</th>\n",
       "      <th>withheld</th>\n",
       "      <th>woods</th>\n",
       "      <th>world</th>\n",
       "      <th>worse</th>\n",
       "      <th>writer</th>\n",
       "      <th>yalova</th>\n",
       "      <th>yearold</th>\n",
       "      <th>yelova</th>\n",
       "      <th>£bn</th>\n",
       "      <th>—</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 653 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abdulaziz  absent  accident  accidentally  accidentallyerdogan  account  \\\n",
       "0        0.0     0.0       0.0           0.0                  0.0      0.0   \n",
       "1        0.0     1.0       0.0           0.0                  0.0      1.0   \n",
       "2        2.0     0.0       0.0           1.0                  0.0      1.0   \n",
       "3        0.0     0.0       1.0           0.0                  1.0      0.0   \n",
       "4        0.0     0.0       0.0           0.0                  0.0      0.0   \n",
       "\n",
       "   accounts  accusation  accusing  acknowledged  ...  withheld  woods  world  \\\n",
       "0       0.0         0.0       1.0           0.0  ...       0.0    0.0    0.0   \n",
       "1       2.0         0.0       0.0           1.0  ...       0.0    0.0    1.0   \n",
       "2       0.0         1.0       1.0           0.0  ...       1.0    0.0    1.0   \n",
       "3       0.0         0.0       0.0           0.0  ...       0.0    0.0    0.0   \n",
       "4       0.0         0.0       0.0           0.0  ...       0.0    1.0    0.0   \n",
       "\n",
       "   worse  writer  yalova  yearold  yelova  £bn    —  \n",
       "0    0.0     0.0     0.0      0.0     0.0  0.0  0.0  \n",
       "1    0.0     0.0     0.0      1.0     0.0  1.0  0.0  \n",
       "2    0.0     0.0     0.0      0.0     0.0  0.0  0.0  \n",
       "3    0.0     0.0     1.0      0.0     0.0  0.0  0.0  \n",
       "4    1.0     2.0     0.0      0.0     1.0  0.0  3.0  \n",
       "\n",
       "[5 rows x 653 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A full data frame of all the news articles and their word count frequencies\n",
    "combo_word_bank = combo_dtm(all_stories)\n",
    "combo_word_bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8003cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(a, b):\n",
    "    '''\n",
    "    This function calculates the cosine similarity of two article word counts.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    Array (A): Words counted in article A\n",
    "    Array (B): Words counted in article B\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    int: Cosine similarity value of the two \n",
    "    '''\n",
    "    cos = np.dot(a, b) / (np.sqrt(np.dot(a, a)) * np.sqrt(np.dot(b, b)))\n",
    "    return cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "772ec463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a blank cosine matrix which is the appropriate size and correct headings\n",
    "blank_cos_matrix = pd.DataFrame(index = ['Aljazeera', 'BBC', 'Breitbart', 'CNN', 'Fox'], columns = ['Aljazeera', 'BBC', 'Breitbart', 'CNN', 'Fox'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22f57cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cr_matrix(matrix, word_bank):\n",
    "    '''\n",
    "    This function creates the cosine matrix of all the articles compared to one another.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    Data Frame (matrix): Takes in an empty matrix to fill with values\n",
    "    Data Frame (word bank): A word bank of all the word frequency counts\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    Data Frame (matrix): Returns the matrix now filled with cosine values\n",
    "    '''\n",
    "    for i in range(len(matrix.index)):\n",
    "        for c in range(len(matrix.columns)):\n",
    "            text_1 = word_bank.iloc[i].values\n",
    "            text_2 = word_bank.iloc[c].values\n",
    "            cos_val = round(cosine(text_1, text_2), 4)\n",
    "            matrix.iloc[i, c] = cos_val\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b817122c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aljazeera</th>\n",
       "      <th>BBC</th>\n",
       "      <th>Breitbart</th>\n",
       "      <th>CNN</th>\n",
       "      <th>Fox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aljazeera</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6796</td>\n",
       "      <td>0.5877</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.6825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBC</th>\n",
       "      <td>0.6796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>0.5029</td>\n",
       "      <td>0.6298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Breitbart</th>\n",
       "      <td>0.5877</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3684</td>\n",
       "      <td>0.5489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>0.533</td>\n",
       "      <td>0.5029</td>\n",
       "      <td>0.3684</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fox</th>\n",
       "      <td>0.6825</td>\n",
       "      <td>0.6298</td>\n",
       "      <td>0.5489</td>\n",
       "      <td>0.5188</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Aljazeera     BBC Breitbart     CNN     Fox\n",
       "Aljazeera       1.0  0.6796    0.5877   0.533  0.6825\n",
       "BBC          0.6796     1.0    0.5833  0.5029  0.6298\n",
       "Breitbart    0.5877  0.5833       1.0  0.3684  0.5489\n",
       "CNN           0.533  0.5029    0.3684     1.0  0.5188\n",
       "Fox          0.6825  0.6298    0.5489  0.5188     1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a cosine matrix of the news articles word frequencies\n",
    "cos_matrix_1 = cr_matrix(blank_cos_matrix, combo_word_bank)\n",
    "cos_matrix_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddd227a",
   "metadata": {},
   "source": [
    "##### Initial Cosine Matrix Analysis\n",
    "The cosine matrix shows us which articles are most similar based on the value seen - obviously a value of 1 means that the articles are exactly the same. The most similar articles seem to be Fox and Aljazeera at 0.6825, followed by BBC and Aljazeera. Interestingly Aljazeera and BBC are the only mainly international news sources on this list (CNN definitely has an international branch, maybe not the focus). The least similar articles are CNN and Breitbart, which is to be expected seeing how the news outlets report on any type of news they lean politically on opposite ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9ff0b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the top common words that are most likely repeated in all articles, creating a list of extra stop words and adding them to the stop words list\n",
    "extra_words = [\"saudi\", \"erdogan\", \"jamal\", \"khashoggi\", \"khashoggis\", \"turkish\", \"turkey\", \"istanbul\", \"arabia\", \"bin\", \"saudis\", \"mohammed\"]\n",
    "stop_words.extend(extra_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67d2bfcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aljazeera</th>\n",
       "      <th>BBC</th>\n",
       "      <th>Breitbart</th>\n",
       "      <th>CNN</th>\n",
       "      <th>Fox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aljazeera</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4633</td>\n",
       "      <td>0.4133</td>\n",
       "      <td>0.2391</td>\n",
       "      <td>0.4752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBC</th>\n",
       "      <td>0.4633</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4422</td>\n",
       "      <td>0.2489</td>\n",
       "      <td>0.4281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Breitbart</th>\n",
       "      <td>0.4133</td>\n",
       "      <td>0.4422</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1378</td>\n",
       "      <td>0.4286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>0.2391</td>\n",
       "      <td>0.2489</td>\n",
       "      <td>0.1378</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fox</th>\n",
       "      <td>0.4752</td>\n",
       "      <td>0.4281</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.2237</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Aljazeera     BBC Breitbart     CNN     Fox\n",
       "Aljazeera       1.0  0.4633    0.4133  0.2391  0.4752\n",
       "BBC          0.4633     1.0    0.4422  0.2489  0.4281\n",
       "Breitbart    0.4133  0.4422       1.0  0.1378  0.4286\n",
       "CNN          0.2391  0.2489    0.1378     1.0  0.2237\n",
       "Fox          0.4752  0.4281    0.4286  0.2237     1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a new data frame of frequencies and passing that in to create a new cosine comparison matrix\n",
    "combo_word_bank_extra = combo_dtm(all_stories)\n",
    "cos_matrix_2 = cr_matrix(blank_cos_matrix, combo_word_bank_extra)\n",
    "cos_matrix_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5636dd",
   "metadata": {},
   "source": [
    "##### Updated Cosine Matrix Analysis\n",
    "For this matrix, we removed extra words from the frequency counter - the words selected were based on the highly used ones that were most likely to appear in every article (names, locations); basically more fact based reporting words. Once we do this, we still see similar results as before with CNN and Breitbart being the most different and Aljazeera, BBC, and Fox being the most similar. This further proves that the actual opinions are differing in the news outlets reporting, not just the reporting style or fact based information that's being presented."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
