{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6bf81b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47146a0e",
   "metadata": {},
   "source": [
    "### Calculate the similarities without stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc580b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the stop words and make them a list.\n",
    "stop_word = pd.read_csv(\"stop_words.csv\")\n",
    "stop_word_list = list(stop_word[\"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "159fe068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['turkey',\n",
       " 'istanbul',\n",
       " 'turkish',\n",
       " 'president',\n",
       " 'recep',\n",
       " 'tayyip',\n",
       " 'erdogan',\n",
       " 'murder',\n",
       " 'journalist',\n",
       " 'jamal',\n",
       " 'khashoggi',\n",
       " 'kingdoms',\n",
       " 'consulate',\n",
       " 'istanbul',\n",
       " 'planned',\n",
       " 'saudi',\n",
       " 'officials',\n",
       " 'days',\n",
       " 'advance',\n",
       " 'addressing',\n",
       " 'legislators',\n",
       " 'justice',\n",
       " 'development',\n",
       " 'party',\n",
       " 'ak',\n",
       " 'party',\n",
       " 'tuesday',\n",
       " 'erdogan',\n",
       " 'detailed',\n",
       " 'khashoggis',\n",
       " 'disappearance',\n",
       " 'murder',\n",
       " 'stopped',\n",
       " 'short',\n",
       " 'accusing',\n",
       " 'saudi',\n",
       " 'royals',\n",
       " 'savage',\n",
       " 'killing',\n",
       " 'caused',\n",
       " 'global',\n",
       " 'outrage',\n",
       " 'september',\n",
       " '28',\n",
       " 'khashoggi',\n",
       " 'arrived',\n",
       " 'saudi',\n",
       " 'arabian',\n",
       " 'consulate',\n",
       " 'sort',\n",
       " 'wedding',\n",
       " 'paperwork',\n",
       " 'erdogan',\n",
       " 'speech',\n",
       " 'turkish',\n",
       " 'parliament',\n",
       " 'capital',\n",
       " 'ankara',\n",
       " 'time',\n",
       " 'saudi',\n",
       " 'arabian',\n",
       " 'officials',\n",
       " 'started',\n",
       " 'plan',\n",
       " 'roadmap',\n",
       " 'murder',\n",
       " 'added',\n",
       " 'saudi',\n",
       " 'officials',\n",
       " 'left',\n",
       " 'turkey',\n",
       " 'travelled',\n",
       " 'saudi',\n",
       " 'arabia',\n",
       " 'indicating',\n",
       " 'planned',\n",
       " 'murder',\n",
       " 'khashoggi',\n",
       " '59',\n",
       " 'washington',\n",
       " 'post',\n",
       " 'columnist',\n",
       " 'critic',\n",
       " 'powerful',\n",
       " 'saudi',\n",
       " 'crown',\n",
       " 'prince',\n",
       " 'mohammed',\n",
       " 'bin',\n",
       " 'salman',\n",
       " 'disappeared',\n",
       " 'entering',\n",
       " 'saudi',\n",
       " 'consulate',\n",
       " 'october',\n",
       " '2',\n",
       " 'tuesdays',\n",
       " 'speech',\n",
       " 'erdogan',\n",
       " 'remained',\n",
       " 'silent',\n",
       " 'unnamed',\n",
       " 'turkish',\n",
       " 'officials',\n",
       " 'leaked',\n",
       " 'information',\n",
       " 'murder',\n",
       " 'including',\n",
       " 'information',\n",
       " '15member',\n",
       " 'saudi',\n",
       " 'assassination',\n",
       " 'team',\n",
       " 'flew',\n",
       " 'istanbul',\n",
       " 'chartered',\n",
       " 'planes',\n",
       " 'wake',\n",
       " 'intense',\n",
       " 'global',\n",
       " 'pressure',\n",
       " 'saudi',\n",
       " 'arabia',\n",
       " 'admitted',\n",
       " 'week',\n",
       " 'khashoggi',\n",
       " 'killed',\n",
       " 'inside',\n",
       " 'istanbul',\n",
       " 'consulate',\n",
       " 'october',\n",
       " '2',\n",
       " 'result',\n",
       " 'fistfight',\n",
       " 'interrogation',\n",
       " 'saudi',\n",
       " 'authorities',\n",
       " 'arrested',\n",
       " '18',\n",
       " 'people',\n",
       " 'connection',\n",
       " 'killing',\n",
       " 'fired',\n",
       " 'top',\n",
       " 'security',\n",
       " 'officials',\n",
       " 'considered',\n",
       " 'close',\n",
       " 'bin',\n",
       " 'salman',\n",
       " 'erdogan',\n",
       " 'called',\n",
       " 'killing',\n",
       " 'political',\n",
       " 'murder',\n",
       " 'adding',\n",
       " 'international',\n",
       " 'investigators',\n",
       " 'included',\n",
       " 'probe',\n",
       " 'turkish',\n",
       " 'leader',\n",
       " 'call',\n",
       " 'killing',\n",
       " 'savage',\n",
       " 'adding',\n",
       " 'ankara',\n",
       " 'continue',\n",
       " 'investigation',\n",
       " 'questions',\n",
       " 'answered',\n",
       " 'saudi',\n",
       " 'team',\n",
       " 'istanbul',\n",
       " 'instruction',\n",
       " 'erdogan',\n",
       " 'adding',\n",
       " 'saudi',\n",
       " 'arabia',\n",
       " 'investigators',\n",
       " 'consulate',\n",
       " 'days',\n",
       " 'body',\n",
       " 'galip',\n",
       " 'dalay',\n",
       " 'visiting',\n",
       " 'scholar',\n",
       " 'university',\n",
       " 'oxford',\n",
       " 'stressed',\n",
       " 'significance',\n",
       " 'erdogans',\n",
       " 'speech',\n",
       " 'erdogan',\n",
       " 'confirmed',\n",
       " 'sort',\n",
       " 'heard',\n",
       " 'channels',\n",
       " 'told',\n",
       " 'al',\n",
       " 'jazeera',\n",
       " 'attributed',\n",
       " 'unnamed',\n",
       " 'turkish',\n",
       " 'officials',\n",
       " 'president',\n",
       " 'turkey',\n",
       " 'confirmed',\n",
       " 'happened',\n",
       " 'dalay',\n",
       " 'erdogan',\n",
       " 'demanded',\n",
       " 'answers',\n",
       " 'happened',\n",
       " 'khashoggis',\n",
       " 'body',\n",
       " 'mentioning',\n",
       " 'reports',\n",
       " 'local',\n",
       " 'cooperator',\n",
       " 'allegedly',\n",
       " 'disposed',\n",
       " 'body',\n",
       " 'claims',\n",
       " 'body',\n",
       " 'local',\n",
       " 'person',\n",
       " 'local',\n",
       " 'person',\n",
       " 'erdogan',\n",
       " 'allowed',\n",
       " 'answering',\n",
       " 'questions',\n",
       " 'added',\n",
       " 'turkish',\n",
       " 'president',\n",
       " 'saudi',\n",
       " 'arabia',\n",
       " 'taking',\n",
       " 'steps',\n",
       " 'ankara',\n",
       " 'investigation',\n",
       " 'carrying',\n",
       " '18',\n",
       " 'arrests',\n",
       " 'dalay',\n",
       " 'nonresident',\n",
       " 'fellow',\n",
       " 'brookings',\n",
       " 'institution',\n",
       " 'doha',\n",
       " 'underlined',\n",
       " 'erdogans',\n",
       " 'distinction',\n",
       " 'speech',\n",
       " 'king',\n",
       " 'salman',\n",
       " 'son',\n",
       " 'bin',\n",
       " 'salman',\n",
       " 'erdogan',\n",
       " 'provided',\n",
       " 'mbs',\n",
       " 'naming',\n",
       " 'crown',\n",
       " 'prince',\n",
       " 'specifically',\n",
       " 'dalay',\n",
       " 'adding',\n",
       " 'turkish',\n",
       " 'president',\n",
       " 'prevent',\n",
       " 'fullblown',\n",
       " 'crisis',\n",
       " 'ankara',\n",
       " 'riyadh',\n",
       " 'sunday',\n",
       " 'speaking',\n",
       " 'exclusive',\n",
       " 'interview',\n",
       " 'fox',\n",
       " 'news',\n",
       " 'saudi',\n",
       " 'arabias',\n",
       " 'foreign',\n",
       " 'minister',\n",
       " 'adel',\n",
       " 'aljubeir',\n",
       " 'khashoggis',\n",
       " 'killing',\n",
       " 'inside',\n",
       " 'consulate',\n",
       " 'terrible',\n",
       " 'tragedy',\n",
       " 'mbs',\n",
       " 'taha',\n",
       " 'ozhan',\n",
       " 'research',\n",
       " 'director',\n",
       " 'ankara',\n",
       " 'institute',\n",
       " 'told',\n",
       " 'al',\n",
       " 'jazeera',\n",
       " 'erdogan',\n",
       " 'taking',\n",
       " 'steps',\n",
       " 'saudis',\n",
       " 'turkey',\n",
       " 'erdogan',\n",
       " 'saudis',\n",
       " 'cooperation']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_text_txt(address):\n",
    "    '''\n",
    "    This function takes a txt file's directory as input and outputs a list that contains each word of the text.\n",
    "    \n",
    "    Arguements\n",
    "    ----------\n",
    "    address: a txt file's directory.\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    a list that contains each word of the txt file.\n",
    "    '''\n",
    "    text_as_list = []#create a new list.\n",
    "    with open(address) as f:#append each lineofnthe file to the list.\n",
    "        for line in f:\n",
    "            text_as_list.append(line)\n",
    "    text_as_list = text_as_list[0].lower().translate(str.maketrans('', '', string.punctuation)).split()#make the content to lower case, remove all punctuation and split to single word.\n",
    "    text_as_list2 = [word for word in text_as_list if word not in stop_word_list]#remove all the stop words.\n",
    "    return text_as_list2\n",
    "\n",
    "get_text_txt('aljazeera-khashoggi.txt')#test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7811c956",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turkey</th>\n",
       "      <th>istanbul</th>\n",
       "      <th>turkish</th>\n",
       "      <th>president</th>\n",
       "      <th>recep</th>\n",
       "      <th>tayyip</th>\n",
       "      <th>erdogan</th>\n",
       "      <th>murder</th>\n",
       "      <th>journalist</th>\n",
       "      <th>jamal</th>\n",
       "      <th>...</th>\n",
       "      <th>aljubeir</th>\n",
       "      <th>terrible</th>\n",
       "      <th>tragedy</th>\n",
       "      <th>taha</th>\n",
       "      <th>ozhan</th>\n",
       "      <th>research</th>\n",
       "      <th>director</th>\n",
       "      <th>institute</th>\n",
       "      <th>saudis</th>\n",
       "      <th>cooperation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   turkey  istanbul  turkish  president  recep  tayyip  erdogan  murder  \\\n",
       "0       4         5        7          4      1       1       12       6   \n",
       "\n",
       "   journalist  jamal  ...  aljubeir  terrible  tragedy  taha  ozhan  research  \\\n",
       "0           1      1  ...         1         1        1     1      1         1   \n",
       "\n",
       "   director  institute  saudis  cooperation  \n",
       "0         1          1       2            1  \n",
       "\n",
       "[1 rows x 190 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_text_to_dtm(txt):\n",
    "    '''\n",
    "    This function takes a list that contains each word of the text as input and outputs a dataframe that counts the appearance of each word.\n",
    "    \n",
    "    Arguements\n",
    "    ----------\n",
    "    txt: a list that contains each word of the text.\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    a dataframe that counts the appearance of each word.\n",
    "    '''\n",
    "    d = dict()#create a dictionary to count the appearance.\n",
    "    for word in get_text_txt(txt):#if the word is in the dict, add one to the value. if not, create a new key.\n",
    "        if word in d:\n",
    "            d[word][0] += 1\n",
    "        else:\n",
    "            d[word] = [1]\n",
    "    return pd.DataFrame(d)\n",
    "\n",
    "convert_text_to_dtm('aljazeera-khashoggi.txt')#test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de69b6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list that contains all the directorys(in this case it's the name because my ipynb file and my data are in the same floder).\n",
    "texts_list= ['aljazeera-khashoggi.txt', 'bbc-khashoggi.txt', 'breitbart-khashoggi.txt', 'cnn-khashoggi.txt', 'fox-khashoggi.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accc7ad5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>108</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>15member</th>\n",
       "      <th>18</th>\n",
       "      <th>2</th>\n",
       "      <th>28</th>\n",
       "      <th>2r</th>\n",
       "      <th>...</th>\n",
       "      <th>“may</th>\n",
       "      <th>“other</th>\n",
       "      <th>“partner</th>\n",
       "      <th>“putting</th>\n",
       "      <th>“saudi</th>\n",
       "      <th>“the</th>\n",
       "      <th>“to</th>\n",
       "      <th>“we</th>\n",
       "      <th>“were</th>\n",
       "      <th>“why</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 696 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  108   11   12   15  15member   18    2   28   2r  ...  “may  “other  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0       1.0  2.0  2.0  1.0  0.0  ...   0.0     0.0   \n",
       "1  0.0  0.0  0.0  1.0  0.0       0.0  2.0  1.0  0.0  1.0  ...   0.0     0.0   \n",
       "2  0.0  0.0  0.0  0.0  1.0       0.0  0.0  0.0  0.0  0.0  ...   1.0     1.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0       0.0  1.0  0.0  0.0  0.0  ...   0.0     0.0   \n",
       "4  1.0  1.0  1.0  0.0  1.0       0.0  1.0  1.0  0.0  0.0  ...   0.0     0.0   \n",
       "\n",
       "   “partner  “putting  “saudi  “the  “to  “we  “were  “why  \n",
       "0       0.0       0.0     0.0   0.0  0.0  0.0    0.0   0.0  \n",
       "1       0.0       0.0     0.0   0.0  0.0  0.0    0.0   0.0  \n",
       "2       1.0       1.0     0.0   2.0  0.0  1.0    0.0   1.0  \n",
       "3       0.0       0.0     0.0   0.0  0.0  0.0    0.0   0.0  \n",
       "4       0.0       0.0     1.0   0.0  1.0  0.0    1.0   0.0  \n",
       "\n",
       "[5 rows x 696 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now build a function that does this for a list of texts\n",
    "def gen_DTM(texts=None):\n",
    "    '''\n",
    "    This function Generate a document term matrix.\n",
    "    \n",
    "    Arguements\n",
    "    ----------\n",
    "    texts: a list that contains all the dirctorys that you want to include.\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    a dataframe that counts the appearance of each word of each txt file.\n",
    "    '''\n",
    "    DTM = pd.DataFrame()#create a new dataframe\n",
    "    for text in texts:#convert the appearance of words of each file and combine them.\n",
    "        entry = convert_text_to_dtm(text)\n",
    "        DTM = DTM.append(pd.DataFrame(entry),ignore_index=True,sort=True) # Row bind\n",
    "    \n",
    "    DTM.fillna(0, inplace=True) # Fill in any missing values with 0s (i.e. when a word is in one text but not another)\n",
    "    return DTM\n",
    "      \n",
    "gen_DTM(texts_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d0c2235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(a,b):\n",
    "    '''\n",
    "    This function calculate the the cosine of two vectors\n",
    "    \n",
    "    Arguements\n",
    "    ----------\n",
    "    a,b: vectors\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    the value of cosine of these two vectors\n",
    "    '''\n",
    "    cos = np.dot(a,b)/(np.sqrt(np.dot(a,a)) * np.sqrt(np.dot(b,b)))#calculate the cosine\n",
    "    return cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ebb5a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities_without_stop = {}#create a new dict.\n",
    "for i in range(gen_DTM(texts_list) .shape[0]):#calculate the cosine of each two combinaton and append it to the dictionary with there names as key.\n",
    "    for j in range(i + 1, gen_DTM(texts_list).shape[0]):\n",
    "        similarities_without_stop[texts_list[i], texts_list[j]] = cosine(gen_DTM(texts_list).iloc[i].values, gen_DTM(texts_list).iloc[j].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5ee9447",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('aljazeera-khashoggi.txt', 'bbc-khashoggi.txt'): 0.6789384344078828,\n",
       " ('aljazeera-khashoggi.txt', 'breitbart-khashoggi.txt'): 0.5549596552430964,\n",
       " ('aljazeera-khashoggi.txt', 'cnn-khashoggi.txt'): 0.5331228099011469,\n",
       " ('aljazeera-khashoggi.txt', 'fox-khashoggi.txt'): 0.6575655805929,\n",
       " ('bbc-khashoggi.txt', 'breitbart-khashoggi.txt'): 0.5647225050115716,\n",
       " ('bbc-khashoggi.txt', 'cnn-khashoggi.txt'): 0.5039192189493414,\n",
       " ('bbc-khashoggi.txt', 'fox-khashoggi.txt'): 0.6062429083809844,\n",
       " ('breitbart-khashoggi.txt', 'cnn-khashoggi.txt'): 0.3527237380899392,\n",
       " ('breitbart-khashoggi.txt', 'fox-khashoggi.txt'): 0.5182983952188844,\n",
       " ('cnn-khashoggi.txt', 'fox-khashoggi.txt'): 0.5137505781798409}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities_without_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76651d1",
   "metadata": {},
   "source": [
    "### Calculate the similarities with stopwords(in this part, the fuctions are basically the same except a minor change in the first fuction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f46bcd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['turkey',\n",
       " 'istanbul',\n",
       " 'turkish',\n",
       " 'president',\n",
       " 'recep',\n",
       " 'tayyip',\n",
       " 'erdogan',\n",
       " 'has',\n",
       " 'said',\n",
       " 'the',\n",
       " 'murder',\n",
       " 'of',\n",
       " 'journalist',\n",
       " 'jamal',\n",
       " 'khashoggi',\n",
       " 'at',\n",
       " 'the',\n",
       " 'kingdoms',\n",
       " 'consulate',\n",
       " 'in',\n",
       " 'istanbul',\n",
       " 'was',\n",
       " 'planned',\n",
       " 'by',\n",
       " 'saudi',\n",
       " 'officials',\n",
       " 'days',\n",
       " 'in',\n",
       " 'advance',\n",
       " 'addressing',\n",
       " 'legislators',\n",
       " 'from',\n",
       " 'his',\n",
       " 'justice',\n",
       " 'and',\n",
       " 'development',\n",
       " 'party',\n",
       " 'ak',\n",
       " 'party',\n",
       " 'on',\n",
       " 'tuesday',\n",
       " 'erdogan',\n",
       " 'detailed',\n",
       " 'khashoggis',\n",
       " 'disappearance',\n",
       " 'and',\n",
       " 'murder',\n",
       " 'but',\n",
       " 'stopped',\n",
       " 'short',\n",
       " 'of',\n",
       " 'accusing',\n",
       " 'saudi',\n",
       " 'royals',\n",
       " 'of',\n",
       " 'the',\n",
       " 'savage',\n",
       " 'killing',\n",
       " 'that',\n",
       " 'has',\n",
       " 'caused',\n",
       " 'global',\n",
       " 'outrage',\n",
       " 'on',\n",
       " 'september',\n",
       " '28',\n",
       " 'khashoggi',\n",
       " 'arrived',\n",
       " 'at',\n",
       " 'the',\n",
       " 'saudi',\n",
       " 'arabian',\n",
       " 'consulate',\n",
       " 'for',\n",
       " 'him',\n",
       " 'to',\n",
       " 'sort',\n",
       " 'out',\n",
       " 'his',\n",
       " 'wedding',\n",
       " 'paperwork',\n",
       " 'erdogan',\n",
       " 'said',\n",
       " 'during',\n",
       " 'the',\n",
       " 'speech',\n",
       " 'in',\n",
       " 'the',\n",
       " 'turkish',\n",
       " 'parliament',\n",
       " 'in',\n",
       " 'the',\n",
       " 'capital',\n",
       " 'ankara',\n",
       " 'it',\n",
       " 'seems',\n",
       " 'that',\n",
       " 'at',\n",
       " 'that',\n",
       " 'time',\n",
       " 'they',\n",
       " 'saudi',\n",
       " 'arabian',\n",
       " 'officials',\n",
       " 'started',\n",
       " 'to',\n",
       " 'plan',\n",
       " 'a',\n",
       " 'roadmap',\n",
       " 'for',\n",
       " 'his',\n",
       " 'murder',\n",
       " 'he',\n",
       " 'added',\n",
       " 'that',\n",
       " 'some',\n",
       " 'saudi',\n",
       " 'officials',\n",
       " 'left',\n",
       " 'turkey',\n",
       " 'and',\n",
       " 'travelled',\n",
       " 'to',\n",
       " 'saudi',\n",
       " 'arabia',\n",
       " 'indicating',\n",
       " 'they',\n",
       " 'planned',\n",
       " 'the',\n",
       " 'murder',\n",
       " 'khashoggi',\n",
       " '59',\n",
       " 'a',\n",
       " 'washington',\n",
       " 'post',\n",
       " 'columnist',\n",
       " 'and',\n",
       " 'critic',\n",
       " 'of',\n",
       " 'the',\n",
       " 'powerful',\n",
       " 'saudi',\n",
       " 'crown',\n",
       " 'prince',\n",
       " 'mohammed',\n",
       " 'bin',\n",
       " 'salman',\n",
       " 'disappeared',\n",
       " 'after',\n",
       " 'entering',\n",
       " 'the',\n",
       " 'saudi',\n",
       " 'consulate',\n",
       " 'on',\n",
       " 'october',\n",
       " '2',\n",
       " 'until',\n",
       " 'tuesdays',\n",
       " 'speech',\n",
       " 'erdogan',\n",
       " 'had',\n",
       " 'remained',\n",
       " 'largely',\n",
       " 'silent',\n",
       " 'on',\n",
       " 'the',\n",
       " 'case',\n",
       " 'although',\n",
       " 'unnamed',\n",
       " 'turkish',\n",
       " 'officials',\n",
       " 'have',\n",
       " 'leaked',\n",
       " 'information',\n",
       " 'about',\n",
       " 'the',\n",
       " 'murder',\n",
       " 'including',\n",
       " 'information',\n",
       " 'about',\n",
       " 'a',\n",
       " '15member',\n",
       " 'saudi',\n",
       " 'assassination',\n",
       " 'team',\n",
       " 'who',\n",
       " 'flew',\n",
       " 'into',\n",
       " 'istanbul',\n",
       " 'on',\n",
       " 'two',\n",
       " 'chartered',\n",
       " 'planes',\n",
       " 'in',\n",
       " 'the',\n",
       " 'wake',\n",
       " 'of',\n",
       " 'intense',\n",
       " 'global',\n",
       " 'pressure',\n",
       " 'saudi',\n",
       " 'arabia',\n",
       " 'admitted',\n",
       " 'last',\n",
       " 'week',\n",
       " 'that',\n",
       " 'khashoggi',\n",
       " 'was',\n",
       " 'killed',\n",
       " 'inside',\n",
       " 'its',\n",
       " 'istanbul',\n",
       " 'consulate',\n",
       " 'on',\n",
       " 'october',\n",
       " '2',\n",
       " 'as',\n",
       " 'a',\n",
       " 'result',\n",
       " 'of',\n",
       " 'a',\n",
       " 'fistfight',\n",
       " 'during',\n",
       " 'an',\n",
       " 'interrogation',\n",
       " 'saudi',\n",
       " 'authorities',\n",
       " 'arrested',\n",
       " '18',\n",
       " 'people',\n",
       " 'in',\n",
       " 'connection',\n",
       " 'with',\n",
       " 'the',\n",
       " 'killing',\n",
       " 'and',\n",
       " 'fired',\n",
       " 'top',\n",
       " 'security',\n",
       " 'officials',\n",
       " 'considered',\n",
       " 'close',\n",
       " 'to',\n",
       " 'bin',\n",
       " 'salman',\n",
       " 'erdogan',\n",
       " 'called',\n",
       " 'the',\n",
       " 'killing',\n",
       " 'a',\n",
       " 'political',\n",
       " 'murder',\n",
       " 'adding',\n",
       " 'that',\n",
       " 'international',\n",
       " 'investigators',\n",
       " 'should',\n",
       " 'be',\n",
       " 'included',\n",
       " 'in',\n",
       " 'the',\n",
       " 'probe',\n",
       " 'the',\n",
       " 'turkish',\n",
       " 'leader',\n",
       " 'went',\n",
       " 'on',\n",
       " 'to',\n",
       " 'call',\n",
       " 'the',\n",
       " 'killing',\n",
       " 'savage',\n",
       " 'adding',\n",
       " 'that',\n",
       " 'ankara',\n",
       " 'would',\n",
       " 'continue',\n",
       " 'its',\n",
       " 'investigation',\n",
       " 'until',\n",
       " 'all',\n",
       " 'questions',\n",
       " 'have',\n",
       " 'been',\n",
       " 'answered',\n",
       " 'why',\n",
       " 'did',\n",
       " 'they',\n",
       " 'the',\n",
       " 'saudi',\n",
       " 'team',\n",
       " 'come',\n",
       " 'to',\n",
       " 'istanbul',\n",
       " 'on',\n",
       " 'instruction',\n",
       " 'by',\n",
       " 'whom',\n",
       " 'erdogan',\n",
       " 'asked',\n",
       " 'adding',\n",
       " 'that',\n",
       " 'saudi',\n",
       " 'arabia',\n",
       " 'should',\n",
       " 'make',\n",
       " 'clear',\n",
       " 'why',\n",
       " 'it',\n",
       " 'did',\n",
       " 'not',\n",
       " 'let',\n",
       " 'investigators',\n",
       " 'into',\n",
       " 'the',\n",
       " 'consulate',\n",
       " 'until',\n",
       " 'days',\n",
       " 'later',\n",
       " 'where',\n",
       " 'is',\n",
       " 'the',\n",
       " 'body',\n",
       " 'galip',\n",
       " 'dalay',\n",
       " 'visiting',\n",
       " 'scholar',\n",
       " 'at',\n",
       " 'the',\n",
       " 'university',\n",
       " 'of',\n",
       " 'oxford',\n",
       " 'stressed',\n",
       " 'the',\n",
       " 'significance',\n",
       " 'of',\n",
       " 'erdogans',\n",
       " 'speech',\n",
       " 'the',\n",
       " 'most',\n",
       " 'important',\n",
       " 'thing',\n",
       " 'is',\n",
       " 'that',\n",
       " 'erdogan',\n",
       " 'confirmed',\n",
       " 'everything',\n",
       " 'we',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'heard',\n",
       " 'through',\n",
       " 'other',\n",
       " 'channels',\n",
       " 'he',\n",
       " 'told',\n",
       " 'al',\n",
       " 'jazeera',\n",
       " 'however',\n",
       " 'now',\n",
       " 'its',\n",
       " 'no',\n",
       " 'longer',\n",
       " 'attributed',\n",
       " 'to',\n",
       " 'unnamed',\n",
       " 'turkish',\n",
       " 'officials',\n",
       " 'but',\n",
       " 'its',\n",
       " 'the',\n",
       " 'president',\n",
       " 'of',\n",
       " 'turkey',\n",
       " 'who',\n",
       " 'has',\n",
       " 'confirmed',\n",
       " 'what',\n",
       " 'has',\n",
       " 'happened',\n",
       " 'dalay',\n",
       " 'said',\n",
       " 'erdogan',\n",
       " 'also',\n",
       " 'demanded',\n",
       " 'answers',\n",
       " 'on',\n",
       " 'what',\n",
       " 'happened',\n",
       " 'to',\n",
       " 'khashoggis',\n",
       " 'body',\n",
       " 'mentioning',\n",
       " 'reports',\n",
       " 'that',\n",
       " 'a',\n",
       " 'local',\n",
       " 'cooperator',\n",
       " 'allegedly',\n",
       " 'disposed',\n",
       " 'of',\n",
       " 'it',\n",
       " 'where',\n",
       " 'is',\n",
       " 'the',\n",
       " 'body',\n",
       " 'there',\n",
       " 'are',\n",
       " 'claims',\n",
       " 'his',\n",
       " 'body',\n",
       " 'has',\n",
       " 'been',\n",
       " 'given',\n",
       " 'to',\n",
       " 'a',\n",
       " 'local',\n",
       " 'person',\n",
       " 'but',\n",
       " 'who',\n",
       " 'is',\n",
       " 'this',\n",
       " 'local',\n",
       " 'person',\n",
       " 'erdogan',\n",
       " 'asked',\n",
       " 'nobody',\n",
       " 'is',\n",
       " 'allowed',\n",
       " 'to',\n",
       " 'think',\n",
       " 'this',\n",
       " 'case',\n",
       " 'will',\n",
       " 'come',\n",
       " 'to',\n",
       " 'an',\n",
       " 'end',\n",
       " 'without',\n",
       " 'answering',\n",
       " 'all',\n",
       " 'these',\n",
       " 'questions',\n",
       " 'he',\n",
       " 'added',\n",
       " 'the',\n",
       " 'turkish',\n",
       " 'president',\n",
       " 'also',\n",
       " 'said',\n",
       " 'saudi',\n",
       " 'arabia',\n",
       " 'was',\n",
       " 'taking',\n",
       " 'the',\n",
       " 'right',\n",
       " 'steps',\n",
       " 'by',\n",
       " 'working',\n",
       " 'with',\n",
       " 'ankara',\n",
       " 'on',\n",
       " 'the',\n",
       " 'investigation',\n",
       " 'and',\n",
       " 'carrying',\n",
       " 'out',\n",
       " 'the',\n",
       " '18',\n",
       " 'arrests',\n",
       " 'dalay',\n",
       " 'who',\n",
       " 'is',\n",
       " 'also',\n",
       " 'a',\n",
       " 'nonresident',\n",
       " 'fellow',\n",
       " 'at',\n",
       " 'brookings',\n",
       " 'institution',\n",
       " 'doha',\n",
       " 'underlined',\n",
       " 'erdogans',\n",
       " 'distinction',\n",
       " 'in',\n",
       " 'his',\n",
       " 'speech',\n",
       " 'between',\n",
       " 'king',\n",
       " 'salman',\n",
       " 'and',\n",
       " 'his',\n",
       " 'son',\n",
       " 'bin',\n",
       " 'salman',\n",
       " 'everything',\n",
       " 'that',\n",
       " 'erdogan',\n",
       " 'provided',\n",
       " 'pointed',\n",
       " 'towards',\n",
       " 'mbs',\n",
       " 'without',\n",
       " 'naming',\n",
       " 'the',\n",
       " 'crown',\n",
       " 'prince',\n",
       " 'specifically',\n",
       " 'said',\n",
       " 'dalay',\n",
       " 'adding',\n",
       " 'that',\n",
       " 'the',\n",
       " 'turkish',\n",
       " 'president',\n",
       " 'was',\n",
       " 'clearly',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'prevent',\n",
       " 'a',\n",
       " 'fullblown',\n",
       " 'crisis',\n",
       " 'between',\n",
       " 'ankara',\n",
       " 'and',\n",
       " 'riyadh',\n",
       " 'on',\n",
       " 'sunday',\n",
       " 'speaking',\n",
       " 'in',\n",
       " 'an',\n",
       " 'exclusive',\n",
       " 'interview',\n",
       " 'with',\n",
       " 'fox',\n",
       " 'news',\n",
       " 'saudi',\n",
       " 'arabias',\n",
       " 'foreign',\n",
       " 'minister',\n",
       " 'adel',\n",
       " 'aljubeir',\n",
       " 'said',\n",
       " 'khashoggis',\n",
       " 'killing',\n",
       " 'inside',\n",
       " 'the',\n",
       " 'consulate',\n",
       " 'was',\n",
       " 'a',\n",
       " 'terrible',\n",
       " 'tragedy',\n",
       " 'and',\n",
       " 'that',\n",
       " 'mbs',\n",
       " 'had',\n",
       " 'nothing',\n",
       " 'to',\n",
       " 'do',\n",
       " 'with',\n",
       " 'it',\n",
       " 'taha',\n",
       " 'ozhan',\n",
       " 'research',\n",
       " 'director',\n",
       " 'at',\n",
       " 'the',\n",
       " 'ankara',\n",
       " 'institute',\n",
       " 'told',\n",
       " 'al',\n",
       " 'jazeera',\n",
       " 'that',\n",
       " 'he',\n",
       " 'thought',\n",
       " 'erdogan',\n",
       " 'was',\n",
       " 'taking',\n",
       " 'the',\n",
       " 'right',\n",
       " 'steps',\n",
       " 'the',\n",
       " 'saudis',\n",
       " 'know',\n",
       " 'very',\n",
       " 'well',\n",
       " 'what',\n",
       " 'turkey',\n",
       " 'knows',\n",
       " 'and',\n",
       " 'what',\n",
       " 'erdogan',\n",
       " 'has',\n",
       " 'been',\n",
       " 'doing',\n",
       " 'is',\n",
       " 'the',\n",
       " 'right',\n",
       " 'thing',\n",
       " 'namely',\n",
       " 'asking',\n",
       " 'the',\n",
       " 'saudis',\n",
       " 'for',\n",
       " 'full',\n",
       " 'cooperation',\n",
       " 'in',\n",
       " 'this',\n",
       " 'case']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_text_txt_with(address):\n",
    "    '''\n",
    "    This function takes a txt file's directory as input and outputs a list that contains each word of the text.\n",
    "    \n",
    "    Arguements\n",
    "    ----------\n",
    "    address: a txt file's directory.\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    a list that contains each word of the txt file.\n",
    "    '''\n",
    "    text_as_list = []#create a new list.\n",
    "    with open(address) as f:#append each lineofnthe file to the list.\n",
    "        for line in f:\n",
    "            text_as_list.append(line)\n",
    "    text_as_list = text_as_list[0].lower().translate(str.maketrans('', '', string.punctuation)).split()#make the content to lower case, remove all punctuation and split to single word.\n",
    "    \n",
    "    return text_as_list\n",
    "\n",
    "get_text_txt_with('aljazeera-khashoggi.txt')#test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "676e4d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turkey</th>\n",
       "      <th>istanbul</th>\n",
       "      <th>turkish</th>\n",
       "      <th>president</th>\n",
       "      <th>recep</th>\n",
       "      <th>tayyip</th>\n",
       "      <th>erdogan</th>\n",
       "      <th>has</th>\n",
       "      <th>said</th>\n",
       "      <th>the</th>\n",
       "      <th>...</th>\n",
       "      <th>saudis</th>\n",
       "      <th>know</th>\n",
       "      <th>very</th>\n",
       "      <th>well</th>\n",
       "      <th>knows</th>\n",
       "      <th>doing</th>\n",
       "      <th>namely</th>\n",
       "      <th>asking</th>\n",
       "      <th>full</th>\n",
       "      <th>cooperation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 290 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   turkey  istanbul  turkish  president  recep  tayyip  erdogan  has  said  \\\n",
       "0       4         5        7          4      1       1       12    6     6   \n",
       "\n",
       "   the  ...  saudis  know  very  well  knows  doing  namely  asking  full  \\\n",
       "0   38  ...       2     1     1     1      1      1       1       1     1   \n",
       "\n",
       "   cooperation  \n",
       "0            1  \n",
       "\n",
       "[1 rows x 290 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_text_to_dtm_with(txt):\n",
    "    '''\n",
    "    This function takes a list that contains each word of the text as input and outputs a dataframe that counts the appearance of each word.\n",
    "    \n",
    "    Arguements\n",
    "    ----------\n",
    "    txt: a list that contains each word of the text.\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    a dataframe that counts the appearance of each word.\n",
    "    '''\n",
    "    d = dict()#create a dictionary to count the appearance.\n",
    "    for word in get_text_txt_with(txt):#if the word is in the dict, add one to the value. if not, create a new key.\n",
    "        if word in d:\n",
    "            d[word][0] += 1\n",
    "        else:\n",
    "            d[word] = [1]\n",
    "    return pd.DataFrame(d)\n",
    "\n",
    "convert_text_to_dtm_with('aljazeera-khashoggi.txt')#test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97172c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>108</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>15</th>\n",
       "      <th>15member</th>\n",
       "      <th>18</th>\n",
       "      <th>2</th>\n",
       "      <th>28</th>\n",
       "      <th>2r</th>\n",
       "      <th>...</th>\n",
       "      <th>“may</th>\n",
       "      <th>“other</th>\n",
       "      <th>“partner</th>\n",
       "      <th>“putting</th>\n",
       "      <th>“saudi</th>\n",
       "      <th>“the</th>\n",
       "      <th>“to</th>\n",
       "      <th>“we</th>\n",
       "      <th>“were</th>\n",
       "      <th>“why</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 919 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  108   11   12   15  15member   18    2   28   2r  ...  “may  “other  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0       1.0  2.0  2.0  1.0  0.0  ...   0.0     0.0   \n",
       "1  0.0  0.0  0.0  1.0  0.0       0.0  2.0  1.0  0.0  1.0  ...   0.0     0.0   \n",
       "2  0.0  0.0  0.0  0.0  1.0       0.0  0.0  0.0  0.0  0.0  ...   1.0     1.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0       0.0  1.0  0.0  0.0  0.0  ...   0.0     0.0   \n",
       "4  1.0  1.0  1.0  0.0  1.0       0.0  1.0  1.0  0.0  0.0  ...   0.0     0.0   \n",
       "\n",
       "   “partner  “putting  “saudi  “the  “to  “we  “were  “why  \n",
       "0       0.0       0.0     0.0   0.0  0.0  0.0    0.0   0.0  \n",
       "1       0.0       0.0     0.0   0.0  0.0  0.0    0.0   0.0  \n",
       "2       1.0       1.0     0.0   2.0  0.0  1.0    0.0   1.0  \n",
       "3       0.0       0.0     0.0   0.0  0.0  0.0    0.0   0.0  \n",
       "4       0.0       0.0     1.0   0.0  1.0  0.0    1.0   0.0  \n",
       "\n",
       "[5 rows x 919 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now build a function that does this for a list of texts\n",
    "def gen_DTM_with(texts=None):\n",
    "    '''\n",
    "    This function Generate a document term matrix.\n",
    "    \n",
    "    Arguements\n",
    "    ----------\n",
    "    texts: a list that contains all the dirctorys that you want to include.\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    a dataframe that counts the appearance of each word of each txt file.\n",
    "    '''\n",
    "    DTM = pd.DataFrame()#create a new dataframe\n",
    "    for text in texts:#convert the appearance of words of each file and combine them.\n",
    "        entry = convert_text_to_dtm_with(text)\n",
    "        DTM = DTM.append(pd.DataFrame(entry),ignore_index=True,sort=True) # Row bind\n",
    "    \n",
    "    DTM.fillna(0, inplace=True) # Fill in any missing values with 0s (i.e. when a word is in one text but not another)\n",
    "    return DTM\n",
    "      \n",
    "gen_DTM_with(texts_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11c6e008",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities_with_stop = {}#create a new dict.\n",
    "for i in range(gen_DTM_with(texts_list) .shape[0]):#calculate the cosine of each two combinaton and append it to the dictionary with there names as key.\n",
    "    for j in range(i + 1, gen_DTM_with(texts_list).shape[0]):\n",
    "        similarities_with_stop[texts_list[i], texts_list[j]] = cosine(gen_DTM_with(texts_list).iloc[i].values, gen_DTM_with(texts_list).iloc[j].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "193e0a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('aljazeera-khashoggi.txt', 'bbc-khashoggi.txt'): 0.8704785650109934,\n",
       " ('aljazeera-khashoggi.txt', 'breitbart-khashoggi.txt'): 0.8307040967375,\n",
       " ('aljazeera-khashoggi.txt', 'cnn-khashoggi.txt'): 0.7346592558334714,\n",
       " ('aljazeera-khashoggi.txt', 'fox-khashoggi.txt'): 0.837865118014574,\n",
       " ('bbc-khashoggi.txt', 'breitbart-khashoggi.txt'): 0.8938858587288907,\n",
       " ('bbc-khashoggi.txt', 'cnn-khashoggi.txt'): 0.7440412240226454,\n",
       " ('bbc-khashoggi.txt', 'fox-khashoggi.txt'): 0.885635500576476,\n",
       " ('breitbart-khashoggi.txt', 'cnn-khashoggi.txt'): 0.681866663912452,\n",
       " ('breitbart-khashoggi.txt', 'fox-khashoggi.txt'): 0.865128633261706,\n",
       " ('cnn-khashoggi.txt', 'fox-khashoggi.txt'): 0.736447336924943}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities_with_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c6661d",
   "metadata": {},
   "source": [
    "We can see that the combination of 'aljazeera-khashoggi.txt', 'bbc-khashoggi.txt' and 'aljazeera-khashoggi.txt', 'fox-khashoggi.txt' have more similarities(without stopwords). 'breitbart-khashoggi.txt', 'cnn-khashoggi.txt' tell the story more differently than others(without stopwords).\n",
    "\n",
    "It is clear that with stop words, on average the similarities are higher."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
