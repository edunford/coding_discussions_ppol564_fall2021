{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Discussion Four"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "from itertools import combinations\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Text Files\n",
    "p1 = open(\"coding_discussions_ppol564_fall2021/04_coding_discussion/Data/aljazeera-khashoggi.txt\", \"r\", encoding=\"utf8\")\n",
    "p2 = open(\"coding_discussions_ppol564_fall2021/04_coding_discussion/Data/bbc-khashoggi.txt\", \"r\")\n",
    "p3 = open(\"coding_discussions_ppol564_fall2021/04_coding_discussion/Data/breitbart-khashoggi.txt\", \"r\", encoding=\"utf8\")\n",
    "p4 = open(\"coding_discussions_ppol564_fall2021/04_coding_discussion/Data/cnn-khashoggi.txt\", \"r\")\n",
    "p5 = open(\"coding_discussions_ppol564_fall2021/04_coding_discussion/Data/fox-khashoggi.txt\", \"r\", encoding=\"utf8\")\n",
    "\n",
    "# Read File and store into variables\n",
    "txt1 = p1.read()\n",
    "txt2 = p2.read()\n",
    "txt3 = p3.read()\n",
    "txt4 = p4.read()\n",
    "txt5 = p5.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p1_name': 'aljazeera',\n",
       " 'p2_name': 'bbc',\n",
       " 'p3_name': 'breitbart',\n",
       " 'p4_name': 'cnn',\n",
       " 'p5_name': 'fox'}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store Each articles company into dictionary\n",
    "names = {}\n",
    "for i in range(1,6):\n",
    "    names[\"p\" + str(i) + \"_name\"] = eval(\"p\" + str(i)).name.split('/')[-1].split('-')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two types of stop words second is adding nuetral words\n",
    "stop_words = pd.read_csv(\"coding_discussions_ppol564_fall2021/04_coding_discussion/Data/stop_words.csv\")\n",
    "stop_words_extended = stop_words['word'].tolist() + [\"khashoggi\", \"saudi\", \"erdogan\", \"turkish\", \"arabia\", \"istanbul\", \"salman\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CV using different stop words\n",
    "CountVec = CountVectorizer(stop_words = stop_words['word'].tolist())\n",
    "CountVec2 = CountVectorizer(stop_words = stop_words_extended, min_df=1)\n",
    "\n",
    "# Fit data\n",
    "Count_data = CountVec.fit_transform([txt1, txt2,txt3,txt4,txt5])\n",
    "Count_data_2 = CountVec2.fit_transform([txt1,txt2,txt3,txt4,txt5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The five most common words across all texts are: \n",
      "[('saudi', 56), ('erdogan', 49), ('khashoggi', 47), ('consulate', 24), ('turkish', 23)]\n"
     ]
    }
   ],
   "source": [
    "# First CV\n",
    "sum_words = Count_data.sum(axis=0)\n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in CountVec.vocabulary_.items()]\n",
    "words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "print(\"The five most common words across all texts are: \")\n",
    "print(words_freq[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If we remove the most common neutral words we find that the most common words are:\n",
      "[('consulate', 24), ('murder', 22), ('president', 21), ('killing', 21), ('speech', 13)]\n"
     ]
    }
   ],
   "source": [
    "# Second CV\n",
    "sum_words_2 = Count_data_2.sum(axis=0)\n",
    "words_freq_2 = [(word, sum_words_2[0, idx]) for word, idx in CountVec2.vocabulary_.items()]\n",
    "words_freq_2 = sorted(words_freq_2, key = lambda x: x[1], reverse=True)\n",
    "print(\"If we remove the most common neutral words we find that the most common words are:\")\n",
    "print(words_freq_2[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate similarity scores\n",
    "def sim_scores(a, b):\n",
    "    \n",
    "    \"\"\"\n",
    "    Args: (a,b) which are both the index of the article you want to compare\n",
    "    Return: The cosine similarity score is retured\n",
    "    \"\"\"\n",
    "    \n",
    "    a = a - 1\n",
    "    b = b - 1\n",
    "    a_data = Count_data[a,:]\n",
    "    b_data = Count_data[b,:]\n",
    "    numerator = int(np.dot(a_data.todense(), b_data.todense().transpose()))\n",
    "    denom = LA.norm(a_data.todense()) * LA.norm(b_data.todense())\n",
    "    return numerator / denom\n",
    "\n",
    "def sim_scores_2(a, b):\n",
    "    \n",
    "    \"\"\"\n",
    "    Args: (a,b) which are both the index of the article you want to compare\n",
    "    Function: Uses the extended stop words CV\n",
    "    Return: The cosine similarity score is retured\n",
    "    \"\"\"\n",
    "    \n",
    "    a = a - 1\n",
    "    b = b - 1\n",
    "    a_data = Count_data_2[a,:]\n",
    "    b_data = Count_data_2[b,:]\n",
    "    numerator = int(np.dot(a_data.todense(), b_data.todense().transpose()))\n",
    "    denom = LA.norm(a_data.todense()) * LA.norm(b_data.todense())\n",
    "    return numerator / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_a</th>\n",
       "      <th>source_b</th>\n",
       "      <th>similarity</th>\n",
       "      <th>similarity_removed</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aljazeera</td>\n",
       "      <td>bbc</td>\n",
       "      <td>0.704288</td>\n",
       "      <td>0.484164</td>\n",
       "      <td>0.220124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aljazeera</td>\n",
       "      <td>breitbart</td>\n",
       "      <td>0.600776</td>\n",
       "      <td>0.416694</td>\n",
       "      <td>0.184082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aljazeera</td>\n",
       "      <td>cnn</td>\n",
       "      <td>0.608624</td>\n",
       "      <td>0.311458</td>\n",
       "      <td>0.297166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aljazeera</td>\n",
       "      <td>fox</td>\n",
       "      <td>0.719294</td>\n",
       "      <td>0.502585</td>\n",
       "      <td>0.216709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bbc</td>\n",
       "      <td>breitbart</td>\n",
       "      <td>0.621047</td>\n",
       "      <td>0.476368</td>\n",
       "      <td>0.144678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bbc</td>\n",
       "      <td>cnn</td>\n",
       "      <td>0.550651</td>\n",
       "      <td>0.265059</td>\n",
       "      <td>0.285592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bbc</td>\n",
       "      <td>fox</td>\n",
       "      <td>0.692978</td>\n",
       "      <td>0.479765</td>\n",
       "      <td>0.213213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>breitbart</td>\n",
       "      <td>cnn</td>\n",
       "      <td>0.421972</td>\n",
       "      <td>0.168846</td>\n",
       "      <td>0.253126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>breitbart</td>\n",
       "      <td>fox</td>\n",
       "      <td>0.581209</td>\n",
       "      <td>0.429816</td>\n",
       "      <td>0.151393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cnn</td>\n",
       "      <td>fox</td>\n",
       "      <td>0.605116</td>\n",
       "      <td>0.269107</td>\n",
       "      <td>0.336009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    source_a   source_b  similarity  similarity_removed      diff\n",
       "0  aljazeera        bbc    0.704288            0.484164  0.220124\n",
       "1  aljazeera  breitbart    0.600776            0.416694  0.184082\n",
       "2  aljazeera        cnn    0.608624            0.311458  0.297166\n",
       "3  aljazeera        fox    0.719294            0.502585  0.216709\n",
       "4        bbc  breitbart    0.621047            0.476368  0.144678\n",
       "5        bbc        cnn    0.550651            0.265059  0.285592\n",
       "6        bbc        fox    0.692978            0.479765  0.213213\n",
       "7  breitbart        cnn    0.421972            0.168846  0.253126\n",
       "8  breitbart        fox    0.581209            0.429816  0.151393\n",
       "9        cnn        fox    0.605116            0.269107  0.336009"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create combination of articles to compare similarity\n",
    "combs = list(combinations(range(1,6),2))\n",
    "df = pd.DataFrame(columns = [\"source_a\", \"source_b\", \"similarity\", \"similarity_removed\", \"diff\"])\n",
    "\n",
    "# Add values to df\n",
    "for c in combs:\n",
    "    v1 = list(names.values())[c[0] - 1]\n",
    "    v2 = list(names.values())[c[1] - 1]\n",
    "    v3 = sim_scores(c[0], c[1])\n",
    "    v4 = sim_scores_2(c[0], c[1])\n",
    "    df.loc[len(df)] = [v1,v2,v3,v4, v3-v4]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above dataframe we can see that when we leave the stop words to be the original words that the articles that seem to be most similar are between Aljazeera and Fox, Aljazeera and BBC. However, the reason I was a little skeptical about these findings are they still use words that are neutral such as names and the country. There I hypothesized that if I removed these words then we would find more meaningful results to describe the similarities between articles. If we look at those results we see that Aljazeera and Fox, Aljazeera and BBC are still in the top of the chart, however another grouping also becomes more prevalant in the BBC and Breitbart, BBC and Fox articles. To further analysis we could also do larger grouping of words.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
